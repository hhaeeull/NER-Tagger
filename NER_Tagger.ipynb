{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tzB0WgQhtH9"
      },
      "source": [
        "This project aims to implement a NER Tagger with Pytorch. We will be using the English CONLL 2003 data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUnG00_hYl0"
      },
      "source": [
        "Data download & description\n",
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCe8as2ej9E0",
        "outputId": "e0cc9dde-4c84-472c-dd3e-74324074a9f8"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.train','eng.train')\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.testa','eng.testa')\n",
        "\n",
        "#Prints the beginning of the training set\n",
        "istream = open('eng.train')\n",
        "for idx, line in enumerate(istream):\n",
        "  print(line.strip())\n",
        "\n",
        "  print(line.strip().split())\n",
        "  if idx >=3:\n",
        "    break\n",
        "istream.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "['-DOCSTART-', '-X-', '-X-', 'O']\n",
            "\n",
            "[]\n",
            "EU NNP I-NP I-ORG\n",
            "['EU', 'NNP', 'I-NP', 'I-ORG']\n",
            "rejects VBZ I-VP O\n",
            "['rejects', 'VBZ', 'I-VP', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2f9l5U7mjLz"
      },
      "source": [
        "The CONLL 2003 dataset encodes each token on a single line followed by its annotation. A token line is a quadruple:\n",
        "\n",
        "> (token,tag,chunk,named entity)\n",
        "\n",
        "A named entity tagger aims to predict the named entity annotations given the raw tokens. The NER tags follows the IOB convention.\n",
        "* **I** stands for **Inside** and is used to flag tokens that are part of a named entity.\n",
        "* **B** stands for **Begin** and is used to flag a token starting a new entity when the preceding token is already part of an entity.\n",
        "* **O** stands for **Outside** and is used to flag tokens that are not part of a named entity.\n",
        "\n",
        "The I and B Tag are followed by a specifier. For instance I-PER means that the named entity refers to a person, I-ORG means that the entity is refers to an Organisation.\n",
        "\n",
        "Sentences are separated by a blank line. The train file is `eng.train`, the dev file is `eng.testa`. I will evaluate your work with a test file unknown to you.\n",
        "To do this, I will change the content of the dev file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAo1csOSpgBh"
      },
      "source": [
        "Using CONLL2003 the train file, you will:\n",
        "\n",
        "* Extract an input vocabulary and create two maps: one mapping tokens to integers and a second mapping integers to tokens (see the pdf notes)\n",
        "* Include elements in the input vocabulary for padding and for unknown words\n",
        "* Extract an output vocabulary (the set of NER tags) and returns two maps\n",
        "mapping tags to integer and vice-versa.\n",
        "\n",
        "These functionalities should be implemented in a function with signature `vocabulary(filename)` that returns the two maps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_conllu(filename):\n",
        "  lines = open(filename).readlines()\n",
        "  sentences = []\n",
        "  current_sentence = []\n",
        "  for line in lines:\n",
        "\n",
        "    line = line.strip() # remove the empty in the beging of seq\n",
        "\n",
        "    if line.startswith(\"-DOCSTART-\"):\n",
        "      continue\n",
        "    # if /n means the end of one sentence\n",
        "    if not line: # /n not line\n",
        "      if current_sentence:\n",
        "        sentences.append(current_sentence)\n",
        "        current_sentence = []\n",
        "      continue\n",
        "\n",
        "    tokens = line.split()\n",
        "    token_map = {\n",
        "        \"word\":tokens[0],\n",
        "        \"pos\":tokens[1],\n",
        "        \"chunk\":tokens[2],\n",
        "        \"ner\":tokens[3]\n",
        "    }\n",
        "    current_sentence.append(token_map)\n",
        "  # process last sentence\n",
        "  if current_sentence:\n",
        "    sentences.append(current_sentence)\n",
        "  return sentences\n",
        "train_data = read_conllu(\"./eng.train\")\n"
      ],
      "metadata": {
        "id": "_-dlBxfJdcyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYXwOXn1gRnf",
        "outputId": "ca3fac97-8c25-4149-8ad1-7e28acb63669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'word': 'Swansea', 'pos': 'NN', 'chunk': 'I-NP', 'ner': 'I-ORG'},\n",
              " {'word': '1', 'pos': 'CD', 'chunk': 'I-NP', 'ner': 'O'},\n",
              " {'word': 'Lincoln', 'pos': 'NNP', 'chunk': 'I-NP', 'ner': 'I-ORG'},\n",
              " {'word': '2', 'pos': 'CD', 'chunk': 'I-NP', 'ner': 'O'}]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sym2idx = {}\n",
        "for data in train_data:\n",
        "  for sub_dict in data:\n",
        "    word = sub_dict['word']\n",
        "    if word not in sym2idx:\n",
        "      sym2idx[word] = len(sym2idx)\n"
      ],
      "metadata": {
        "id": "RffmakDKhuey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_check = {sub_dict['word'] for data in train_data for sub_dict in data}"
      ],
      "metadata": {
        "id": "u_R4tZoPkFzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91gPda_ckKyu",
        "outputId": "3b489f0a-31e6-4126-95d9-ede9add9d723",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nose',\n",
              " 'Assoc',\n",
              " 'Germain',\n",
              " '2.777',\n",
              " 'Brown',\n",
              " 'campaigning',\n",
              " 'SARAJEVO',\n",
              " '1,429',\n",
              " 'colourful',\n",
              " 'PNW',\n",
              " '12,900-13,150',\n",
              " 'Finally',\n",
              " 'Atlanta',\n",
              " 'yorker',\n",
              " 'Bonds',\n",
              " '48,000',\n",
              " 'MS',\n",
              " '1995',\n",
              " 'Bunge',\n",
              " '4.38',\n",
              " '33969650',\n",
              " 'Roda',\n",
              " 'speculated',\n",
              " 'necessary',\n",
              " 'rules',\n",
              " 'Watanabe',\n",
              " 'single-digits',\n",
              " 'Firearms',\n",
              " 'Flemming',\n",
              " 'street-level',\n",
              " 'Hubner',\n",
              " 'Les',\n",
              " 'consolidating',\n",
              " 'Freedom',\n",
              " 'communism',\n",
              " 'infections',\n",
              " 'explained',\n",
              " 'Optimised',\n",
              " 'Leonard',\n",
              " 'passes',\n",
              " 'newly-established',\n",
              " 'Economic',\n",
              " 'tough',\n",
              " 'anti-',\n",
              " 'November',\n",
              " 'confiscation',\n",
              " 'Welspun',\n",
              " 'board',\n",
              " 'injection',\n",
              " '50',\n",
              " 'secondary',\n",
              " 'reports',\n",
              " 'Lavaggi',\n",
              " 'Elections',\n",
              " 'Malik',\n",
              " 'Put',\n",
              " 'Actor',\n",
              " 'engaging',\n",
              " 'vouch',\n",
              " '13',\n",
              " 'sedan',\n",
              " 'volunteers',\n",
              " 'method',\n",
              " 'Lt.',\n",
              " 'Non-Callable',\n",
              " 'races',\n",
              " 'burned',\n",
              " '482-1003',\n",
              " 'nine-to-one',\n",
              " 'Displaced',\n",
              " '.Giuseppe',\n",
              " 'inflamation',\n",
              " '1,196',\n",
              " 'texts',\n",
              " 'Gillian',\n",
              " 'Beryllium',\n",
              " 'roadblocks',\n",
              " 'Jill',\n",
              " 'front-page',\n",
              " 'Strategic',\n",
              " 'Hanover',\n",
              " '1996-08-26',\n",
              " '3-167',\n",
              " '10-12',\n",
              " 'Recriminations',\n",
              " 'sucks',\n",
              " '49.83',\n",
              " 'interview',\n",
              " 'undergo',\n",
              " 'Midwest',\n",
              " 'installation',\n",
              " 'BVSC',\n",
              " 'Jonty',\n",
              " 'peaked',\n",
              " '17,000',\n",
              " '12.',\n",
              " 'Yelena',\n",
              " 'Popular',\n",
              " '117.00',\n",
              " 'kidding',\n",
              " 'Equivalents',\n",
              " 'Musa',\n",
              " 'emptied',\n",
              " 'Tauziat',\n",
              " 'handles',\n",
              " 'Major-General',\n",
              " '32.3',\n",
              " 'Junior',\n",
              " '758',\n",
              " '11-year-old',\n",
              " 'Gunda',\n",
              " 'marksmen',\n",
              " 'Adem',\n",
              " 'Knoroz',\n",
              " '9000',\n",
              " 'cancer',\n",
              " 'venue',\n",
              " 'HAT-TRICK',\n",
              " 'consumer',\n",
              " 'Kieran',\n",
              " '19999.777',\n",
              " 'MBIA',\n",
              " '1.0',\n",
              " 'modem',\n",
              " 'tipped',\n",
              " 'parents',\n",
              " 'equality',\n",
              " 'collectivisation',\n",
              " 'unwinding',\n",
              " '1.00',\n",
              " 'tbf',\n",
              " 'Rittner',\n",
              " 'SORENSEN',\n",
              " 'precedence',\n",
              " 'England-based',\n",
              " 'disappoint',\n",
              " 'Elephants',\n",
              " 'Montolio',\n",
              " 'DNS',\n",
              " '568',\n",
              " 'Shabwa',\n",
              " '141',\n",
              " 'fashion',\n",
              " 'CRAWLEY',\n",
              " '2009',\n",
              " 'broader',\n",
              " '6603377',\n",
              " 'O-157',\n",
              " 'gifts',\n",
              " 'surveillance',\n",
              " 'Gabon',\n",
              " 'Waqar',\n",
              " 'race',\n",
              " 'Apertura',\n",
              " '1:53.067',\n",
              " 'unfortunate',\n",
              " 'cents',\n",
              " 'dressed',\n",
              " 'locals',\n",
              " '10.14',\n",
              " '605M',\n",
              " '3M',\n",
              " 'dislodge',\n",
              " 'Roy',\n",
              " 'quadrangular',\n",
              " 'propaganda',\n",
              " 'contributed',\n",
              " 'delay',\n",
              " 'Blakey',\n",
              " '13-15',\n",
              " 'MANAGUA',\n",
              " 'runner',\n",
              " 'AUTHORITY',\n",
              " '26-year-old',\n",
              " 'Frana',\n",
              " '97.79',\n",
              " '14-pct',\n",
              " 'Gcaleka',\n",
              " 'GENERAL',\n",
              " 'Rikl',\n",
              " '120.5',\n",
              " 'flames',\n",
              " 'Masayoshi',\n",
              " '45.48',\n",
              " 'Course',\n",
              " 'misfortune',\n",
              " 'rallying',\n",
              " 'eighth',\n",
              " '782.6',\n",
              " 'senior',\n",
              " 'Motorola',\n",
              " 'primarily',\n",
              " 'PSC',\n",
              " 'encamped',\n",
              " 'rejoined',\n",
              " '1.4789',\n",
              " 'Swe',\n",
              " '---------------------',\n",
              " 'Caldwell',\n",
              " '3024.95',\n",
              " 'fine',\n",
              " '9251-274757',\n",
              " 'especially',\n",
              " '173',\n",
              " 'Chenab',\n",
              " '1992-95',\n",
              " 'unsettled',\n",
              " 'TOSS',\n",
              " '25-6-95-4',\n",
              " '5.1700',\n",
              " 'conversion',\n",
              " '199',\n",
              " 'pedestrain',\n",
              " 'Eksportfinans',\n",
              " '144',\n",
              " 'ALEXANDROUPOLIS',\n",
              " '1:50.858',\n",
              " 'switched',\n",
              " 'Luo',\n",
              " 'spoken',\n",
              " 'LOSE',\n",
              " '.573',\n",
              " 'Universities',\n",
              " 'registering',\n",
              " '16.75',\n",
              " 'Children',\n",
              " 'Artur',\n",
              " 'determination',\n",
              " '21.08',\n",
              " '76.6',\n",
              " 'McPherson',\n",
              " 'parts',\n",
              " '4-205',\n",
              " 'roadblock',\n",
              " 'VfB',\n",
              " 'Golf',\n",
              " 'Minister',\n",
              " 'Burundi-Central',\n",
              " 'kilo',\n",
              " 'once',\n",
              " 'Vass',\n",
              " '49.31',\n",
              " 'front-line',\n",
              " 'hurdler',\n",
              " 'middle',\n",
              " 'discharge',\n",
              " '12.130',\n",
              " 'absolute',\n",
              " 'Oklahoma',\n",
              " 'TRUTH',\n",
              " 'medium-term',\n",
              " 'CENTER',\n",
              " 'PMC-Sierra',\n",
              " 'Easley',\n",
              " 'Marcel',\n",
              " 'Gil',\n",
              " 'in-house',\n",
              " 'Ajaccio',\n",
              " 'Regan',\n",
              " 'tries',\n",
              " 'plan',\n",
              " 'upright',\n",
              " '212.00',\n",
              " 'Ababa',\n",
              " 'guards',\n",
              " 'expect',\n",
              " 'demilitarised',\n",
              " 'Vancouver-based',\n",
              " 'Ojanen',\n",
              " 'Pot',\n",
              " 'Simeonov',\n",
              " 'harder',\n",
              " '50-cent',\n",
              " 'performed',\n",
              " 'acrimonious',\n",
              " 'YR',\n",
              " '58.92',\n",
              " 'attributed',\n",
              " '1.84',\n",
              " 'independence',\n",
              " 'Khalaf',\n",
              " 'steady',\n",
              " 'Dutroux',\n",
              " 'one-run',\n",
              " 'Muscular',\n",
              " 'TNT',\n",
              " 'RIA',\n",
              " 'reportedly',\n",
              " 'Six',\n",
              " 'reassure',\n",
              " 'Lausanne',\n",
              " 'decomposed',\n",
              " 'in-form',\n",
              " 'Dejan',\n",
              " '4.7200',\n",
              " 'hard-pressed',\n",
              " 'three-engine',\n",
              " 'submissions',\n",
              " 'recalled',\n",
              " 'FTSE-100',\n",
              " 'dying',\n",
              " 'Beachcomber',\n",
              " 'snatched',\n",
              " 'fund',\n",
              " '7',\n",
              " '6.03',\n",
              " 'MUNDO',\n",
              " 'horses',\n",
              " 'Fox',\n",
              " 'trimmed',\n",
              " 'overnight',\n",
              " 'Karen',\n",
              " 'Aggregate',\n",
              " 'sectarian',\n",
              " 'mid-twenties',\n",
              " '285',\n",
              " 'Dnevi',\n",
              " 'NATO-led',\n",
              " 'bronze',\n",
              " 'expand',\n",
              " '0.86',\n",
              " 'picked',\n",
              " 'photographs',\n",
              " '4:26.467',\n",
              " 'Siofok',\n",
              " 'superstar',\n",
              " '1-0',\n",
              " 'Cruyff',\n",
              " 'filing',\n",
              " 'fruit',\n",
              " 'finalists',\n",
              " '409',\n",
              " 'Prior',\n",
              " 'Markets',\n",
              " 'dipping',\n",
              " 'moral',\n",
              " 'Shanghai',\n",
              " 'trials',\n",
              " 'Nairobi',\n",
              " 'architect',\n",
              " 'weakness',\n",
              " 'Wyborcza',\n",
              " 'Semerdjieva',\n",
              " 'green',\n",
              " 'Baird',\n",
              " '12-1',\n",
              " 'store',\n",
              " 'Leopold',\n",
              " 'opium',\n",
              " 'b-6',\n",
              " 'BOND',\n",
              " 'findings',\n",
              " '0-1',\n",
              " 'incredulous',\n",
              " '251/06',\n",
              " 'TM',\n",
              " '25-30',\n",
              " 'compromise',\n",
              " '11,500',\n",
              " 'Gordon',\n",
              " '1964',\n",
              " '988.2',\n",
              " 'Americast',\n",
              " 'Italo',\n",
              " '1900',\n",
              " 'tube',\n",
              " 'Pizzichini',\n",
              " 'confessing',\n",
              " 'eventual',\n",
              " '3:54.57',\n",
              " 'Salomon',\n",
              " '4.46',\n",
              " 'shortage',\n",
              " '4-334',\n",
              " 'earth-shattering',\n",
              " 'Fenerbahce',\n",
              " 'Bessemer',\n",
              " 'Siebens',\n",
              " '1947-48',\n",
              " 'first-time',\n",
              " 'Campora',\n",
              " '211',\n",
              " 'LITTLE',\n",
              " 'children',\n",
              " 'north-west',\n",
              " 'Terence',\n",
              " 'telephone',\n",
              " 'peacefully',\n",
              " 'Bagwell',\n",
              " 'Detroux',\n",
              " 'ENHANCEMENTS',\n",
              " '2:29.66',\n",
              " 'bowed',\n",
              " '2,386',\n",
              " 'say',\n",
              " 'nb-3',\n",
              " 'library',\n",
              " 'FORMULA',\n",
              " 'Mrs.',\n",
              " 'FORECAST',\n",
              " 'Berlusconi',\n",
              " 'Kongsvinger',\n",
              " 'orderly',\n",
              " 'hall',\n",
              " '252',\n",
              " 'Wengert',\n",
              " 'spiritually',\n",
              " '39.',\n",
              " 'CAREER',\n",
              " '10-0-59-1',\n",
              " 'Jerry',\n",
              " 'took',\n",
              " 'callers',\n",
              " 'explicit',\n",
              " 'ascribed',\n",
              " 'IMF-hosted',\n",
              " 'were',\n",
              " 'concrete',\n",
              " 'marvelling',\n",
              " 'Becker',\n",
              " 'reverts',\n",
              " 'details',\n",
              " 'gangland-style',\n",
              " 'throat',\n",
              " 'sanctions',\n",
              " 'acquisitions',\n",
              " 'Pedersen',\n",
              " 'registry',\n",
              " 'Isbank',\n",
              " 'Reina',\n",
              " 'Makinen',\n",
              " 'Arrows',\n",
              " 'deliberately',\n",
              " 'Galarraga',\n",
              " 'IPE',\n",
              " 'Bradley',\n",
              " 'polls',\n",
              " 'clinched',\n",
              " 'steamrollered',\n",
              " 'shake',\n",
              " 'Ludmila',\n",
              " 'minimise',\n",
              " 'empower',\n",
              " 'Saudi',\n",
              " 'Cometra',\n",
              " 'Coltart',\n",
              " 'GAZA',\n",
              " 'note',\n",
              " 'deficit',\n",
              " 'usually',\n",
              " 'fired',\n",
              " '.623',\n",
              " 'Last-minute',\n",
              " 'impact',\n",
              " 'Chernyavskaya',\n",
              " 'capturing',\n",
              " 'Nobilo',\n",
              " 'stockpile',\n",
              " 'Fernandez',\n",
              " 'financed',\n",
              " 'Annette',\n",
              " 'Eau',\n",
              " 'reporting',\n",
              " 'Albanian-born',\n",
              " 'rampage',\n",
              " '10.19',\n",
              " 'Duvillard',\n",
              " 'Greer',\n",
              " 'Pietro',\n",
              " 'outscored',\n",
              " 'Neuchatel',\n",
              " 'Stocher',\n",
              " 'thigh',\n",
              " 'cup',\n",
              " 'Lugo',\n",
              " 'raging',\n",
              " 'crane',\n",
              " 'Described',\n",
              " 'ONE-DAY',\n",
              " 'big',\n",
              " 'reopen',\n",
              " 'BankWatch',\n",
              " 'Bedouin',\n",
              " 'Okada',\n",
              " 'Ranatunga',\n",
              " 'Bangkok',\n",
              " 'No1',\n",
              " 'kidney',\n",
              " 'contribution',\n",
              " 'necessitate',\n",
              " 'Caucasus',\n",
              " 'scared',\n",
              " '5th',\n",
              " 'Bulgarians',\n",
              " 'culprit',\n",
              " 'Chandrika',\n",
              " 'standings',\n",
              " 'detect',\n",
              " 'safeguarded',\n",
              " \"O'Sullivan\",\n",
              " '226-1',\n",
              " 'Arabised',\n",
              " 'deteriorating',\n",
              " 'degrading',\n",
              " '39',\n",
              " 'million',\n",
              " 'Economy',\n",
              " 'mixture',\n",
              " 'liberalising',\n",
              " 'second-placed',\n",
              " 'confronting',\n",
              " '1952',\n",
              " 'Organisation',\n",
              " '6179',\n",
              " 'Premiership',\n",
              " 'developers',\n",
              " 'Oakland',\n",
              " 'stationery',\n",
              " '0900',\n",
              " 'OM',\n",
              " '1464/96',\n",
              " 'gratitude',\n",
              " 'reinforced',\n",
              " 'Malekos',\n",
              " 'quiet',\n",
              " 'vice-president',\n",
              " '5,539',\n",
              " 'Hassan',\n",
              " 'Angeles',\n",
              " 'pumps',\n",
              " 'Waldorf',\n",
              " '36th',\n",
              " '3-0-17-0',\n",
              " 'QUENCH',\n",
              " 'LOSS',\n",
              " 'recognised',\n",
              " 'post-mortem',\n",
              " 'Banfield',\n",
              " 'Chabora',\n",
              " '45.67',\n",
              " '570M',\n",
              " 'theologian',\n",
              " '351',\n",
              " 'removing',\n",
              " '65-56',\n",
              " 'Ssangbangwool',\n",
              " 'District',\n",
              " 'theme',\n",
              " 'repaid',\n",
              " 'skilful',\n",
              " 'commitments',\n",
              " 'Berkshire',\n",
              " 'waged',\n",
              " 'Theodore',\n",
              " '63.48',\n",
              " 'coal-mining',\n",
              " 'laid',\n",
              " 'Ferrigato',\n",
              " 'en',\n",
              " 'immigrants',\n",
              " 'wheels',\n",
              " 'playoff',\n",
              " 'Zealand',\n",
              " 'Prize-winning',\n",
              " 'audacity',\n",
              " 'Guillermo',\n",
              " '17',\n",
              " 'vs',\n",
              " 'turnover',\n",
              " 'utterly',\n",
              " 'Bremen',\n",
              " 'socialism',\n",
              " 'Soccer',\n",
              " '06/01',\n",
              " 'arson',\n",
              " 'demonstrations',\n",
              " 'commit',\n",
              " 'Lotte',\n",
              " '8.2',\n",
              " '531',\n",
              " 'AA+',\n",
              " 'scholar',\n",
              " 'onto',\n",
              " '15.75',\n",
              " '2562.094',\n",
              " 'capped',\n",
              " 'Martinez',\n",
              " 'advisory',\n",
              " '1989',\n",
              " 'Gorre',\n",
              " 'identified',\n",
              " 'adjourned',\n",
              " 'Book',\n",
              " 'Bidzos',\n",
              " 'blasts',\n",
              " 'standby',\n",
              " 'Derrick',\n",
              " 'resort',\n",
              " 'lane',\n",
              " 'Exploitation',\n",
              " 'fo',\n",
              " 'Gaseous',\n",
              " 'anticipated',\n",
              " 'Svetlana',\n",
              " 'pothole',\n",
              " 'restraint',\n",
              " 'Middlesex',\n",
              " 'marched',\n",
              " 'suppliers',\n",
              " 'west',\n",
              " 'Tabarez',\n",
              " 'Pre-election',\n",
              " 'Jonathon',\n",
              " '4:19.762',\n",
              " 'Gobert',\n",
              " 'crashed',\n",
              " 'Bevan',\n",
              " 'ROUTS',\n",
              " 'echoed',\n",
              " 'Benin',\n",
              " 'photograph',\n",
              " 'Magnus',\n",
              " 'FR',\n",
              " 'McAllister',\n",
              " 'Canopic',\n",
              " '2183',\n",
              " '1945',\n",
              " 'causes',\n",
              " 'Throughout',\n",
              " 'DLA',\n",
              " 'hold',\n",
              " 'exclude',\n",
              " 'MEN',\n",
              " '58th',\n",
              " 'HEMISPHERE',\n",
              " 'canoe',\n",
              " 'two-year-old',\n",
              " 'unofficial',\n",
              " 'Caribbean',\n",
              " 'pence',\n",
              " 'also',\n",
              " 'hollow',\n",
              " 'RUN-OUT',\n",
              " 'good-natured',\n",
              " 'oral',\n",
              " '+0.9;+23.6',\n",
              " 'Adnan',\n",
              " 'CNN',\n",
              " 'Tristan',\n",
              " 'league-Australian',\n",
              " 'Esnaider',\n",
              " 'accessible',\n",
              " 'remorse',\n",
              " 'strengthen',\n",
              " 'symbolised',\n",
              " 'outbreak',\n",
              " 'Bombarda',\n",
              " 'passengers',\n",
              " 'corporation',\n",
              " 'Ploiesti',\n",
              " '7.4',\n",
              " 'technology',\n",
              " 'Anderson',\n",
              " 'Madeira',\n",
              " 'scream',\n",
              " 'homeland',\n",
              " 'Hungarian',\n",
              " 'Olazabal',\n",
              " 'contractor',\n",
              " 'Westner',\n",
              " 'adrift',\n",
              " 'Franklin',\n",
              " 'margin',\n",
              " 'terror',\n",
              " 'manages',\n",
              " 'Viciosa',\n",
              " 'VAT',\n",
              " 'inflation',\n",
              " 'kingdom',\n",
              " 'This',\n",
              " 'Prievidza',\n",
              " 'STAVBY',\n",
              " 'rocked',\n",
              " 'Microsystems',\n",
              " '11-15',\n",
              " 'abnout',\n",
              " 'prosecute',\n",
              " 'Championship',\n",
              " '319,600',\n",
              " '1950s',\n",
              " 'TLUMACOV',\n",
              " 'pipes',\n",
              " '8.54',\n",
              " 'Phelan',\n",
              " 'Across',\n",
              " 'belongings',\n",
              " 'strapless',\n",
              " 'barbarity',\n",
              " 'topsoil',\n",
              " 'Harelbeke',\n",
              " 'Coritiba',\n",
              " 'bookable',\n",
              " 'Hutton',\n",
              " '950',\n",
              " 'refugees',\n",
              " 'vowed',\n",
              " 'declining',\n",
              " 'steep',\n",
              " 'NYMEX',\n",
              " '26-29',\n",
              " 'Monrovia',\n",
              " 'Atteveld',\n",
              " 'economically',\n",
              " 'President',\n",
              " '4-8',\n",
              " 'fail',\n",
              " 'Maso',\n",
              " 'So',\n",
              " 'Peacekeepers',\n",
              " 'Cynthia',\n",
              " '285,000',\n",
              " 'Advertising',\n",
              " 'covering',\n",
              " '1997--Ruehe',\n",
              " 'Kontogiannis',\n",
              " 'Reg',\n",
              " 'VfL',\n",
              " 'Ironically',\n",
              " '.439',\n",
              " '0:04',\n",
              " 'habits',\n",
              " 'distributers',\n",
              " 'defeated',\n",
              " 'Erbakan',\n",
              " 'physicist',\n",
              " 'Jolene',\n",
              " 'Q4',\n",
              " 'Afghanistan',\n",
              " 'forcing',\n",
              " 'blame',\n",
              " '280,556',\n",
              " 'Reviewed',\n",
              " 'procedures',\n",
              " 'Lohani',\n",
              " '8.9',\n",
              " 'over',\n",
              " 'moratorium',\n",
              " 'Marchal',\n",
              " 'Girard-Leno',\n",
              " 'Harwood',\n",
              " 'List',\n",
              " 'offences',\n",
              " 'Adrian',\n",
              " '1.126',\n",
              " 'x-Anderlecht',\n",
              " '9,500',\n",
              " 'showcased',\n",
              " 'pays',\n",
              " 'actions',\n",
              " 'German-based',\n",
              " 'Kabariti',\n",
              " 'minority',\n",
              " 'BBB+',\n",
              " 'Swindon',\n",
              " 'KATHIMERINI',\n",
              " 'favor',\n",
              " 'assault',\n",
              " 'Maase',\n",
              " '22,434',\n",
              " 'Wilkinson',\n",
              " 'fruits',\n",
              " 'Greens',\n",
              " 'footing',\n",
              " 'APARTHEID',\n",
              " 'outline',\n",
              " '2.75',\n",
              " 'clarifications',\n",
              " 'veto',\n",
              " 'Karunanidhi',\n",
              " '94.26',\n",
              " 'managerless',\n",
              " '60M',\n",
              " '96/97',\n",
              " 'Charity',\n",
              " 'Kuhn',\n",
              " 'Francois-Rene',\n",
              " 'shuffles',\n",
              " 'MATURITY',\n",
              " 'Leon',\n",
              " '290,000',\n",
              " 'April-July',\n",
              " 'exposed',\n",
              " 'come',\n",
              " 'goalscorers',\n",
              " 'Botham',\n",
              " 'railways',\n",
              " 'Pushpakumara',\n",
              " '20,500',\n",
              " 'felons',\n",
              " 'Auchard',\n",
              " 'lashed',\n",
              " 'Mobbs',\n",
              " '228.7',\n",
              " 'put',\n",
              " 'Eastern',\n",
              " 'indeed',\n",
              " 'FACILITIES',\n",
              " 'watchdog',\n",
              " 'alleges',\n",
              " 'wagons',\n",
              " 'Shinichi',\n",
              " 'Sousa',\n",
              " 'Rayyan',\n",
              " 'powerful',\n",
              " 'oportunity',\n",
              " 'pros',\n",
              " 'His',\n",
              " 'partially',\n",
              " '3.3',\n",
              " '7-2-11-0',\n",
              " 'Brunmayr',\n",
              " 'BOLD',\n",
              " 'Dhahran',\n",
              " 'Hideo',\n",
              " 'm;-0.2yr',\n",
              " '27.482',\n",
              " 'Chimonetos',\n",
              " 'predicted',\n",
              " 'Sofia',\n",
              " '4-28',\n",
              " 'Pool',\n",
              " '203.000',\n",
              " 'besides',\n",
              " 'redistribution',\n",
              " 'Chevron',\n",
              " '15:04.94',\n",
              " 'KTM',\n",
              " '2.3',\n",
              " '94',\n",
              " 'Scottish',\n",
              " 'Ibrahim',\n",
              " 'Suisse',\n",
              " 'Lopez',\n",
              " 'residence',\n",
              " 'Ginebra',\n",
              " 'Limerick',\n",
              " '.405',\n",
              " 'affected',\n",
              " 'dropped',\n",
              " '55,627',\n",
              " 'Archives',\n",
              " 'Amr',\n",
              " 'Miami',\n",
              " 'trading',\n",
              " '1996-08-23',\n",
              " 'news',\n",
              " 'Munton',\n",
              " 'kingdoms',\n",
              " '105',\n",
              " '3.31',\n",
              " '31.6',\n",
              " 'alien-led',\n",
              " 'Mechelen',\n",
              " 'Juergen',\n",
              " 'inject',\n",
              " 'Borussia',\n",
              " 'Benito',\n",
              " 'halls',\n",
              " 'Brunswijk',\n",
              " 'tide',\n",
              " '003',\n",
              " '476/698',\n",
              " 'prft',\n",
              " 'Bogota',\n",
              " 'decides',\n",
              " 'STRAIGHT',\n",
              " '+17',\n",
              " 'Pavin',\n",
              " '23.25',\n",
              " '2,326.00',\n",
              " 'FILING',\n",
              " 'Puebla',\n",
              " 'CHAMPIONS',\n",
              " 'earth',\n",
              " 'baht',\n",
              " 'Decheiver',\n",
              " 'Boo-nee-OL',\n",
              " 'EDBERG',\n",
              " 'Costis',\n",
              " 'Ylonen',\n",
              " 'reduce',\n",
              " 'generates',\n",
              " 'Apple',\n",
              " 'Joyner',\n",
              " '190,000',\n",
              " 'youth',\n",
              " 'Jamaat-i-Islami',\n",
              " '446',\n",
              " 'yield',\n",
              " 'Confederacy',\n",
              " 'Guenter',\n",
              " 'System',\n",
              " 'advising',\n",
              " 'discussion',\n",
              " 'abduction',\n",
              " 'letting',\n",
              " 'leadership',\n",
              " 'Agir',\n",
              " 'OB',\n",
              " 'BANGLADESH',\n",
              " 'North',\n",
              " 'nearest',\n",
              " 'lined',\n",
              " 'Indian-ruled',\n",
              " 'worse',\n",
              " 'railway',\n",
              " 'Sammy',\n",
              " 'three',\n",
              " 'leftist',\n",
              " 'Szonn',\n",
              " 'Andrea',\n",
              " 'supermodel',\n",
              " 'Hasan',\n",
              " 'Ezer',\n",
              " 'its',\n",
              " '2067',\n",
              " 'SLOVAK',\n",
              " 'caves',\n",
              " 'Kilmarnock',\n",
              " 'Rinaldi',\n",
              " 'Associates',\n",
              " 'mutilated',\n",
              " 'analysts',\n",
              " 'physiology',\n",
              " '28-36C',\n",
              " 'estimated',\n",
              " 'CONSENSUS',\n",
              " 'plugs',\n",
              " 'recommend',\n",
              " 'insisted',\n",
              " 'bars',\n",
              " 'open',\n",
              " 'Valentin',\n",
              " 'Leeds',\n",
              " 'Kassala',\n",
              " 'internationally-sponsored',\n",
              " 'Harte',\n",
              " 'pole',\n",
              " 'actively',\n",
              " \"'ll\",\n",
              " 'penfriend',\n",
              " 'OLAZABAL',\n",
              " 'uncontrolled',\n",
              " '918,288',\n",
              " 'Lidl',\n",
              " 'Several',\n",
              " 'useful',\n",
              " 'composite',\n",
              " 'Calcutta',\n",
              " 'Interpol',\n",
              " 'Nuclear',\n",
              " '1990s',\n",
              " 'Reserve',\n",
              " 'Exiled',\n",
              " '25.10',\n",
              " 'settling',\n",
              " 'committing',\n",
              " 'WEN',\n",
              " 'treatments',\n",
              " 'IFOR',\n",
              " 'buyback',\n",
              " 'MONTH',\n",
              " 'answers',\n",
              " 'rupees',\n",
              " 'riverways',\n",
              " '0.4-0-9-0',\n",
              " 'one-time',\n",
              " 'three-hitter',\n",
              " 'SLIDE',\n",
              " 'criminal',\n",
              " 'Marcos',\n",
              " 'Nothing',\n",
              " 'coasted',\n",
              " '.522',\n",
              " 'NEED',\n",
              " 'Income',\n",
              " 'Prasad',\n",
              " 'MATIN',\n",
              " 'stole',\n",
              " 'starting',\n",
              " 'parred',\n",
              " '95',\n",
              " 'allegedly',\n",
              " 'Rakow',\n",
              " '29th-ranked',\n",
              " '37.2',\n",
              " 'none',\n",
              " '+18.3',\n",
              " 'Texas',\n",
              " 'tobacco',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = {word for data in train_data for sub_dict in data for word in [sub_dict['word']]}"
      ],
      "metadata": {
        "id": "mqSSepQrjKE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWe_6ODkkM39",
        "outputId": "5f675715-ef37-43e7-9b37-954cdd01beef",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nose',\n",
              " 'Assoc',\n",
              " 'Germain',\n",
              " '2.777',\n",
              " 'Brown',\n",
              " 'campaigning',\n",
              " 'SARAJEVO',\n",
              " '1,429',\n",
              " 'colourful',\n",
              " 'PNW',\n",
              " '12,900-13,150',\n",
              " 'Finally',\n",
              " 'Atlanta',\n",
              " 'yorker',\n",
              " 'Bonds',\n",
              " '48,000',\n",
              " 'MS',\n",
              " '1995',\n",
              " 'Bunge',\n",
              " '4.38',\n",
              " '33969650',\n",
              " 'Roda',\n",
              " 'speculated',\n",
              " 'necessary',\n",
              " 'rules',\n",
              " 'Watanabe',\n",
              " 'single-digits',\n",
              " 'Firearms',\n",
              " 'Flemming',\n",
              " 'street-level',\n",
              " 'Hubner',\n",
              " 'Les',\n",
              " 'consolidating',\n",
              " 'Freedom',\n",
              " 'communism',\n",
              " 'infections',\n",
              " 'explained',\n",
              " 'Optimised',\n",
              " 'Leonard',\n",
              " 'passes',\n",
              " 'newly-established',\n",
              " 'Economic',\n",
              " 'tough',\n",
              " 'anti-',\n",
              " 'November',\n",
              " 'confiscation',\n",
              " 'Welspun',\n",
              " 'board',\n",
              " 'injection',\n",
              " '50',\n",
              " 'secondary',\n",
              " 'reports',\n",
              " 'Lavaggi',\n",
              " 'Elections',\n",
              " 'Malik',\n",
              " 'Put',\n",
              " 'Actor',\n",
              " 'engaging',\n",
              " 'vouch',\n",
              " '13',\n",
              " 'sedan',\n",
              " 'volunteers',\n",
              " 'method',\n",
              " 'Lt.',\n",
              " 'Non-Callable',\n",
              " 'races',\n",
              " 'burned',\n",
              " '482-1003',\n",
              " 'nine-to-one',\n",
              " 'Displaced',\n",
              " '.Giuseppe',\n",
              " 'inflamation',\n",
              " '1,196',\n",
              " 'texts',\n",
              " 'Gillian',\n",
              " 'Beryllium',\n",
              " 'roadblocks',\n",
              " 'Jill',\n",
              " 'front-page',\n",
              " 'Strategic',\n",
              " 'Hanover',\n",
              " '1996-08-26',\n",
              " '3-167',\n",
              " '10-12',\n",
              " 'Recriminations',\n",
              " 'sucks',\n",
              " '49.83',\n",
              " 'interview',\n",
              " 'undergo',\n",
              " 'Midwest',\n",
              " 'installation',\n",
              " 'BVSC',\n",
              " 'Jonty',\n",
              " 'peaked',\n",
              " '17,000',\n",
              " '12.',\n",
              " 'Yelena',\n",
              " 'Popular',\n",
              " '117.00',\n",
              " 'kidding',\n",
              " 'Equivalents',\n",
              " 'Musa',\n",
              " 'emptied',\n",
              " 'Tauziat',\n",
              " 'handles',\n",
              " 'Major-General',\n",
              " '32.3',\n",
              " 'Junior',\n",
              " '758',\n",
              " '11-year-old',\n",
              " 'Gunda',\n",
              " 'marksmen',\n",
              " 'Adem',\n",
              " 'Knoroz',\n",
              " '9000',\n",
              " 'cancer',\n",
              " 'venue',\n",
              " 'HAT-TRICK',\n",
              " 'consumer',\n",
              " 'Kieran',\n",
              " '19999.777',\n",
              " 'MBIA',\n",
              " '1.0',\n",
              " 'modem',\n",
              " 'tipped',\n",
              " 'parents',\n",
              " 'equality',\n",
              " 'collectivisation',\n",
              " 'unwinding',\n",
              " '1.00',\n",
              " 'tbf',\n",
              " 'Rittner',\n",
              " 'SORENSEN',\n",
              " 'precedence',\n",
              " 'England-based',\n",
              " 'disappoint',\n",
              " 'Elephants',\n",
              " 'Montolio',\n",
              " 'DNS',\n",
              " '568',\n",
              " 'Shabwa',\n",
              " '141',\n",
              " 'fashion',\n",
              " 'CRAWLEY',\n",
              " '2009',\n",
              " 'broader',\n",
              " '6603377',\n",
              " 'O-157',\n",
              " 'gifts',\n",
              " 'surveillance',\n",
              " 'Gabon',\n",
              " 'Waqar',\n",
              " 'race',\n",
              " 'Apertura',\n",
              " '1:53.067',\n",
              " 'unfortunate',\n",
              " 'cents',\n",
              " 'dressed',\n",
              " 'locals',\n",
              " '10.14',\n",
              " '605M',\n",
              " '3M',\n",
              " 'dislodge',\n",
              " 'Roy',\n",
              " 'quadrangular',\n",
              " 'propaganda',\n",
              " 'contributed',\n",
              " 'delay',\n",
              " 'Blakey',\n",
              " '13-15',\n",
              " 'MANAGUA',\n",
              " 'runner',\n",
              " 'AUTHORITY',\n",
              " '26-year-old',\n",
              " 'Frana',\n",
              " '97.79',\n",
              " '14-pct',\n",
              " 'Gcaleka',\n",
              " 'GENERAL',\n",
              " 'Rikl',\n",
              " '120.5',\n",
              " 'flames',\n",
              " 'Masayoshi',\n",
              " '45.48',\n",
              " 'Course',\n",
              " 'misfortune',\n",
              " 'rallying',\n",
              " 'eighth',\n",
              " '782.6',\n",
              " 'senior',\n",
              " 'Motorola',\n",
              " 'primarily',\n",
              " 'PSC',\n",
              " 'encamped',\n",
              " 'rejoined',\n",
              " '1.4789',\n",
              " 'Swe',\n",
              " '---------------------',\n",
              " 'Caldwell',\n",
              " '3024.95',\n",
              " 'fine',\n",
              " '9251-274757',\n",
              " 'especially',\n",
              " '173',\n",
              " 'Chenab',\n",
              " '1992-95',\n",
              " 'unsettled',\n",
              " 'TOSS',\n",
              " '25-6-95-4',\n",
              " '5.1700',\n",
              " 'conversion',\n",
              " '199',\n",
              " 'pedestrain',\n",
              " 'Eksportfinans',\n",
              " '144',\n",
              " 'ALEXANDROUPOLIS',\n",
              " '1:50.858',\n",
              " 'switched',\n",
              " 'Luo',\n",
              " 'spoken',\n",
              " 'LOSE',\n",
              " '.573',\n",
              " 'Universities',\n",
              " 'registering',\n",
              " '16.75',\n",
              " 'Children',\n",
              " 'Artur',\n",
              " 'determination',\n",
              " '21.08',\n",
              " '76.6',\n",
              " 'McPherson',\n",
              " 'parts',\n",
              " '4-205',\n",
              " 'roadblock',\n",
              " 'VfB',\n",
              " 'Golf',\n",
              " 'Minister',\n",
              " 'Burundi-Central',\n",
              " 'kilo',\n",
              " 'once',\n",
              " 'Vass',\n",
              " '49.31',\n",
              " 'front-line',\n",
              " 'hurdler',\n",
              " 'middle',\n",
              " 'discharge',\n",
              " '12.130',\n",
              " 'absolute',\n",
              " 'Oklahoma',\n",
              " 'TRUTH',\n",
              " 'medium-term',\n",
              " 'CENTER',\n",
              " 'PMC-Sierra',\n",
              " 'Easley',\n",
              " 'Marcel',\n",
              " 'Gil',\n",
              " 'in-house',\n",
              " 'Ajaccio',\n",
              " 'Regan',\n",
              " 'tries',\n",
              " 'plan',\n",
              " 'upright',\n",
              " '212.00',\n",
              " 'Ababa',\n",
              " 'guards',\n",
              " 'expect',\n",
              " 'demilitarised',\n",
              " 'Vancouver-based',\n",
              " 'Ojanen',\n",
              " 'Pot',\n",
              " 'Simeonov',\n",
              " 'harder',\n",
              " '50-cent',\n",
              " 'performed',\n",
              " 'acrimonious',\n",
              " 'YR',\n",
              " '58.92',\n",
              " 'attributed',\n",
              " '1.84',\n",
              " 'independence',\n",
              " 'Khalaf',\n",
              " 'steady',\n",
              " 'Dutroux',\n",
              " 'one-run',\n",
              " 'Muscular',\n",
              " 'TNT',\n",
              " 'RIA',\n",
              " 'reportedly',\n",
              " 'Six',\n",
              " 'reassure',\n",
              " 'Lausanne',\n",
              " 'decomposed',\n",
              " 'in-form',\n",
              " 'Dejan',\n",
              " '4.7200',\n",
              " 'hard-pressed',\n",
              " 'three-engine',\n",
              " 'submissions',\n",
              " 'recalled',\n",
              " 'FTSE-100',\n",
              " 'dying',\n",
              " 'Beachcomber',\n",
              " 'snatched',\n",
              " 'fund',\n",
              " '7',\n",
              " '6.03',\n",
              " 'MUNDO',\n",
              " 'horses',\n",
              " 'Fox',\n",
              " 'trimmed',\n",
              " 'overnight',\n",
              " 'Karen',\n",
              " 'Aggregate',\n",
              " 'sectarian',\n",
              " 'mid-twenties',\n",
              " '285',\n",
              " 'Dnevi',\n",
              " 'NATO-led',\n",
              " 'bronze',\n",
              " 'expand',\n",
              " '0.86',\n",
              " 'picked',\n",
              " 'photographs',\n",
              " '4:26.467',\n",
              " 'Siofok',\n",
              " 'superstar',\n",
              " '1-0',\n",
              " 'Cruyff',\n",
              " 'filing',\n",
              " 'fruit',\n",
              " 'finalists',\n",
              " '409',\n",
              " 'Prior',\n",
              " 'Markets',\n",
              " 'dipping',\n",
              " 'moral',\n",
              " 'Shanghai',\n",
              " 'trials',\n",
              " 'Nairobi',\n",
              " 'architect',\n",
              " 'weakness',\n",
              " 'Wyborcza',\n",
              " 'Semerdjieva',\n",
              " 'green',\n",
              " 'Baird',\n",
              " '12-1',\n",
              " 'store',\n",
              " 'Leopold',\n",
              " 'opium',\n",
              " 'b-6',\n",
              " 'BOND',\n",
              " 'findings',\n",
              " '0-1',\n",
              " 'incredulous',\n",
              " '251/06',\n",
              " 'TM',\n",
              " '25-30',\n",
              " 'compromise',\n",
              " '11,500',\n",
              " 'Gordon',\n",
              " '1964',\n",
              " '988.2',\n",
              " 'Americast',\n",
              " 'Italo',\n",
              " '1900',\n",
              " 'tube',\n",
              " 'Pizzichini',\n",
              " 'confessing',\n",
              " 'eventual',\n",
              " '3:54.57',\n",
              " 'Salomon',\n",
              " '4.46',\n",
              " 'shortage',\n",
              " '4-334',\n",
              " 'earth-shattering',\n",
              " 'Fenerbahce',\n",
              " 'Bessemer',\n",
              " 'Siebens',\n",
              " '1947-48',\n",
              " 'first-time',\n",
              " 'Campora',\n",
              " '211',\n",
              " 'LITTLE',\n",
              " 'children',\n",
              " 'north-west',\n",
              " 'Terence',\n",
              " 'telephone',\n",
              " 'peacefully',\n",
              " 'Bagwell',\n",
              " 'Detroux',\n",
              " 'ENHANCEMENTS',\n",
              " '2:29.66',\n",
              " 'bowed',\n",
              " '2,386',\n",
              " 'say',\n",
              " 'nb-3',\n",
              " 'library',\n",
              " 'FORMULA',\n",
              " 'Mrs.',\n",
              " 'FORECAST',\n",
              " 'Berlusconi',\n",
              " 'Kongsvinger',\n",
              " 'orderly',\n",
              " 'hall',\n",
              " '252',\n",
              " 'Wengert',\n",
              " 'spiritually',\n",
              " '39.',\n",
              " 'CAREER',\n",
              " '10-0-59-1',\n",
              " 'Jerry',\n",
              " 'took',\n",
              " 'callers',\n",
              " 'explicit',\n",
              " 'ascribed',\n",
              " 'IMF-hosted',\n",
              " 'were',\n",
              " 'concrete',\n",
              " 'marvelling',\n",
              " 'Becker',\n",
              " 'reverts',\n",
              " 'details',\n",
              " 'gangland-style',\n",
              " 'throat',\n",
              " 'sanctions',\n",
              " 'acquisitions',\n",
              " 'Pedersen',\n",
              " 'registry',\n",
              " 'Isbank',\n",
              " 'Reina',\n",
              " 'Makinen',\n",
              " 'Arrows',\n",
              " 'deliberately',\n",
              " 'Galarraga',\n",
              " 'IPE',\n",
              " 'Bradley',\n",
              " 'polls',\n",
              " 'clinched',\n",
              " 'steamrollered',\n",
              " 'shake',\n",
              " 'Ludmila',\n",
              " 'minimise',\n",
              " 'empower',\n",
              " 'Saudi',\n",
              " 'Cometra',\n",
              " 'Coltart',\n",
              " 'GAZA',\n",
              " 'note',\n",
              " 'deficit',\n",
              " 'usually',\n",
              " 'fired',\n",
              " '.623',\n",
              " 'Last-minute',\n",
              " 'impact',\n",
              " 'Chernyavskaya',\n",
              " 'capturing',\n",
              " 'Nobilo',\n",
              " 'stockpile',\n",
              " 'Fernandez',\n",
              " 'financed',\n",
              " 'Annette',\n",
              " 'Eau',\n",
              " 'reporting',\n",
              " 'Albanian-born',\n",
              " 'rampage',\n",
              " '10.19',\n",
              " 'Duvillard',\n",
              " 'Greer',\n",
              " 'Pietro',\n",
              " 'outscored',\n",
              " 'Neuchatel',\n",
              " 'Stocher',\n",
              " 'thigh',\n",
              " 'cup',\n",
              " 'Lugo',\n",
              " 'raging',\n",
              " 'crane',\n",
              " 'Described',\n",
              " 'ONE-DAY',\n",
              " 'big',\n",
              " 'reopen',\n",
              " 'BankWatch',\n",
              " 'Bedouin',\n",
              " 'Okada',\n",
              " 'Ranatunga',\n",
              " 'Bangkok',\n",
              " 'No1',\n",
              " 'kidney',\n",
              " 'contribution',\n",
              " 'necessitate',\n",
              " 'Caucasus',\n",
              " 'scared',\n",
              " '5th',\n",
              " 'Bulgarians',\n",
              " 'culprit',\n",
              " 'Chandrika',\n",
              " 'standings',\n",
              " 'detect',\n",
              " 'safeguarded',\n",
              " \"O'Sullivan\",\n",
              " '226-1',\n",
              " 'Arabised',\n",
              " 'deteriorating',\n",
              " 'degrading',\n",
              " '39',\n",
              " 'million',\n",
              " 'Economy',\n",
              " 'mixture',\n",
              " 'liberalising',\n",
              " 'second-placed',\n",
              " 'confronting',\n",
              " '1952',\n",
              " 'Organisation',\n",
              " '6179',\n",
              " 'Premiership',\n",
              " 'developers',\n",
              " 'Oakland',\n",
              " 'stationery',\n",
              " '0900',\n",
              " 'OM',\n",
              " '1464/96',\n",
              " 'gratitude',\n",
              " 'reinforced',\n",
              " 'Malekos',\n",
              " 'quiet',\n",
              " 'vice-president',\n",
              " '5,539',\n",
              " 'Hassan',\n",
              " 'Angeles',\n",
              " 'pumps',\n",
              " 'Waldorf',\n",
              " '36th',\n",
              " '3-0-17-0',\n",
              " 'QUENCH',\n",
              " 'LOSS',\n",
              " 'recognised',\n",
              " 'post-mortem',\n",
              " 'Banfield',\n",
              " 'Chabora',\n",
              " '45.67',\n",
              " '570M',\n",
              " 'theologian',\n",
              " '351',\n",
              " 'removing',\n",
              " '65-56',\n",
              " 'Ssangbangwool',\n",
              " 'District',\n",
              " 'theme',\n",
              " 'repaid',\n",
              " 'skilful',\n",
              " 'commitments',\n",
              " 'Berkshire',\n",
              " 'waged',\n",
              " 'Theodore',\n",
              " '63.48',\n",
              " 'coal-mining',\n",
              " 'laid',\n",
              " 'Ferrigato',\n",
              " 'en',\n",
              " 'immigrants',\n",
              " 'wheels',\n",
              " 'playoff',\n",
              " 'Zealand',\n",
              " 'Prize-winning',\n",
              " 'audacity',\n",
              " 'Guillermo',\n",
              " '17',\n",
              " 'vs',\n",
              " 'turnover',\n",
              " 'utterly',\n",
              " 'Bremen',\n",
              " 'socialism',\n",
              " 'Soccer',\n",
              " '06/01',\n",
              " 'arson',\n",
              " 'demonstrations',\n",
              " 'commit',\n",
              " 'Lotte',\n",
              " '8.2',\n",
              " '531',\n",
              " 'AA+',\n",
              " 'scholar',\n",
              " 'onto',\n",
              " '15.75',\n",
              " '2562.094',\n",
              " 'capped',\n",
              " 'Martinez',\n",
              " 'advisory',\n",
              " '1989',\n",
              " 'Gorre',\n",
              " 'identified',\n",
              " 'adjourned',\n",
              " 'Book',\n",
              " 'Bidzos',\n",
              " 'blasts',\n",
              " 'standby',\n",
              " 'Derrick',\n",
              " 'resort',\n",
              " 'lane',\n",
              " 'Exploitation',\n",
              " 'fo',\n",
              " 'Gaseous',\n",
              " 'anticipated',\n",
              " 'Svetlana',\n",
              " 'pothole',\n",
              " 'restraint',\n",
              " 'Middlesex',\n",
              " 'marched',\n",
              " 'suppliers',\n",
              " 'west',\n",
              " 'Tabarez',\n",
              " 'Pre-election',\n",
              " 'Jonathon',\n",
              " '4:19.762',\n",
              " 'Gobert',\n",
              " 'crashed',\n",
              " 'Bevan',\n",
              " 'ROUTS',\n",
              " 'echoed',\n",
              " 'Benin',\n",
              " 'photograph',\n",
              " 'Magnus',\n",
              " 'FR',\n",
              " 'McAllister',\n",
              " 'Canopic',\n",
              " '2183',\n",
              " '1945',\n",
              " 'causes',\n",
              " 'Throughout',\n",
              " 'DLA',\n",
              " 'hold',\n",
              " 'exclude',\n",
              " 'MEN',\n",
              " '58th',\n",
              " 'HEMISPHERE',\n",
              " 'canoe',\n",
              " 'two-year-old',\n",
              " 'unofficial',\n",
              " 'Caribbean',\n",
              " 'pence',\n",
              " 'also',\n",
              " 'hollow',\n",
              " 'RUN-OUT',\n",
              " 'good-natured',\n",
              " 'oral',\n",
              " '+0.9;+23.6',\n",
              " 'Adnan',\n",
              " 'CNN',\n",
              " 'Tristan',\n",
              " 'league-Australian',\n",
              " 'Esnaider',\n",
              " 'accessible',\n",
              " 'remorse',\n",
              " 'strengthen',\n",
              " 'symbolised',\n",
              " 'outbreak',\n",
              " 'Bombarda',\n",
              " 'passengers',\n",
              " 'corporation',\n",
              " 'Ploiesti',\n",
              " '7.4',\n",
              " 'technology',\n",
              " 'Anderson',\n",
              " 'Madeira',\n",
              " 'scream',\n",
              " 'homeland',\n",
              " 'Hungarian',\n",
              " 'Olazabal',\n",
              " 'contractor',\n",
              " 'Westner',\n",
              " 'adrift',\n",
              " 'Franklin',\n",
              " 'margin',\n",
              " 'terror',\n",
              " 'manages',\n",
              " 'Viciosa',\n",
              " 'VAT',\n",
              " 'inflation',\n",
              " 'kingdom',\n",
              " 'This',\n",
              " 'Prievidza',\n",
              " 'STAVBY',\n",
              " 'rocked',\n",
              " 'Microsystems',\n",
              " '11-15',\n",
              " 'abnout',\n",
              " 'prosecute',\n",
              " 'Championship',\n",
              " '319,600',\n",
              " '1950s',\n",
              " 'TLUMACOV',\n",
              " 'pipes',\n",
              " '8.54',\n",
              " 'Phelan',\n",
              " 'Across',\n",
              " 'belongings',\n",
              " 'strapless',\n",
              " 'barbarity',\n",
              " 'topsoil',\n",
              " 'Harelbeke',\n",
              " 'Coritiba',\n",
              " 'bookable',\n",
              " 'Hutton',\n",
              " '950',\n",
              " 'refugees',\n",
              " 'vowed',\n",
              " 'declining',\n",
              " 'steep',\n",
              " 'NYMEX',\n",
              " '26-29',\n",
              " 'Monrovia',\n",
              " 'Atteveld',\n",
              " 'economically',\n",
              " 'President',\n",
              " '4-8',\n",
              " 'fail',\n",
              " 'Maso',\n",
              " 'So',\n",
              " 'Peacekeepers',\n",
              " 'Cynthia',\n",
              " '285,000',\n",
              " 'Advertising',\n",
              " 'covering',\n",
              " '1997--Ruehe',\n",
              " 'Kontogiannis',\n",
              " 'Reg',\n",
              " 'VfL',\n",
              " 'Ironically',\n",
              " '.439',\n",
              " '0:04',\n",
              " 'habits',\n",
              " 'distributers',\n",
              " 'defeated',\n",
              " 'Erbakan',\n",
              " 'physicist',\n",
              " 'Jolene',\n",
              " 'Q4',\n",
              " 'Afghanistan',\n",
              " 'forcing',\n",
              " 'blame',\n",
              " '280,556',\n",
              " 'Reviewed',\n",
              " 'procedures',\n",
              " 'Lohani',\n",
              " '8.9',\n",
              " 'over',\n",
              " 'moratorium',\n",
              " 'Marchal',\n",
              " 'Girard-Leno',\n",
              " 'Harwood',\n",
              " 'List',\n",
              " 'offences',\n",
              " 'Adrian',\n",
              " '1.126',\n",
              " 'x-Anderlecht',\n",
              " '9,500',\n",
              " 'showcased',\n",
              " 'pays',\n",
              " 'actions',\n",
              " 'German-based',\n",
              " 'Kabariti',\n",
              " 'minority',\n",
              " 'BBB+',\n",
              " 'Swindon',\n",
              " 'KATHIMERINI',\n",
              " 'favor',\n",
              " 'assault',\n",
              " 'Maase',\n",
              " '22,434',\n",
              " 'Wilkinson',\n",
              " 'fruits',\n",
              " 'Greens',\n",
              " 'footing',\n",
              " 'APARTHEID',\n",
              " 'outline',\n",
              " '2.75',\n",
              " 'clarifications',\n",
              " 'veto',\n",
              " 'Karunanidhi',\n",
              " '94.26',\n",
              " 'managerless',\n",
              " '60M',\n",
              " '96/97',\n",
              " 'Charity',\n",
              " 'Kuhn',\n",
              " 'Francois-Rene',\n",
              " 'shuffles',\n",
              " 'MATURITY',\n",
              " 'Leon',\n",
              " '290,000',\n",
              " 'April-July',\n",
              " 'exposed',\n",
              " 'come',\n",
              " 'goalscorers',\n",
              " 'Botham',\n",
              " 'railways',\n",
              " 'Pushpakumara',\n",
              " '20,500',\n",
              " 'felons',\n",
              " 'Auchard',\n",
              " 'lashed',\n",
              " 'Mobbs',\n",
              " '228.7',\n",
              " 'put',\n",
              " 'Eastern',\n",
              " 'indeed',\n",
              " 'FACILITIES',\n",
              " 'watchdog',\n",
              " 'alleges',\n",
              " 'wagons',\n",
              " 'Shinichi',\n",
              " 'Sousa',\n",
              " 'Rayyan',\n",
              " 'powerful',\n",
              " 'oportunity',\n",
              " 'pros',\n",
              " 'His',\n",
              " 'partially',\n",
              " '3.3',\n",
              " '7-2-11-0',\n",
              " 'Brunmayr',\n",
              " 'BOLD',\n",
              " 'Dhahran',\n",
              " 'Hideo',\n",
              " 'm;-0.2yr',\n",
              " '27.482',\n",
              " 'Chimonetos',\n",
              " 'predicted',\n",
              " 'Sofia',\n",
              " '4-28',\n",
              " 'Pool',\n",
              " '203.000',\n",
              " 'besides',\n",
              " 'redistribution',\n",
              " 'Chevron',\n",
              " '15:04.94',\n",
              " 'KTM',\n",
              " '2.3',\n",
              " '94',\n",
              " 'Scottish',\n",
              " 'Ibrahim',\n",
              " 'Suisse',\n",
              " 'Lopez',\n",
              " 'residence',\n",
              " 'Ginebra',\n",
              " 'Limerick',\n",
              " '.405',\n",
              " 'affected',\n",
              " 'dropped',\n",
              " '55,627',\n",
              " 'Archives',\n",
              " 'Amr',\n",
              " 'Miami',\n",
              " 'trading',\n",
              " '1996-08-23',\n",
              " 'news',\n",
              " 'Munton',\n",
              " 'kingdoms',\n",
              " '105',\n",
              " '3.31',\n",
              " '31.6',\n",
              " 'alien-led',\n",
              " 'Mechelen',\n",
              " 'Juergen',\n",
              " 'inject',\n",
              " 'Borussia',\n",
              " 'Benito',\n",
              " 'halls',\n",
              " 'Brunswijk',\n",
              " 'tide',\n",
              " '003',\n",
              " '476/698',\n",
              " 'prft',\n",
              " 'Bogota',\n",
              " 'decides',\n",
              " 'STRAIGHT',\n",
              " '+17',\n",
              " 'Pavin',\n",
              " '23.25',\n",
              " '2,326.00',\n",
              " 'FILING',\n",
              " 'Puebla',\n",
              " 'CHAMPIONS',\n",
              " 'earth',\n",
              " 'baht',\n",
              " 'Decheiver',\n",
              " 'Boo-nee-OL',\n",
              " 'EDBERG',\n",
              " 'Costis',\n",
              " 'Ylonen',\n",
              " 'reduce',\n",
              " 'generates',\n",
              " 'Apple',\n",
              " 'Joyner',\n",
              " '190,000',\n",
              " 'youth',\n",
              " 'Jamaat-i-Islami',\n",
              " '446',\n",
              " 'yield',\n",
              " 'Confederacy',\n",
              " 'Guenter',\n",
              " 'System',\n",
              " 'advising',\n",
              " 'discussion',\n",
              " 'abduction',\n",
              " 'letting',\n",
              " 'leadership',\n",
              " 'Agir',\n",
              " 'OB',\n",
              " 'BANGLADESH',\n",
              " 'North',\n",
              " 'nearest',\n",
              " 'lined',\n",
              " 'Indian-ruled',\n",
              " 'worse',\n",
              " 'railway',\n",
              " 'Sammy',\n",
              " 'three',\n",
              " 'leftist',\n",
              " 'Szonn',\n",
              " 'Andrea',\n",
              " 'supermodel',\n",
              " 'Hasan',\n",
              " 'Ezer',\n",
              " 'its',\n",
              " '2067',\n",
              " 'SLOVAK',\n",
              " 'caves',\n",
              " 'Kilmarnock',\n",
              " 'Rinaldi',\n",
              " 'Associates',\n",
              " 'mutilated',\n",
              " 'analysts',\n",
              " 'physiology',\n",
              " '28-36C',\n",
              " 'estimated',\n",
              " 'CONSENSUS',\n",
              " 'plugs',\n",
              " 'recommend',\n",
              " 'insisted',\n",
              " 'bars',\n",
              " 'open',\n",
              " 'Valentin',\n",
              " 'Leeds',\n",
              " 'Kassala',\n",
              " 'internationally-sponsored',\n",
              " 'Harte',\n",
              " 'pole',\n",
              " 'actively',\n",
              " \"'ll\",\n",
              " 'penfriend',\n",
              " 'OLAZABAL',\n",
              " 'uncontrolled',\n",
              " '918,288',\n",
              " 'Lidl',\n",
              " 'Several',\n",
              " 'useful',\n",
              " 'composite',\n",
              " 'Calcutta',\n",
              " 'Interpol',\n",
              " 'Nuclear',\n",
              " '1990s',\n",
              " 'Reserve',\n",
              " 'Exiled',\n",
              " '25.10',\n",
              " 'settling',\n",
              " 'committing',\n",
              " 'WEN',\n",
              " 'treatments',\n",
              " 'IFOR',\n",
              " 'buyback',\n",
              " 'MONTH',\n",
              " 'answers',\n",
              " 'rupees',\n",
              " 'riverways',\n",
              " '0.4-0-9-0',\n",
              " 'one-time',\n",
              " 'three-hitter',\n",
              " 'SLIDE',\n",
              " 'criminal',\n",
              " 'Marcos',\n",
              " 'Nothing',\n",
              " 'coasted',\n",
              " '.522',\n",
              " 'NEED',\n",
              " 'Income',\n",
              " 'Prasad',\n",
              " 'MATIN',\n",
              " 'stole',\n",
              " 'starting',\n",
              " 'parred',\n",
              " '95',\n",
              " 'allegedly',\n",
              " 'Rakow',\n",
              " '29th-ranked',\n",
              " '37.2',\n",
              " 'none',\n",
              " '+18.3',\n",
              " 'Texas',\n",
              " 'tobacco',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sym2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0zyivtkiSxr",
        "outputId": "a7f3bd73-278c-4b69-c078-9966acb8089f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'EU': 0,\n",
              " 'rejects': 1,\n",
              " 'German': 2,\n",
              " 'call': 3,\n",
              " 'to': 4,\n",
              " 'boycott': 5,\n",
              " 'British': 6,\n",
              " 'lamb': 7,\n",
              " '.': 8,\n",
              " 'Peter': 9,\n",
              " 'Blackburn': 10,\n",
              " 'BRUSSELS': 11,\n",
              " '1996-08-22': 12,\n",
              " 'The': 13,\n",
              " 'European': 14,\n",
              " 'Commission': 15,\n",
              " 'said': 16,\n",
              " 'on': 17,\n",
              " 'Thursday': 18,\n",
              " 'it': 19,\n",
              " 'disagreed': 20,\n",
              " 'with': 21,\n",
              " 'advice': 22,\n",
              " 'consumers': 23,\n",
              " 'shun': 24,\n",
              " 'until': 25,\n",
              " 'scientists': 26,\n",
              " 'determine': 27,\n",
              " 'whether': 28,\n",
              " 'mad': 29,\n",
              " 'cow': 30,\n",
              " 'disease': 31,\n",
              " 'can': 32,\n",
              " 'be': 33,\n",
              " 'transmitted': 34,\n",
              " 'sheep': 35,\n",
              " 'Germany': 36,\n",
              " \"'s\": 37,\n",
              " 'representative': 38,\n",
              " 'the': 39,\n",
              " 'Union': 40,\n",
              " 'veterinary': 41,\n",
              " 'committee': 42,\n",
              " 'Werner': 43,\n",
              " 'Zwingmann': 44,\n",
              " 'Wednesday': 45,\n",
              " 'should': 46,\n",
              " 'buy': 47,\n",
              " 'sheepmeat': 48,\n",
              " 'from': 49,\n",
              " 'countries': 50,\n",
              " 'other': 51,\n",
              " 'than': 52,\n",
              " 'Britain': 53,\n",
              " 'scientific': 54,\n",
              " 'was': 55,\n",
              " 'clearer': 56,\n",
              " '\"': 57,\n",
              " 'We': 58,\n",
              " 'do': 59,\n",
              " \"n't\": 60,\n",
              " 'support': 61,\n",
              " 'any': 62,\n",
              " 'such': 63,\n",
              " 'recommendation': 64,\n",
              " 'because': 65,\n",
              " 'we': 66,\n",
              " 'see': 67,\n",
              " 'grounds': 68,\n",
              " 'for': 69,\n",
              " ',': 70,\n",
              " 'chief': 71,\n",
              " 'spokesman': 72,\n",
              " 'Nikolaus': 73,\n",
              " 'van': 74,\n",
              " 'der': 75,\n",
              " 'Pas': 76,\n",
              " 'told': 77,\n",
              " 'a': 78,\n",
              " 'news': 79,\n",
              " 'briefing': 80,\n",
              " 'He': 81,\n",
              " 'further': 82,\n",
              " 'study': 83,\n",
              " 'required': 84,\n",
              " 'and': 85,\n",
              " 'if': 86,\n",
              " 'found': 87,\n",
              " 'that': 88,\n",
              " 'action': 89,\n",
              " 'needed': 90,\n",
              " 'taken': 91,\n",
              " 'by': 92,\n",
              " 'proposal': 93,\n",
              " 'last': 94,\n",
              " 'month': 95,\n",
              " 'Farm': 96,\n",
              " 'Commissioner': 97,\n",
              " 'Franz': 98,\n",
              " 'Fischler': 99,\n",
              " 'ban': 100,\n",
              " 'brains': 101,\n",
              " 'spleens': 102,\n",
              " 'spinal': 103,\n",
              " 'cords': 104,\n",
              " 'human': 105,\n",
              " 'animal': 106,\n",
              " 'food': 107,\n",
              " 'chains': 108,\n",
              " 'highly': 109,\n",
              " 'specific': 110,\n",
              " 'precautionary': 111,\n",
              " 'move': 112,\n",
              " 'protect': 113,\n",
              " 'health': 114,\n",
              " 'proposed': 115,\n",
              " 'EU-wide': 116,\n",
              " 'measures': 117,\n",
              " 'after': 118,\n",
              " 'reports': 119,\n",
              " 'France': 120,\n",
              " 'under': 121,\n",
              " 'laboratory': 122,\n",
              " 'conditions': 123,\n",
              " 'could': 124,\n",
              " 'contract': 125,\n",
              " 'Bovine': 126,\n",
              " 'Spongiform': 127,\n",
              " 'Encephalopathy': 128,\n",
              " '(': 129,\n",
              " 'BSE': 130,\n",
              " ')': 131,\n",
              " '--': 132,\n",
              " 'But': 133,\n",
              " 'agreed': 134,\n",
              " 'review': 135,\n",
              " 'his': 136,\n",
              " 'standing': 137,\n",
              " 'mational': 138,\n",
              " 'officials': 139,\n",
              " 'questioned': 140,\n",
              " 'justified': 141,\n",
              " 'as': 142,\n",
              " 'there': 143,\n",
              " 'only': 144,\n",
              " 'slight': 145,\n",
              " 'risk': 146,\n",
              " 'Spanish': 147,\n",
              " 'Minister': 148,\n",
              " 'Loyola': 149,\n",
              " 'de': 150,\n",
              " 'Palacio': 151,\n",
              " 'had': 152,\n",
              " 'earlier': 153,\n",
              " 'accused': 154,\n",
              " 'at': 155,\n",
              " 'an': 156,\n",
              " 'farm': 157,\n",
              " 'ministers': 158,\n",
              " \"'\": 159,\n",
              " 'meeting': 160,\n",
              " 'of': 161,\n",
              " 'causing': 162,\n",
              " 'unjustified': 163,\n",
              " 'alarm': 164,\n",
              " 'through': 165,\n",
              " 'dangerous': 166,\n",
              " 'generalisation': 167,\n",
              " 'Only': 168,\n",
              " 'backed': 169,\n",
              " 'multidisciplinary': 170,\n",
              " 'committees': 171,\n",
              " 'are': 172,\n",
              " 'due': 173,\n",
              " 're-examine': 174,\n",
              " 'issue': 175,\n",
              " 'early': 176,\n",
              " 'next': 177,\n",
              " 'make': 178,\n",
              " 'recommendations': 179,\n",
              " 'senior': 180,\n",
              " 'Sheep': 181,\n",
              " 'have': 182,\n",
              " 'long': 183,\n",
              " 'been': 184,\n",
              " 'known': 185,\n",
              " 'scrapie': 186,\n",
              " 'brain-wasting': 187,\n",
              " 'similar': 188,\n",
              " 'which': 189,\n",
              " 'is': 190,\n",
              " 'believed': 191,\n",
              " 'transferred': 192,\n",
              " 'cattle': 193,\n",
              " 'feed': 194,\n",
              " 'containing': 195,\n",
              " 'waste': 196,\n",
              " 'farmers': 197,\n",
              " 'denied': 198,\n",
              " 'danger': 199,\n",
              " 'their': 200,\n",
              " 'but': 201,\n",
              " 'expressed': 202,\n",
              " 'concern': 203,\n",
              " 'government': 204,\n",
              " 'avoid': 205,\n",
              " 'might': 206,\n",
              " 'influence': 207,\n",
              " 'across': 208,\n",
              " 'Europe': 209,\n",
              " 'What': 210,\n",
              " 'extremely': 211,\n",
              " 'careful': 212,\n",
              " 'how': 213,\n",
              " 'going': 214,\n",
              " 'take': 215,\n",
              " 'lead': 216,\n",
              " 'Welsh': 217,\n",
              " 'National': 218,\n",
              " 'Farmers': 219,\n",
              " 'NFU': 220,\n",
              " 'chairman': 221,\n",
              " 'John': 222,\n",
              " 'Lloyd': 223,\n",
              " 'Jones': 224,\n",
              " 'BBC': 225,\n",
              " 'radio': 226,\n",
              " 'Bonn': 227,\n",
              " 'has': 228,\n",
              " 'led': 229,\n",
              " 'efforts': 230,\n",
              " 'public': 231,\n",
              " 'consumer': 232,\n",
              " 'confidence': 233,\n",
              " 'collapsed': 234,\n",
              " 'in': 235,\n",
              " 'March': 236,\n",
              " 'report': 237,\n",
              " 'suggested': 238,\n",
              " 'humans': 239,\n",
              " 'illness': 240,\n",
              " 'eating': 241,\n",
              " 'contaminated': 242,\n",
              " 'beef': 243,\n",
              " 'imported': 244,\n",
              " '47,600': 245,\n",
              " 'year': 246,\n",
              " 'nearly': 247,\n",
              " 'half': 248,\n",
              " 'total': 249,\n",
              " 'imports': 250,\n",
              " 'It': 251,\n",
              " 'brought': 252,\n",
              " '4,275': 253,\n",
              " 'tonnes': 254,\n",
              " 'mutton': 255,\n",
              " 'some': 256,\n",
              " '10': 257,\n",
              " 'percent': 258,\n",
              " 'overall': 259,\n",
              " 'Rare': 260,\n",
              " 'Hendrix': 261,\n",
              " 'song': 262,\n",
              " 'draft': 263,\n",
              " 'sells': 264,\n",
              " 'almost': 265,\n",
              " '$': 266,\n",
              " '17,000': 267,\n",
              " 'LONDON': 268,\n",
              " 'A': 269,\n",
              " 'rare': 270,\n",
              " 'handwritten': 271,\n",
              " 'U.S.': 272,\n",
              " 'guitar': 273,\n",
              " 'legend': 274,\n",
              " 'Jimi': 275,\n",
              " 'sold': 276,\n",
              " 'auction': 277,\n",
              " 'late': 278,\n",
              " 'musician': 279,\n",
              " 'favourite': 280,\n",
              " 'possessions': 281,\n",
              " 'Florida': 282,\n",
              " 'restaurant': 283,\n",
              " 'paid': 284,\n",
              " '10,925': 285,\n",
              " 'pounds': 286,\n",
              " '16,935': 287,\n",
              " 'Ai': 288,\n",
              " 'no': 289,\n",
              " 'telling': 290,\n",
              " 'penned': 291,\n",
              " 'piece': 292,\n",
              " 'London': 293,\n",
              " 'hotel': 294,\n",
              " 'stationery': 295,\n",
              " '1966': 296,\n",
              " 'At': 297,\n",
              " 'end': 298,\n",
              " 'January': 299,\n",
              " '1967': 300,\n",
              " 'concert': 301,\n",
              " 'English': 302,\n",
              " 'city': 303,\n",
              " 'Nottingham': 304,\n",
              " 'he': 305,\n",
              " 'threw': 306,\n",
              " 'sheet': 307,\n",
              " 'paper': 308,\n",
              " 'into': 309,\n",
              " 'audience': 310,\n",
              " 'where': 311,\n",
              " 'retrieved': 312,\n",
              " 'fan': 313,\n",
              " 'Buyers': 314,\n",
              " 'also': 315,\n",
              " 'snapped': 316,\n",
              " 'up': 317,\n",
              " '16': 318,\n",
              " 'items': 319,\n",
              " 'were': 320,\n",
              " 'put': 321,\n",
              " 'former': 322,\n",
              " 'girlfriend': 323,\n",
              " 'Kathy': 324,\n",
              " 'Etchingham': 325,\n",
              " 'who': 326,\n",
              " 'lived': 327,\n",
              " 'him': 328,\n",
              " '1969': 329,\n",
              " 'They': 330,\n",
              " 'included': 331,\n",
              " 'black': 332,\n",
              " 'lacquer': 333,\n",
              " 'mother': 334,\n",
              " 'pearl': 335,\n",
              " 'inlaid': 336,\n",
              " 'box': 337,\n",
              " 'used': 338,\n",
              " 'store': 339,\n",
              " 'drugs': 340,\n",
              " 'anonymous': 341,\n",
              " 'Australian': 342,\n",
              " 'purchaser': 343,\n",
              " 'bought': 344,\n",
              " '5,060': 345,\n",
              " '7,845': 346,\n",
              " 'guitarist': 347,\n",
              " 'died': 348,\n",
              " 'overdose': 349,\n",
              " '1970': 350,\n",
              " 'aged': 351,\n",
              " '27': 352,\n",
              " 'China': 353,\n",
              " 'says': 354,\n",
              " 'Taiwan': 355,\n",
              " 'spoils': 356,\n",
              " 'atmosphere': 357,\n",
              " 'talks': 358,\n",
              " 'BEIJING': 359,\n",
              " 'Taipei': 360,\n",
              " 'spoiling': 361,\n",
              " 'resumption': 362,\n",
              " 'Strait': 363,\n",
              " 'visit': 364,\n",
              " 'Ukraine': 365,\n",
              " 'Taiwanese': 366,\n",
              " 'Vice': 367,\n",
              " 'President': 368,\n",
              " 'Lien': 369,\n",
              " 'Chan': 370,\n",
              " 'this': 371,\n",
              " 'week': 372,\n",
              " 'infuriated': 373,\n",
              " 'Beijing': 374,\n",
              " 'Speaking': 375,\n",
              " 'hours': 376,\n",
              " 'Chinese': 377,\n",
              " 'state': 378,\n",
              " 'media': 379,\n",
              " 'time': 380,\n",
              " 'right': 381,\n",
              " 'engage': 382,\n",
              " 'political': 383,\n",
              " 'Foreign': 384,\n",
              " 'Ministry': 385,\n",
              " 'Shen': 386,\n",
              " 'Guofang': 387,\n",
              " 'Reuters': 388,\n",
              " ':': 389,\n",
              " 'necessary': 390,\n",
              " 'opening': 391,\n",
              " 'disrupted': 392,\n",
              " 'authorities': 393,\n",
              " 'State': 394,\n",
              " 'quoted': 395,\n",
              " 'top': 396,\n",
              " 'negotiator': 397,\n",
              " 'Tang': 398,\n",
              " 'Shubei': 399,\n",
              " 'visiting': 400,\n",
              " 'group': 401,\n",
              " 'rivals': 402,\n",
              " 'hold': 403,\n",
              " 'Now': 404,\n",
              " 'two': 405,\n",
              " 'sides': 406,\n",
              " '...': 407,\n",
              " 'hostility': 408,\n",
              " 'overseas': 409,\n",
              " 'edition': 410,\n",
              " 'People': 411,\n",
              " 'Daily': 412,\n",
              " 'saying': 413,\n",
              " 'foreign': 414,\n",
              " 'ministry': 415,\n",
              " 'Television': 416,\n",
              " 'interview': 417,\n",
              " 'read': 418,\n",
              " 'comments': 419,\n",
              " 'gave': 420,\n",
              " 'details': 421,\n",
              " 'why': 422,\n",
              " 'considered': 423,\n",
              " 'considers': 424,\n",
              " 'renegade': 425,\n",
              " 'province': 426,\n",
              " 'opposed': 427,\n",
              " 'all': 428,\n",
              " 'gain': 429,\n",
              " 'greater': 430,\n",
              " 'international': 431,\n",
              " 'recognition': 432,\n",
              " 'rival': 433,\n",
              " 'island': 434,\n",
              " 'practical': 435,\n",
              " 'steps': 436,\n",
              " 'towards': 437,\n",
              " 'goal': 438,\n",
              " 'Consultations': 439,\n",
              " 'held': 440,\n",
              " 'set': 441,\n",
              " 'format': 442,\n",
              " 'official': 443,\n",
              " 'Xinhua': 444,\n",
              " 'agency': 445,\n",
              " 'executive': 446,\n",
              " 'vice': 447,\n",
              " 'Association': 448,\n",
              " 'Relations': 449,\n",
              " 'Across': 450,\n",
              " 'Straits': 451,\n",
              " 'July': 452,\n",
              " 'car': 453,\n",
              " 'registrations': 454,\n",
              " '14.2': 455,\n",
              " 'pct': 456,\n",
              " 'yr': 457,\n",
              " '/': 458,\n",
              " 'FRANKFURT': 459,\n",
              " 'first-time': 460,\n",
              " 'motor': 461,\n",
              " 'vehicles': 462,\n",
              " 'jumped': 463,\n",
              " 'year-earlier': 464,\n",
              " 'period': 465,\n",
              " 'Federal': 466,\n",
              " 'office': 467,\n",
              " '356,725': 468,\n",
              " 'new': 469,\n",
              " 'cars': 470,\n",
              " 'registered': 471,\n",
              " '1996': 472,\n",
              " '304,850': 473,\n",
              " 'passenger': 474,\n",
              " '15,613': 475,\n",
              " 'trucks': 476,\n",
              " 'figures': 477,\n",
              " 'represent': 478,\n",
              " '13.6': 479,\n",
              " 'increase': 480,\n",
              " '2.2': 481,\n",
              " 'decline': 482,\n",
              " '1995': 483,\n",
              " 'Motor-bike': 484,\n",
              " 'registration': 485,\n",
              " 'rose': 486,\n",
              " '32.7': 487,\n",
              " 'growth': 488,\n",
              " 'partly': 489,\n",
              " 'increased': 490,\n",
              " 'number': 491,\n",
              " 'Germans': 492,\n",
              " 'buying': 493,\n",
              " 'abroad': 494,\n",
              " 'while': 495,\n",
              " 'manufacturers': 496,\n",
              " 'domestic': 497,\n",
              " 'demand': 498,\n",
              " 'weak': 499,\n",
              " 'federal': 500,\n",
              " 'Almost': 501,\n",
              " 'posted': 502,\n",
              " 'gains': 503,\n",
              " 'numbers': 504,\n",
              " 'Volkswagen': 505,\n",
              " 'AG': 506,\n",
              " 'won': 507,\n",
              " '77,719': 508,\n",
              " 'slightly': 509,\n",
              " 'more': 510,\n",
              " 'quarter': 511,\n",
              " 'Opel': 512,\n",
              " 'together': 513,\n",
              " 'General': 514,\n",
              " 'Motors': 515,\n",
              " 'came': 516,\n",
              " 'second': 517,\n",
              " 'place': 518,\n",
              " '49,269': 519,\n",
              " '16.4': 520,\n",
              " 'figure': 521,\n",
              " 'Third': 522,\n",
              " 'Ford': 523,\n",
              " '35,563': 524,\n",
              " 'or': 525,\n",
              " '11.7': 526,\n",
              " 'Seat': 527,\n",
              " 'Porsche': 528,\n",
              " 'fewer': 529,\n",
              " 'compared': 530,\n",
              " '3,420': 531,\n",
              " '5522': 532,\n",
              " 'fell': 533,\n",
              " '554': 534,\n",
              " '643': 535,\n",
              " 'GREEK': 536,\n",
              " 'SOCIALISTS': 537,\n",
              " 'GIVE': 538,\n",
              " 'GREEN': 539,\n",
              " 'LIGHT': 540,\n",
              " 'TO': 541,\n",
              " 'PM': 542,\n",
              " 'FOR': 543,\n",
              " 'ELECTIONS': 544,\n",
              " 'ATHENS': 545,\n",
              " 'Greek': 546,\n",
              " 'socialist': 547,\n",
              " 'party': 548,\n",
              " 'bureau': 549,\n",
              " 'green': 550,\n",
              " 'light': 551,\n",
              " 'Prime': 552,\n",
              " 'Costas': 553,\n",
              " 'Simitis': 554,\n",
              " 'snap': 555,\n",
              " 'elections': 556,\n",
              " 'its': 557,\n",
              " 'general': 558,\n",
              " 'secretary': 559,\n",
              " 'Skandalidis': 560,\n",
              " 'reporters': 561,\n",
              " 'announcement': 562,\n",
              " 'cabinet': 563,\n",
              " 'later': 564,\n",
              " 'Dimitris': 565,\n",
              " 'Kontogiannis': 566,\n",
              " 'Athens': 567,\n",
              " 'Newsroom': 568,\n",
              " '+301': 569,\n",
              " '3311812-4': 570,\n",
              " 'BayerVB': 571,\n",
              " 'sets': 572,\n",
              " 'C$': 573,\n",
              " '100': 574,\n",
              " 'million': 575,\n",
              " 'six-year': 576,\n",
              " 'bond': 577,\n",
              " 'following': 578,\n",
              " 'announced': 579,\n",
              " 'manager': 580,\n",
              " 'Toronto': 581,\n",
              " 'Dominion': 582,\n",
              " 'BORROWER': 583,\n",
              " 'BAYERISCHE': 584,\n",
              " 'VEREINSBANK': 585,\n",
              " 'AMT': 586,\n",
              " 'MLN': 587,\n",
              " 'COUPON': 588,\n",
              " '6.625': 589,\n",
              " 'MATURITY': 590,\n",
              " '24.SEP.02': 591,\n",
              " 'TYPE': 592,\n",
              " 'STRAIGHT': 593,\n",
              " 'ISS': 594,\n",
              " 'PRICE': 595,\n",
              " '100.92': 596,\n",
              " 'PAY': 597,\n",
              " 'DATE': 598,\n",
              " '24.SEP.96': 599,\n",
              " 'FULL': 600,\n",
              " 'FEES': 601,\n",
              " '1.875': 602,\n",
              " 'REOFFER': 603,\n",
              " '99.32': 604,\n",
              " 'SPREAD': 605,\n",
              " '+20': 606,\n",
              " 'BP': 607,\n",
              " 'MOODY': 608,\n",
              " 'AA1': 609,\n",
              " 'LISTING': 610,\n",
              " 'LUX': 611,\n",
              " 'FREQ': 612,\n",
              " '=': 613,\n",
              " 'S&P': 614,\n",
              " 'DENOMS': 615,\n",
              " 'K': 616,\n",
              " '1-10-100': 617,\n",
              " 'SALE': 618,\n",
              " 'LIMITS': 619,\n",
              " 'US': 620,\n",
              " 'UK': 621,\n",
              " 'CA': 622,\n",
              " 'NEG': 623,\n",
              " 'PLG': 624,\n",
              " 'NO': 625,\n",
              " 'CRS': 626,\n",
              " 'DEFLT': 627,\n",
              " 'FORCE': 628,\n",
              " 'MAJ': 629,\n",
              " 'GOV': 630,\n",
              " 'LAW': 631,\n",
              " 'GERMAN': 632,\n",
              " 'HOME': 633,\n",
              " 'CTRY': 634,\n",
              " 'TAX': 635,\n",
              " 'PROVS': 636,\n",
              " 'STANDARD': 637,\n",
              " 'MGT': 638,\n",
              " 'UND': 639,\n",
              " '0.275': 640,\n",
              " 'SELL': 641,\n",
              " 'CONC': 642,\n",
              " '1.60': 643,\n",
              " 'PRAECIP': 644,\n",
              " 'UNDERLYING': 645,\n",
              " 'GOVT': 646,\n",
              " 'BOND': 647,\n",
              " '7.0': 648,\n",
              " 'PCT': 649,\n",
              " 'SEPT': 650,\n",
              " '2001': 651,\n",
              " 'NOTES': 652,\n",
              " 'IS': 653,\n",
              " 'JOINT': 654,\n",
              " 'LEAD': 655,\n",
              " 'MANAGER': 656,\n",
              " '+44': 657,\n",
              " '171': 658,\n",
              " '542': 659,\n",
              " '7658': 660,\n",
              " 'Venantius': 661,\n",
              " '300': 662,\n",
              " '1999': 663,\n",
              " 'FRN': 664,\n",
              " 'floating-rate': 665,\n",
              " 'Lehman': 666,\n",
              " 'Brothers': 667,\n",
              " 'International': 668,\n",
              " 'VENANTIUS': 669,\n",
              " 'AB': 670,\n",
              " 'SWEDISH': 671,\n",
              " 'NATIONAL': 672,\n",
              " 'MORTGAGE': 673,\n",
              " 'AGENCY': 674,\n",
              " '-': 675,\n",
              " '12.5': 676,\n",
              " '21.JAN.99': 677,\n",
              " 'BASE': 678,\n",
              " '3M': 679,\n",
              " 'LIBOR': 680,\n",
              " 'S23.SEP.96': 681,\n",
              " 'LAST': 682,\n",
              " 'AA3': 683,\n",
              " '99.956': 684,\n",
              " 'AA+': 685,\n",
              " 'S': 686,\n",
              " 'SHORT': 687,\n",
              " 'FIRST': 688,\n",
              " 'JP': 689,\n",
              " 'FR': 690,\n",
              " 'YES': 691,\n",
              " 'IPMA': 692,\n",
              " '2': 693,\n",
              " 'ENGLISH': 694,\n",
              " 'SWEDEN': 695,\n",
              " '5': 696,\n",
              " 'ISSUED': 697,\n",
              " 'OFF': 698,\n",
              " 'EMTN': 699,\n",
              " 'PROGRAMME': 700,\n",
              " '8863': 701,\n",
              " 'Port': 702,\n",
              " 'update': 703,\n",
              " 'Syria': 704,\n",
              " 'Lloyds': 705,\n",
              " 'Shipping': 706,\n",
              " 'Intelligence': 707,\n",
              " 'Service': 708,\n",
              " 'LATTAKIA': 709,\n",
              " 'Aug': 710,\n",
              " 'waiting': 711,\n",
              " 'Lattakia': 712,\n",
              " 'Tartous': 713,\n",
              " 'presently': 714,\n",
              " '24': 715,\n",
              " 'Israel': 716,\n",
              " 'plays': 717,\n",
              " 'down': 718,\n",
              " 'fears': 719,\n",
              " 'war': 720,\n",
              " 'Colleen': 721,\n",
              " 'Siegel': 722,\n",
              " 'JERUSALEM': 723,\n",
              " 'outgoing': 724,\n",
              " 'peace': 725,\n",
              " 'current': 726,\n",
              " 'tensions': 727,\n",
              " 'between': 728,\n",
              " 'appeared': 729,\n",
              " 'storm': 730,\n",
              " 'teacup': 731,\n",
              " 'Itamar': 732,\n",
              " 'Rabinovich': 733,\n",
              " 'ambassador': 734,\n",
              " 'Washington': 735,\n",
              " 'conducted': 736,\n",
              " 'unfruitful': 737,\n",
              " 'negotiations': 738,\n",
              " 'Radio': 739,\n",
              " 'looked': 740,\n",
              " 'like': 741,\n",
              " 'Damascus': 742,\n",
              " 'wanted': 743,\n",
              " 'talk': 744,\n",
              " 'rather': 745,\n",
              " 'fight': 746,\n",
              " 'appears': 747,\n",
              " 'me': 748,\n",
              " 'Syrian': 749,\n",
              " 'priority': 750,\n",
              " 'still': 751,\n",
              " 'negotiate': 752,\n",
              " 'Syrians': 753,\n",
              " 'confused': 754,\n",
              " 'they': 755,\n",
              " 'definitely': 756,\n",
              " 'tense': 757,\n",
              " 'assessment': 758,\n",
              " 'here': 759,\n",
              " 'essentially': 760,\n",
              " 'winding': 761,\n",
              " 'term': 762,\n",
              " 'will': 763,\n",
              " 'replaced': 764,\n",
              " 'Eliahu': 765,\n",
              " 'Ben-Elissar': 766,\n",
              " 'Israeli': 767,\n",
              " 'envoy': 768,\n",
              " 'Egypt': 769,\n",
              " 'right-wing': 770,\n",
              " 'Likud': 771,\n",
              " 'politician': 772,\n",
              " 'sent': 773,\n",
              " 'message': 774,\n",
              " 'via': 775,\n",
              " 'committed': 776,\n",
              " 'open': 777,\n",
              " 'without': 778,\n",
              " 'preconditions': 779,\n",
              " 'slammed': 780,\n",
              " 'creating': 781,\n",
              " 'what': 782,\n",
              " 'called': 783,\n",
              " 'launching': 784,\n",
              " 'hysterical': 785,\n",
              " 'campaign': 786,\n",
              " 'against': 787,\n",
              " 'television': 788,\n",
              " 'reported': 789,\n",
              " 'recently': 790,\n",
              " 'test': 791,\n",
              " 'fired': 792,\n",
              " 'missile': 793,\n",
              " 'arms': 794,\n",
              " 'purchases': 795,\n",
              " 'defensive': 796,\n",
              " 'purposes': 797,\n",
              " 'Hafez': 798,\n",
              " 'al-': 799,\n",
              " 'Assad': 800,\n",
              " 'ready': 801,\n",
              " 'enter': 802,\n",
              " 'David': 803,\n",
              " 'Levy': 804,\n",
              " 'Tension': 805,\n",
              " 'mounted': 806,\n",
              " 'since': 807,\n",
              " 'Benjamin': 808,\n",
              " 'Netanyahu': 809,\n",
              " 'took': 810,\n",
              " 'June': 811,\n",
              " 'vowing': 812,\n",
              " 'retain': 813,\n",
              " 'Golan': 814,\n",
              " 'Heights': 815,\n",
              " 'captured': 816,\n",
              " 'Middle': 817,\n",
              " 'East': 818,\n",
              " 'Israeli-Syrian': 819,\n",
              " 'deadlocked': 820,\n",
              " 'over': 821,\n",
              " '1991': 822,\n",
              " 'despite': 823,\n",
              " 'previous': 824,\n",
              " 'willingness': 825,\n",
              " 'concessions': 826,\n",
              " 'Peace': 827,\n",
              " 'February': 828,\n",
              " 'voices': 829,\n",
              " 'coming': 830,\n",
              " 'out': 831,\n",
              " 'bad': 832,\n",
              " 'not': 833,\n",
              " 'good': 834,\n",
              " 'full': 835,\n",
              " 'expressions': 836,\n",
              " 'declarations': 837,\n",
              " 'must': 838,\n",
              " 'worrying': 839,\n",
              " 'artificial': 840,\n",
              " 'very': 841,\n",
              " 'those': 842,\n",
              " 'spread': 843,\n",
              " 'become': 844,\n",
              " 'prisoners': 845,\n",
              " 'expect': 846,\n",
              " 'face': 847,\n",
              " 'answer': 848,\n",
              " 'our': 849,\n",
              " 'want': 850,\n",
              " 'God': 851,\n",
              " 'forbid': 852,\n",
              " 'No': 853,\n",
              " 'one': 854,\n",
              " 'benefits': 855,\n",
              " 'wars': 856,\n",
              " 'Channel': 857,\n",
              " 'Two': 858,\n",
              " 'calming': 859,\n",
              " 'signal': 860,\n",
              " 'source': 861,\n",
              " 'spokesmen': 862,\n",
              " 'confirm': 863,\n",
              " 'messages': 864,\n",
              " 'reassure': 865,\n",
              " 'Cairo': 866,\n",
              " 'United': 867,\n",
              " 'States': 868,\n",
              " 'Moscow': 869,\n",
              " 'Polish': 870,\n",
              " 'diplomat': 871,\n",
              " 'denies': 872,\n",
              " 'nurses': 873,\n",
              " 'stranded': 874,\n",
              " 'Libya': 875,\n",
              " 'TUNIS': 876,\n",
              " 'tabloid': 877,\n",
              " 'refusing': 878,\n",
              " 'exit': 879,\n",
              " 'visas': 880,\n",
              " 'trying': 881,\n",
              " 'return': 882,\n",
              " 'home': 883,\n",
              " 'working': 884,\n",
              " 'North': 885,\n",
              " 'African': 886,\n",
              " 'country': 887,\n",
              " 'This': 888,\n",
              " 'true': 889,\n",
              " 'Up': 890,\n",
              " 'today': 891,\n",
              " 'knowledge': 892,\n",
              " 'nurse': 893,\n",
              " 'kept': 894,\n",
              " 'her': 895,\n",
              " 'received': 896,\n",
              " 'complaint': 897,\n",
              " 'embassy': 898,\n",
              " 'charge': 899,\n",
              " \"d'affaires\": 900,\n",
              " 'Tripoli': 901,\n",
              " 'Tadeusz': 902,\n",
              " 'Awdankiewicz': 903,\n",
              " 'telephone': 904,\n",
              " 'Poland': 905,\n",
              " 'labour': 906,\n",
              " 'would': 907,\n",
              " 'send': 908,\n",
              " 'team': 909,\n",
              " 'investigate': 910,\n",
              " 'probe': 911,\n",
              " 'prompted': 912,\n",
              " 'complaining': 913,\n",
              " 'about': 914,\n",
              " 'work': 915,\n",
              " 'non-payment': 916,\n",
              " 'salaries': 917,\n",
              " 'estimated': 918,\n",
              " '800': 919,\n",
              " 'Iranian': 920,\n",
              " 'opposition': 921,\n",
              " 'leaders': 922,\n",
              " 'meet': 923,\n",
              " 'Baghdad': 924,\n",
              " 'Hassan': 925,\n",
              " 'Hafidh': 926,\n",
              " 'BAGHDAD': 927,\n",
              " 'An': 928,\n",
              " 'exile': 929,\n",
              " 'based': 930,\n",
              " 'Iraq': 931,\n",
              " 'vowed': 932,\n",
              " 'extend': 933,\n",
              " 'Iran': 934,\n",
              " 'Kurdish': 935,\n",
              " 'rebels': 936,\n",
              " 'attacked': 937,\n",
              " 'troops': 938,\n",
              " 'deep': 939,\n",
              " 'inside': 940,\n",
              " 'Mujahideen': 941,\n",
              " 'Khalq': 942,\n",
              " 'statement': 943,\n",
              " 'leader': 944,\n",
              " 'Massoud': 945,\n",
              " 'Rajavi': 946,\n",
              " 'met': 947,\n",
              " 'Secretary-General': 948,\n",
              " 'Kurdistan': 949,\n",
              " 'Democratic': 950,\n",
              " 'Party': 951,\n",
              " 'KDPI': 952,\n",
              " 'Rastegar': 953,\n",
              " 'voiced': 954,\n",
              " 'rebel': 955,\n",
              " 'Kurds': 956,\n",
              " 'emphasised': 957,\n",
              " 'Resistance': 958,\n",
              " 'continue': 959,\n",
              " 'stand': 960,\n",
              " 'side': 961,\n",
              " 'compatriots': 962,\n",
              " 'resistance': 963,\n",
              " 'movement': 964,\n",
              " 'signals': 965,\n",
              " 'level': 966,\n",
              " 'cooperation': 967,\n",
              " 'oppositions': 968,\n",
              " 'heavily': 969,\n",
              " 'bombarded': 970,\n",
              " 'targets': 971,\n",
              " 'northern': 972,\n",
              " 'pursuit': 973,\n",
              " 'guerrillas': 974,\n",
              " 'Iraqi': 975,\n",
              " 'areas': 976,\n",
              " 'outside': 977,\n",
              " 'control': 978,\n",
              " 'bordering': 979,\n",
              " 'Patriotic': 980,\n",
              " 'PUK': 981,\n",
              " 'KDP': 982,\n",
              " 'main': 983,\n",
              " 'factions': 984,\n",
              " 'forces': 985,\n",
              " 'ousted': 986,\n",
              " 'Kuwait': 987,\n",
              " 'Gulf': 988,\n",
              " 'War': 989,\n",
              " 'Clashes': 990,\n",
              " 'parties': 991,\n",
              " 'broke': 992,\n",
              " 'weekend': 993,\n",
              " 'most': 994,\n",
              " 'serious': 995,\n",
              " 'fighting': 996,\n",
              " 'U.S.-sponsored': 997,\n",
              " 'ceasefire': 998,\n",
              " 'shelling': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9r8XbqsH8u"
      },
      "source": [
        "def vocabulary(filename,input_vocab,ner,pos,padding='<pad>',unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token\n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "    #TODO : return the two vocabulary maps idx2sym and sym2idx\n",
        "    \"\"\"\n",
        "    input means the vocabulary\n",
        "    output means the tag (ner)\n",
        "    \"\"\"\n",
        "    if input_vocab:\n",
        "      word_data = read_conllu(filename)\n",
        "      words = {sub_dict['word'] for data in word_data for sub_dict in data}\n",
        "    elif ner:\n",
        "      word_data = read_conllu(filename)\n",
        "      words = {sub_dict['ner'] for data in word_data for sub_dict in data}\n",
        "    elif pos:\n",
        "      word_data = read_conllu(filename)\n",
        "      words = {sub_dict['pos'] for data in word_data for sub_dict in data}\n",
        "    # special token, if None\n",
        "    special_tokens = []\n",
        "    if padding is not None:\n",
        "      special_tokens.append(padding)\n",
        "    if unknown is not None:\n",
        "      special_tokens.append(unknown)\n",
        "    idx2sym = special_tokens+list(words)\n",
        "\n",
        "    sym2idx = {word:idx for idx,word in enumerate(idx2sym)}\n",
        "\n",
        "    return sym2idx,idx2sym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M36kJLft0IO"
      },
      "source": [
        "Now we implement three functions:\n",
        "\n",
        "* One that performs padding\n",
        "* The second will encode a sequence of tokens (or a sequence of tags) on integers\n",
        "* The third will decode as sequence of symbols from integers to strings\n",
        "\n",
        "At test time, some tokens might not belong to the vocabulary. Ensure that your encoding function does not crash in this case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV98Rb66uRmz"
      },
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens if needed\n",
        "    if len(sequence) < pad_size:\n",
        "      padding = [pad_token]*(pad_size - len(sequence))\n",
        "      return sequence + padding\n",
        "    return sequence[:pad_size]\n",
        "\n",
        "    # pass\n",
        "\n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    # seq : list\n",
        "    new_seq = []\n",
        "    for token in sequence:\n",
        "      if token in coding_map:\n",
        "        new_seq.append(coding_map[token])\n",
        "      elif unk_token is not None:\n",
        "        new_seq.append(coding_map[unk_token])\n",
        "      else:\n",
        "        # token not in dict, no unk, raise error\n",
        "        raise KeyError(f\"Token {token} not in coding_map, and no unk, please consider set unk to a specific token\")\n",
        "    return new_seq\n",
        "\n",
        "\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings\n",
        "    #decode map idx2sym list\n",
        "    return [decoding_map[idx] for idx in sequence]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj9pkrOv6-xS"
      },
      "source": [
        "Data generator\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJiBNu737Suv"
      },
      "source": [
        "In this second exercise, we will write a mini-batch generator.\n",
        "This is a class in charge of generating randomized batches of data from the dataset. We start by implementing two functions for reading the textfile\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP3mMhU58Lgu"
      },
      "source": [
        "def read_conll_tokens(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    #TODO\n",
        "    sentences_all = []\n",
        "    conllu_data_all = read_conllu(conllfilename)\n",
        "    for sentence_dict in conllu_data_all:\n",
        "      sentence = [sub_dict['word'] for sub_dict in sentence_dict]\n",
        "      sentences_all.append(sentence)\n",
        "\n",
        "    return sentences_all\n",
        "\n",
        "\n",
        "def read_conll_tags(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (NER-tags)\n",
        "    \"\"\"\n",
        "    #TODO\n",
        "    pass\n",
        "\n",
        "    sentences_tags_all = []\n",
        "    conllu_data_all = read_conllu(conllfilename)\n",
        "    for sentence_dict in conllu_data_all:\n",
        "      sentence = [sub_dict['ner'] for sub_dict in sentence_dict]\n",
        "      sentences_tags_all.append(sentence)\n",
        "\n",
        "    return sentences_tags_all\n",
        "\n",
        "#poslayer\n",
        "def read_conll_pos(conllfilename):\n",
        "  \"\"\"\n",
        "  Read a CONLL 2003 file and returns a list of sentences..\n",
        "  A sentence is a list of strings (POS tagging)\n",
        "  \"\"\"\n",
        "  sentences_tags_all = []\n",
        "  conllu_data_all = read_conllu(conllfilename)\n",
        "  for sentence_dict in conllu_data_all:\n",
        "    sentence = [sub_dict['pos'] for sub_dict in sentence_dict]\n",
        "    sentences_tags_all.append(sentence)\n",
        "  return sentences_tags_all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_sentence =[]\n",
        "for sentence_dict in train_data:\n",
        "  sentence = [sub_dict['ner'] for sub_dict in sentence_dict]\n",
        "  train_data_sentence.append(sentence)\n",
        "  break\n",
        "print(train_data_sentence\n",
        "      )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaWtStPZp7Ot",
        "outputId": "dd533fd1-ca25-4c16-ac36-6d5007847e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0QpXfMmQ0xz"
      },
      "source": [
        "\n",
        "\n",
        "Now we implement the class. You will rely on the helper functions designed above in order to fill in the blanks in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol2Hp2rcGNK9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "        #Reuse all relevant helper functions defined above to solve the problems\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx\n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx\n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym\n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  #TODO : Create 4 encoding maps from datafile\n",
        "                  self.input_sym2idx,self.input_idx2sym   = vocabulary(conllfilename,input_vocab=True,ner=False,pos=False)\n",
        "\n",
        "                  self.output_sym2idx,self.output_idx2sym = vocabulary(conllfilename,input_vocab=False,ner=True,pos=False)\n",
        "                  # pass\n",
        "\n",
        "\n",
        "              #TODO : store the conll dataset with sentence structure (a list of lists of strings) in the following fields\n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename)\n",
        "\n",
        "              # pass\n",
        "\n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #This is an example generator function yielding one batch after another\n",
        "              #Batches are lists of lists\n",
        "\n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "\n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #Data ordering (try to explain why these 2 lines make sense...)\n",
        "              \"\"\"\n",
        "              shuffle : will mix all the sentence idx\n",
        "              idxes.sort() will sort all the sentence by its length, that's why if we print seqX, we can always see the sentence that are of length 1 becomes first\n",
        "              short sentence will be assigned to the batch in the beginning, this will save the padding times, improving efficiency\n",
        "              maintain randomness as well as improve model training efficiency\n",
        "              \"\"\"\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend]\n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)\n",
        "\n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx) for seq in seqY]\n",
        "\n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = DataGenerator(\"./eng.train\")\n",
        "####\n",
        "for seqX,seqY in generator.generate_batches(3):\n",
        "  # print(seqX)\n",
        "  X = torch.LongTensor(seqX)\n",
        "  print(X.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xnt9oR9syrt",
        "outputId": "c3acee72-8b56-4aa2-f7f5-9e6ee6aa705e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx,(batch_x,batch_y) in enumerate(generator.generate_batches(20)):\n",
        "  print(batch_x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWhMZALzs8V3",
        "outputId": "5b5e51ba-5e97-48d3-9b5f-0b5304bf40ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4788], [13851], [15358], [685], [4340], [16504], [12388], [22554], [13947], [4903], [529], [19898], [9834], [2921], [5312], [22635], [3062], [10826], [2761], [10826]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpt98v1US9-t"
      },
      "source": [
        "Implement the tagger\n",
        "---------------\n",
        "This is the core exercise. There are three main tasks:\n",
        "* Implement parameter allocation. This implies allocating the embedding layer, the LSTM (or bi-LSTM) layer and the Linear Layer.\n",
        "* Implement the forward method. This method expects a tensor encoding the input and outputs a tensor of predictions\n",
        "* Implement the train method\n",
        "\n",
        "The evaluation (`validate`) method is given and cannot be modified. But it can be used as source of inspiration for implementing the train method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x6y33H2TKiQ"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "    def __init__(self, traingenerator, embedding_size, hidden_size, device='cpu'):\n",
        "        super(NERtagger, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.allocate_params(traingenerator, device)\n",
        "        self.device = device\n",
        "        self.to(self.device)\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "    def allocate_params(self, datagenerator, device):\n",
        "        vocab_size = len(datagenerator.input_idx2sym)\n",
        "        out_size = len(datagenerator.output_idx2sym)\n",
        "        self.word_embedding = nn.Embedding(vocab_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size)\n",
        "        self.linear_proj = nn.Linear(self.hidden_size, out_size)\n",
        "\n",
        "    def forward(self, Xinput):\n",
        "        embed = self.word_embedding(Xinput)\n",
        "        embed = embed.transpose(0, 1)\n",
        "        lstm_out, _ = self.lstm(embed)\n",
        "        lstm_out = lstm_out.transpose(0, 1)\n",
        "        tag_out = self.linear_proj(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_out, dim=-1)\n",
        "        return tag_scores\n",
        "\n",
        "    def train_model(self, traingenerator, validgenerator, epochs, batch_size, device='cpu', learning_rate=0.001, patience=3):\n",
        "        self.minloss = float('inf')\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        avg_losses = []\n",
        "        avg_valid_losses = []\n",
        "        no_improve_count = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "\n",
        "            self.train()  # Set model to training mode\n",
        "            for (SeqX, SeqY) in traingenerator.generate_batches(batch_size):\n",
        "                SeqX = torch.LongTensor(SeqX).to(self.device)\n",
        "                SeqY = torch.LongTensor(SeqY).to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                y_pred = self.forward(SeqX)\n",
        "\n",
        "                batch_size, seq_y_len = SeqY.shape\n",
        "                y_pred = y_pred.view(batch_size * seq_y_len, -1)\n",
        "                SeqY = SeqY.view(batch_size * seq_y_len)\n",
        "                loss = loss_fnc(y_pred, SeqY)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss.append(loss.item())\n",
        "                mask = (SeqY != pad_index)\n",
        "                y_argmax = torch.argmax(y_pred, dim=-1)\n",
        "                correct = torch.sum((y_argmax == SeqY) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                epoch_acc.append(float(correct) / float(total))\n",
        "\n",
        "            avg_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "            avg_losses.append(avg_loss)\n",
        "            print(f'Epoch {epoch+1}/{epochs}')\n",
        "            print(f'Training - Loss: {avg_loss:.4f}, Accuracy: {sum(epoch_acc) / len(epoch_acc):.4f}')\n",
        "\n",
        "            # Validation step\n",
        "            valid_loss = self.validate(validgenerator, batch_size)\n",
        "            avg_valid_losses.append(valid_loss)\n",
        "\n",
        "            # Early stopping check\n",
        "            if valid_loss < self.minloss:\n",
        "                self.minloss = valid_loss\n",
        "                torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "                no_improve_count = 0\n",
        "            else:\n",
        "                no_improve_count += 1\n",
        "                if no_improve_count >= patience:\n",
        "                    print(\"Early stopping triggered.\")\n",
        "                    break\n",
        "\n",
        "        # Plotting training and validation losses\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(len(avg_losses)), avg_losses, label='Training Loss')\n",
        "        plt.plot(range(len(avg_valid_losses)), avg_valid_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def validate(self, datagenerator, batch_size, device='cpu'):\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "        pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for (seqX, seqY) in datagenerator.generate_batches(batch_size):\n",
        "                X = torch.LongTensor(seqX).to(self.device)\n",
        "                Y = torch.LongTensor(seqY).to(self.device)\n",
        "                Yhat = self.forward(X)\n",
        "\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "                mask = (Y != pad_index)\n",
        "                Yargmax = torch.argmax(Yhat, dim=1)\n",
        "                correct = torch.sum((Yargmax == Y) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "        valid_loss = sum(batch_losses) / len(batch_losses)\n",
        "        print(f'[Validation] Mean Loss = {valid_loss:.4f}, Mean Accuracy = {sum(batch_accuracies) / len(batch_accuracies):.4f}')\n",
        "        return valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO-d3KVc3kTn"
      },
      "source": [
        "The main program is the following. You are expected to add code for searching for hyperparameters that maximise the validation score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4SoEEEf3uM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5e4c65e0-a71c-4a02-a2b6-55d6b1f33ff4"
      },
      "source": [
        "trainset = DataGenerator('eng.train')\n",
        "validset = DataGenerator('eng.testa',parentgenerator = trainset)\n",
        "tagger   = NERtagger(trainset,64,128,device='cuda')\n",
        "tagger.train_model(trainset, validset, 20, 32)\n",
        "\n",
        "#ADD CODE for searching reasonable hyperparameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Training - Loss: 0.8203, Accuracy: 0.7734\n",
            "[Validation] Mean Loss = 0.6375, Mean Accuracy = 0.7843\n",
            "Epoch 2/20\n",
            "Training - Loss: 0.4898, Accuracy: 0.8346\n",
            "[Validation] Mean Loss = 0.4588, Mean Accuracy = 0.8402\n",
            "Epoch 3/20\n",
            "Training - Loss: 0.3139, Accuracy: 0.8956\n",
            "[Validation] Mean Loss = 0.3627, Mean Accuracy = 0.8778\n",
            "Epoch 4/20\n",
            "Training - Loss: 0.1995, Accuracy: 0.9350\n",
            "[Validation] Mean Loss = 0.3109, Mean Accuracy = 0.8991\n",
            "Epoch 5/20\n",
            "Training - Loss: 0.1333, Accuracy: 0.9580\n",
            "[Validation] Mean Loss = 0.2979, Mean Accuracy = 0.8958\n",
            "Epoch 6/20\n",
            "Training - Loss: 0.0720, Accuracy: 0.9773\n",
            "[Validation] Mean Loss = 0.3116, Mean Accuracy = 0.9061\n",
            "Epoch 7/20\n",
            "Training - Loss: 0.0403, Accuracy: 0.9879\n",
            "[Validation] Mean Loss = 0.3462, Mean Accuracy = 0.9034\n",
            "Epoch 8/20\n",
            "Training - Loss: 0.0259, Accuracy: 0.9927\n",
            "[Validation] Mean Loss = 0.4073, Mean Accuracy = 0.9001\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for (seqx, seqy) in trainset.generate_batches(3):\n",
        "    seqx_tensor = torch.LongTensor(seqx).to(tagger.device)  # Convert seqx to a tensor and move to device if needed\n",
        "    print(seqx)\n",
        "    print(seqy)\n",
        "    print(tagger.forward(seqx_tensor))  # Pass the tensor instead of a list\n",
        "    counter += 1\n",
        "    if counter >= 100:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEbDAQm78Bcp",
        "outputId": "8b2c9dab-3c69-44f5-cfc1-458368473805",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[20705], [2940], [2940]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-3.6553e+01, -3.6391e+01, -2.6816e+01, -2.2626e+01, -2.7240e+01,\n",
            "          -2.3574e+01, -3.8989e+01, -2.6255e+01, -3.1699e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6065], [15912], [2940]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.8214e+01, -2.8424e+01, -2.4130e+01, -2.2611e+01, -2.1284e+01,\n",
            "          -2.1487e+01, -2.8091e+01, -2.4872e+01, -2.3827e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.5049e+01, -2.4791e+01, -1.9323e+01, -9.8104e+00, -1.4934e+01,\n",
            "          -1.5137e+01, -2.5157e+01, -1.0326e+01, -2.0718e+01, -8.8211e-05]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12317], [10833], [1366]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.0452e+01, -2.0515e+01, -1.3889e+01, -1.5651e+01, -1.3490e+01,\n",
            "          -1.3315e+01, -2.1529e+01, -1.4086e+01, -1.5276e+01, -5.1260e-06]],\n",
            "\n",
            "        [[-1.6794e+01, -1.6757e+01, -1.0935e+01, -6.3814e-03, -5.6651e+00,\n",
            "          -9.7521e+00, -1.4054e+01, -1.0735e+01, -1.2172e+01, -5.8809e+00]],\n",
            "\n",
            "        [[-2.2617e+01, -2.2448e+01, -1.3537e+01, -1.2288e+01, -1.0959e+01,\n",
            "          -1.1607e+01, -2.0610e+01, -1.4662e+01, -1.5585e+01, -3.2901e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[20705], [10154], [6133]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-3.6553e+01, -3.6391e+01, -2.6816e+01, -2.2626e+01, -2.7240e+01,\n",
            "          -2.3574e+01, -3.8989e+01, -2.6255e+01, -3.1699e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]],\n",
            "\n",
            "        [[-1.7948e+01, -1.7836e+01, -1.1974e+01, -1.0269e-03, -8.6258e+00,\n",
            "          -7.8578e+00, -1.6736e+01, -7.9641e+00, -1.2457e+01, -9.1881e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10644], [4060], [19095]]\n",
            "[[3], [4], [9]]\n",
            "tensor([[[-1.8827e+01, -1.8766e+01, -1.2378e+01, -1.6860e-03, -7.8118e+00,\n",
            "          -8.4414e+00, -1.5259e+01, -8.1475e+00, -1.1846e+01, -7.1784e+00]],\n",
            "\n",
            "        [[-2.0522e+01, -2.0513e+01, -1.5249e+01, -6.8687e+00, -1.4359e-03,\n",
            "          -9.2326e+00, -2.0563e+01, -9.4389e+00, -1.5486e+01, -8.4347e+00]],\n",
            "\n",
            "        [[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[13028], [9460], [7803]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-3.1024e+01, -3.0875e+01, -2.2389e+01, -1.8832e+01, -1.7273e+01,\n",
            "          -1.7681e+01, -3.1546e+01, -2.3743e+01, -2.4300e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.1160e+01, -2.1149e+01, -1.3112e+01, -8.1550e+00, -1.2067e+01,\n",
            "          -1.0280e+01, -2.1594e+01, -1.1045e+01, -1.7249e+01, -3.4541e-04]],\n",
            "\n",
            "        [[-2.2527e+01, -2.2589e+01, -1.4750e+01, -1.1756e+01, -9.8249e+00,\n",
            "          -1.3143e+01, -2.1093e+01, -1.2699e+01, -1.8867e+01, -6.7232e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1375], [1794], [8741]]\n",
            "[[3], [9], [9]]\n",
            "tensor([[[-1.5110e+01, -1.5086e+01, -1.0068e+01, -5.4152e-03, -5.5969e+00,\n",
            "          -6.6480e+00, -1.3941e+01, -8.3435e+00, -1.1498e+01, -9.1839e+00]],\n",
            "\n",
            "        [[-2.3934e+01, -2.4011e+01, -1.7969e+01, -1.5995e+01, -1.4901e+01,\n",
            "          -1.5649e+01, -2.3084e+01, -1.6115e+01, -2.0181e+01, -7.1526e-07]],\n",
            "\n",
            "        [[-1.9372e+01, -1.9458e+01, -1.4616e+01, -9.4542e+00, -1.3193e+01,\n",
            "          -1.1042e+01, -1.9501e+01, -8.1913e+00, -1.6109e+01, -3.7389e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[22355], [18645], [10154]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-1.1454e+01, -1.1537e+01, -9.4905e+00, -7.0992e+00, -1.0754e+01,\n",
            "          -5.1503e+00, -1.2866e+01, -8.3327e+00, -1.0322e+01, -7.0415e-03]],\n",
            "\n",
            "        [[-2.4404e+01, -2.4379e+01, -1.8596e+01, -1.1641e+01, -1.3686e+01,\n",
            "          -1.4798e+01, -2.4266e+01, -1.7218e+01, -1.9023e+01, -1.0371e-05]],\n",
            "\n",
            "        [[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10452], [23233], [6429]]\n",
            "[[3], [9], [9]]\n",
            "tensor([[[-1.9071e+01, -1.9142e+01, -1.4082e+01, -1.1586e-04, -1.0064e+01,\n",
            "          -9.8724e+00, -1.6900e+01, -1.1734e+01, -1.4833e+01, -1.1291e+01]],\n",
            "\n",
            "        [[-3.2408e+01, -3.2407e+01, -2.4155e+01, -2.1072e+01, -2.1332e+01,\n",
            "          -2.1478e+01, -3.4281e+01, -2.0005e+01, -2.6755e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2509e+01, -2.2581e+01, -1.6212e+01, -1.1672e+01, -1.3688e+01,\n",
            "          -1.2958e+01, -2.2313e+01, -1.3428e+01, -1.8244e+01, -1.3590e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[18319], [5951], [9166]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-2.6026e+01, -2.6007e+01, -1.7945e+01, -1.4195e+01, -1.1688e+01,\n",
            "          -1.5456e+01, -2.6031e+01, -1.5183e+01, -1.8548e+01, -9.6559e-06]],\n",
            "\n",
            "        [[-1.2374e+01, -1.2372e+01, -1.0247e+01, -8.4360e+00, -8.3332e+00,\n",
            "          -7.1336e+00, -1.2117e+01, -8.0108e+00, -1.1640e+01, -1.6466e-03]],\n",
            "\n",
            "        [[-1.6373e+01, -1.6241e+01, -1.2138e+01, -1.9837e-02, -5.7346e+00,\n",
            "          -5.1302e+00, -1.4106e+01, -4.6817e+00, -1.4367e+01, -6.7060e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12446], [9921], [13028]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.3726e+01, -2.3697e+01, -1.9908e+01, -1.8594e+01, -1.4277e+01,\n",
            "          -1.8985e+01, -2.3650e+01, -2.2595e+01, -2.1336e+01, -5.9605e-07]],\n",
            "\n",
            "        [[-1.8264e+01, -1.8341e+01, -1.3781e+01, -9.5366e+00, -1.0108e+01,\n",
            "          -1.2131e+01, -1.6277e+01, -1.1280e+01, -1.2456e+01, -1.3589e-04]],\n",
            "\n",
            "        [[-3.1024e+01, -3.0875e+01, -2.2389e+01, -1.8832e+01, -1.7273e+01,\n",
            "          -1.7681e+01, -3.1546e+01, -2.3743e+01, -2.4300e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23024], [16180], [856]]\n",
            "[[4], [7], [9]]\n",
            "tensor([[[-2.0969e+01, -2.0988e+01, -1.6173e+01, -8.2893e+00, -2.7724e-04,\n",
            "          -1.1569e+01, -1.8656e+01, -1.4051e+01, -1.6250e+01, -1.1071e+01]],\n",
            "\n",
            "        [[-1.4240e+01, -1.4187e+01, -1.1252e+01, -9.7476e+00, -9.3023e+00,\n",
            "          -1.0888e+01, -1.3506e+01, -2.6795e-04, -9.4009e+00, -1.3594e+01]],\n",
            "\n",
            "        [[-3.2512e+01, -3.2444e+01, -2.5256e+01, -1.9070e+01, -2.1771e+01,\n",
            "          -2.2043e+01, -3.3527e+01, -2.5203e+01, -2.7444e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[15496], [19520], [19095]]\n",
            "[[9], [4], [9]]\n",
            "tensor([[[-2.1382e+01, -2.1335e+01, -1.3797e+01, -1.0508e+01, -1.3277e+01,\n",
            "          -1.0352e+01, -2.3345e+01, -1.0866e+01, -1.9480e+01, -8.1059e-05]],\n",
            "\n",
            "        [[-1.5721e+01, -1.5704e+01, -1.0419e+01, -8.8289e+00, -3.1967e-04,\n",
            "          -1.0814e+01, -1.4746e+01, -1.0325e+01, -1.0016e+01, -1.0007e+01]],\n",
            "\n",
            "        [[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6131], [11557], [8954]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-1.5959e+01, -1.5944e+01, -1.1877e+01, -1.2265e+01, -7.3662e+00,\n",
            "          -1.2294e+01, -1.6870e+01, -1.4625e+01, -1.2440e+01, -6.5329e-04]],\n",
            "\n",
            "        [[-2.6189e+01, -2.6050e+01, -1.7003e+01, -1.5766e+01, -1.5597e+01,\n",
            "          -1.6735e+01, -2.6112e+01, -1.3722e+01, -2.2724e+01, -1.4305e-06]],\n",
            "\n",
            "        [[-1.8688e+01, -1.8591e+01, -1.0296e+01, -2.5086e-03, -6.7135e+00,\n",
            "          -7.1747e+00, -1.6966e+01, -8.2474e+00, -1.3463e+01, -8.3854e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[20803], [21138], [199]]\n",
            "[[3], [9], [9]]\n",
            "tensor([[[-2.2384e+01, -2.2388e+01, -1.4834e+01, -1.3137e-03, -7.6763e+00,\n",
            "          -8.2399e+00, -2.0633e+01, -1.3017e+01, -1.8168e+01, -7.4481e+00]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]],\n",
            "\n",
            "        [[-1.9697e+01, -1.9426e+01, -1.2641e+01, -1.0444e+01, -8.4427e+00,\n",
            "          -1.0154e+01, -1.6937e+01, -1.1195e+01, -1.4454e+01, -3.0120e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[3620], [5638], [16915]]\n",
            "[[9], [4], [9]]\n",
            "tensor([[[-2.6964e+01, -2.6802e+01, -1.8129e+01, -1.2956e+01, -1.5973e+01,\n",
            "          -1.4086e+01, -2.7924e+01, -1.2860e+01, -2.2812e+01, -5.8412e-06]],\n",
            "\n",
            "        [[-2.6360e+01, -2.6365e+01, -1.8420e+01, -8.2024e+00, -3.3504e-04,\n",
            "          -1.4537e+01, -2.5979e+01, -1.2300e+01, -2.1960e+01, -9.7911e+00]],\n",
            "\n",
            "        [[-2.2467e+01, -2.2685e+01, -1.7472e+01, -9.3765e+00, -1.1795e+01,\n",
            "          -1.5738e+01, -2.1561e+01, -1.2993e+01, -1.9205e+01, -9.4767e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[17136], [15496], [11273]]\n",
            "[[4], [9], [9]]\n",
            "tensor([[[-1.6367e+01, -1.6403e+01, -9.5876e+00, -6.2759e+00, -4.8001e-03,\n",
            "          -6.0808e+00, -1.4638e+01, -8.9312e+00, -1.1778e+01, -7.7945e+00]],\n",
            "\n",
            "        [[-2.1382e+01, -2.1335e+01, -1.3797e+01, -1.0508e+01, -1.3277e+01,\n",
            "          -1.0352e+01, -2.3345e+01, -1.0866e+01, -1.9480e+01, -8.1059e-05]],\n",
            "\n",
            "        [[-2.5180e+01, -2.5147e+01, -2.0055e+01, -1.4538e+01, -1.4720e+01,\n",
            "          -1.2456e+01, -2.6714e+01, -1.4577e+01, -1.9906e+01, -5.2452e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1161], [19368], [13028]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.1694e+01, -2.1522e+01, -1.6267e+01, -9.5457e+00, -1.3122e+01,\n",
            "          -1.3377e+01, -2.1889e+01, -1.0318e+01, -1.9365e+01, -1.0824e-04]],\n",
            "\n",
            "        [[-1.7750e+01, -1.7739e+01, -1.4176e+01, -1.4055e+01, -1.2097e+01,\n",
            "          -1.0607e+01, -1.9193e+01, -8.7868e+00, -1.4994e+01, -1.8488e-04]],\n",
            "\n",
            "        [[-3.1024e+01, -3.0875e+01, -2.2389e+01, -1.8832e+01, -1.7273e+01,\n",
            "          -1.7681e+01, -3.1546e+01, -2.3743e+01, -2.4300e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[21138], [20705], [10334]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]],\n",
            "\n",
            "        [[-3.6553e+01, -3.6391e+01, -2.6816e+01, -2.2626e+01, -2.7240e+01,\n",
            "          -2.3574e+01, -3.8989e+01, -2.6255e+01, -3.1699e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.1916e+01, -2.1789e+01, -1.5805e+01, -1.6328e+01, -1.2345e+01,\n",
            "          -1.5449e+01, -2.2454e+01, -1.2461e+01, -1.7143e+01, -8.7022e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19278], [2940], [20705]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.1734e+01, -2.1639e+01, -1.4255e+01, -1.1681e+01, -1.1787e+01,\n",
            "          -1.2322e+01, -2.0753e+01, -7.5302e+00, -1.6775e+01, -5.5798e-04]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]],\n",
            "\n",
            "        [[-3.6553e+01, -3.6391e+01, -2.6816e+01, -2.2626e+01, -2.7240e+01,\n",
            "          -2.3574e+01, -3.8989e+01, -2.6255e+01, -3.1699e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10154], [12125], [7471]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]],\n",
            "\n",
            "        [[-2.6674e+01, -2.6801e+01, -1.9866e+01, -1.4095e+01, -1.1763e+01,\n",
            "          -1.5998e+01, -2.6334e+01, -2.0122e+01, -2.3231e+01, -8.5830e-06]],\n",
            "\n",
            "        [[-2.2899e+01, -2.2990e+01, -1.7653e+01, -1.2490e+01, -1.0054e+01,\n",
            "          -1.2087e+01, -2.0127e+01, -1.7864e+01, -1.6727e+01, -5.2451e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19095], [2813], [17628]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2275e+01, -2.2139e+01, -1.5265e+01, -3.8962e-04, -9.8690e+00,\n",
            "          -1.0116e+01, -1.8813e+01, -9.2387e+00, -1.9533e+01, -8.5174e+00]],\n",
            "\n",
            "        [[-2.2473e+01, -2.2290e+01, -1.5299e+01, -1.3539e+01, -1.0032e+01,\n",
            "          -1.3240e+01, -2.3381e+01, -1.5457e+01, -1.7500e+01, -4.7563e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23178], [15659], [17628]]\n",
            "[[3], [3], [9]]\n",
            "tensor([[[-2.1324e+01, -2.1277e+01, -1.2978e+01, -4.9773e-03, -6.7931e+00,\n",
            "          -7.1638e+00, -1.9937e+01, -6.2845e+00, -1.4625e+01, -6.7240e+00]],\n",
            "\n",
            "        [[-1.5269e+01, -1.5296e+01, -1.0844e+01, -3.4550e-03, -6.7184e+00,\n",
            "          -6.1768e+00, -1.3442e+01, -1.0714e+01, -9.1059e+00, -1.1629e+01]],\n",
            "\n",
            "        [[-2.2473e+01, -2.2290e+01, -1.5299e+01, -1.3539e+01, -1.0032e+01,\n",
            "          -1.3240e+01, -2.3381e+01, -1.5457e+01, -1.7500e+01, -4.7563e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10154], [1375], [1030]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]],\n",
            "\n",
            "        [[-1.5110e+01, -1.5086e+01, -1.0068e+01, -5.4152e-03, -5.5969e+00,\n",
            "          -6.6480e+00, -1.3941e+01, -8.3435e+00, -1.1498e+01, -9.1839e+00]],\n",
            "\n",
            "        [[-2.4045e+01, -2.4066e+01, -1.8618e+01, -1.3539e+01, -1.6208e+01,\n",
            "          -1.5032e+01, -2.4571e+01, -1.8323e+01, -1.9435e+01, -1.6689e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23024], [13028], [8330]]\n",
            "[[4], [9], [4]]\n",
            "tensor([[[-2.0969e+01, -2.0988e+01, -1.6173e+01, -8.2893e+00, -2.7724e-04,\n",
            "          -1.1569e+01, -1.8656e+01, -1.4051e+01, -1.6250e+01, -1.1071e+01]],\n",
            "\n",
            "        [[-3.1024e+01, -3.0875e+01, -2.2389e+01, -1.8832e+01, -1.7273e+01,\n",
            "          -1.7681e+01, -3.1546e+01, -2.3743e+01, -2.4300e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9332e+01, -1.9365e+01, -1.3334e+01, -7.9527e+00, -8.3126e-04,\n",
            "          -1.0121e+01, -1.8934e+01, -8.8722e+00, -1.2288e+01, -8.1374e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[83], [21138], [19095]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.4626e+01, -2.4774e+01, -2.0663e+01, -2.0088e+01, -2.1390e+01,\n",
            "          -1.7548e+01, -2.5659e+01, -2.0601e+01, -2.1186e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]],\n",
            "\n",
            "        [[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19095], [3454], [13520]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.9753e+01, -2.9772e+01, -2.1848e+01, -1.4714e+01, -1.5234e+01,\n",
            "          -1.8701e+01, -3.0704e+01, -2.2122e+01, -2.3777e+01, -5.9605e-07]],\n",
            "\n",
            "        [[-1.8530e+01, -1.8728e+01, -1.4996e+01, -9.6413e+00, -1.1403e+01,\n",
            "          -1.2823e+01, -1.8019e+01, -7.5804e+00, -1.4542e+01, -5.9027e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[17799], [15459], [18319]]\n",
            "[[9], [7], [9]]\n",
            "tensor([[[-3.5063e+01, -3.5061e+01, -2.8593e+01, -1.9041e+01, -2.2306e+01,\n",
            "          -2.0309e+01, -3.5333e+01, -2.3584e+01, -2.8906e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2356e+01, -2.2346e+01, -1.8159e+01, -1.7908e+01, -1.8631e+01,\n",
            "          -1.6322e+01, -2.3864e+01, -1.1921e-07, -1.8771e+01, -1.6860e+01]],\n",
            "\n",
            "        [[-2.6026e+01, -2.6007e+01, -1.7945e+01, -1.4195e+01, -1.1688e+01,\n",
            "          -1.5456e+01, -2.6031e+01, -1.5183e+01, -1.8548e+01, -9.6559e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[22700], [6572], [23178]]\n",
            "[[3], [3], [3]]\n",
            "tensor([[[-2.3324e+01, -2.3304e+01, -1.7249e+01, -3.5959e-04, -9.6586e+00,\n",
            "          -9.0474e+00, -2.0620e+01, -8.6925e+00, -1.7868e+01, -1.1495e+01]],\n",
            "\n",
            "        [[-2.2501e+01, -2.2411e+01, -1.6050e+01, -2.1951e-03, -7.6084e+00,\n",
            "          -9.7209e+00, -1.9848e+01, -7.9948e+00, -1.9142e+01, -6.6461e+00]],\n",
            "\n",
            "        [[-2.1324e+01, -2.1277e+01, -1.2978e+01, -4.9773e-03, -6.7931e+00,\n",
            "          -7.1638e+00, -1.9937e+01, -6.2845e+00, -1.4625e+01, -6.7240e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12125], [20131], [4861]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-2.6674e+01, -2.6801e+01, -1.9866e+01, -1.4095e+01, -1.1763e+01,\n",
            "          -1.5998e+01, -2.6334e+01, -2.0122e+01, -2.3231e+01, -8.5830e-06]],\n",
            "\n",
            "        [[-1.8341e+01, -1.8423e+01, -1.2677e+01, -1.4900e+01, -1.6186e+01,\n",
            "          -1.2725e+01, -1.7591e+01, -1.2838e+01, -1.7205e+01, -9.2983e-06]],\n",
            "\n",
            "        [[-2.1094e+01, -2.1153e+01, -1.3327e+01, -6.8438e-04, -8.1425e+00,\n",
            "          -8.4450e+00, -1.7425e+01, -1.0376e+01, -1.6780e+01, -8.8361e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[3174], [2322], [14369]]\n",
            "[[9], [9], [4]]\n",
            "tensor([[[-2.7672e+01, -2.7750e+01, -2.4729e+01, -2.2990e+01, -2.2331e+01,\n",
            "          -2.3667e+01, -2.8144e+01, -2.2324e+01, -2.5826e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.7032e+01, -2.6967e+01, -2.2771e+01, -1.4796e+01, -2.0139e+01,\n",
            "          -1.7245e+01, -2.7749e+01, -1.7805e+01, -2.4007e+01, -3.5763e-07]],\n",
            "\n",
            "        [[-2.3101e+01, -2.3132e+01, -1.5487e+01, -1.1573e+01, -2.8371e-05,\n",
            "          -1.1848e+01, -2.1559e+01, -1.2211e+01, -1.7069e+01, -1.1934e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6065], [22137], [3656]]\n",
            "[[9], [3], [3]]\n",
            "tensor([[[-2.8214e+01, -2.8424e+01, -2.4130e+01, -2.2611e+01, -2.1284e+01,\n",
            "          -2.1487e+01, -2.8091e+01, -2.4872e+01, -2.3827e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.4296e+01, -1.4191e+01, -1.1031e+01, -7.1628e-03, -6.5645e+00,\n",
            "          -6.7334e+00, -1.3023e+01, -7.1105e+00, -1.1241e+01, -5.6027e+00]],\n",
            "\n",
            "        [[-2.2058e+01, -2.2026e+01, -1.3706e+01, -5.1460e-03, -9.8314e+00,\n",
            "          -6.3447e+00, -1.9692e+01, -8.3214e+00, -1.7458e+01, -5.7833e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23233], [3627], [3174]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-3.2408e+01, -3.2407e+01, -2.4155e+01, -2.1072e+01, -2.1332e+01,\n",
            "          -2.1478e+01, -3.4281e+01, -2.0005e+01, -2.6755e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-3.2349e+01, -3.2385e+01, -2.2353e+01, -1.6278e+01, -1.9787e+01,\n",
            "          -1.9607e+01, -3.3838e+01, -2.0038e+01, -2.7460e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-2.7672e+01, -2.7750e+01, -2.4729e+01, -2.2990e+01, -2.2331e+01,\n",
            "          -2.3667e+01, -2.8144e+01, -2.2324e+01, -2.5826e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[4397], [16047], [17152]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.2347e+01, -2.2344e+01, -1.4542e+01, -1.0102e+01, -8.4394e+00,\n",
            "          -8.9356e+00, -2.1609e+01, -9.4678e+00, -1.8325e+01, -4.6671e-04]],\n",
            "\n",
            "        [[-2.1582e+01, -2.1587e+01, -1.4856e+01, -7.1731e+00, -1.3466e+01,\n",
            "          -1.2569e+01, -2.1527e+01, -8.7737e+00, -1.6379e+01, -9.2749e-04]],\n",
            "\n",
            "        [[-2.5083e+01, -2.4999e+01, -1.6963e+01, -1.2058e+01, -1.2086e+01,\n",
            "          -1.2373e+01, -2.4379e+01, -1.8122e+01, -1.8812e+01, -1.5855e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[16328], [8330], [11193]]\n",
            "[[9], [4], [9]]\n",
            "tensor([[[-2.2078e+01, -2.2132e+01, -1.5997e+01, -9.1214e+00, -1.1132e+01,\n",
            "          -1.1873e+01, -2.2198e+01, -8.3109e+00, -1.6855e+01, -3.7699e-04]],\n",
            "\n",
            "        [[-1.9332e+01, -1.9365e+01, -1.3334e+01, -7.9527e+00, -8.3126e-04,\n",
            "          -1.0121e+01, -1.8934e+01, -8.8722e+00, -1.2288e+01, -8.1374e+00]],\n",
            "\n",
            "        [[-1.9298e+01, -1.9315e+01, -1.3573e+01, -1.0098e+01, -1.1483e+01,\n",
            "          -1.0549e+01, -1.6700e+01, -1.0379e+01, -1.5329e+01, -1.1038e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19821], [8258], [21138]]\n",
            "[[4], [9], [9]]\n",
            "tensor([[[-1.7242e+01, -1.7257e+01, -1.4669e+01, -8.5582e+00, -2.6354e-04,\n",
            "          -1.1412e+01, -1.7481e+01, -1.0686e+01, -1.1112e+01, -1.0721e+01]],\n",
            "\n",
            "        [[-2.1559e+01, -2.1636e+01, -1.2845e+01, -9.0352e+00, -1.4673e+01,\n",
            "          -9.1759e+00, -2.3478e+01, -8.8143e+00, -1.6064e+01, -3.7460e-04]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23233], [20705], [15765]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-3.2408e+01, -3.2407e+01, -2.4155e+01, -2.1072e+01, -2.1332e+01,\n",
            "          -2.1478e+01, -3.4281e+01, -2.0005e+01, -2.6755e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-3.6553e+01, -3.6391e+01, -2.6816e+01, -2.2626e+01, -2.7240e+01,\n",
            "          -2.3574e+01, -3.8989e+01, -2.6255e+01, -3.1699e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.9649e+01, -2.9717e+01, -2.2173e+01, -1.4127e+01, -1.9253e+01,\n",
            "          -1.7974e+01, -3.0703e+01, -1.4569e+01, -2.5424e+01, -1.1921e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2940], [2322], [2940]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]],\n",
            "\n",
            "        [[-2.7032e+01, -2.6967e+01, -2.2771e+01, -1.4796e+01, -2.0139e+01,\n",
            "          -1.7245e+01, -2.7749e+01, -1.7805e+01, -2.4007e+01, -3.5763e-07]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[9056], [19095], [2988]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.2536e+01, -2.2417e+01, -1.6905e+01, -1.3200e+01, -1.2499e+01,\n",
            "          -1.2568e+01, -2.1484e+01, -1.0097e+01, -1.5405e+01, -5.0424e-05]],\n",
            "\n",
            "        [[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.7484e+01, -2.7516e+01, -1.8107e+01, -1.8568e+01, -1.8089e+01,\n",
            "          -1.7186e+01, -2.8729e+01, -1.9241e+01, -2.0641e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2322], [13223], [10154]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.7032e+01, -2.6967e+01, -2.2771e+01, -1.4796e+01, -2.0139e+01,\n",
            "          -1.7245e+01, -2.7749e+01, -1.7805e+01, -2.4007e+01, -3.5763e-07]],\n",
            "\n",
            "        [[-1.8785e+01, -1.8688e+01, -1.3240e+01, -9.6144e-04, -7.8181e+00,\n",
            "          -8.4284e+00, -1.7253e+01, -9.0981e+00, -1.4312e+01, -8.3961e+00]],\n",
            "\n",
            "        [[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[13614], [5405], [21284]]\n",
            "[[9], [9], [4]]\n",
            "tensor([[[-2.5358e+01, -2.5339e+01, -1.8614e+01, -1.0530e+01, -9.4783e+00,\n",
            "          -1.5074e+01, -2.5220e+01, -1.3143e+01, -1.8470e+01, -1.0549e-04]],\n",
            "\n",
            "        [[-2.3834e+01, -2.3850e+01, -1.8723e+01, -6.7558e+00, -1.6444e+01,\n",
            "          -1.3712e+01, -2.3105e+01, -1.4572e+01, -1.8857e+01, -1.1664e-03]],\n",
            "\n",
            "        [[-1.7807e+01, -1.7735e+01, -1.2878e+01, -6.0467e+00, -2.5342e-03,\n",
            "          -9.8477e+00, -1.6319e+01, -9.1524e+00, -1.4192e+01, -1.2655e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19770], [23233], [19739]]\n",
            "[[9], [9], [7]]\n",
            "tensor([[[-2.1596e+01, -2.1463e+01, -1.5647e+01, -1.4664e+01, -1.5316e+01,\n",
            "          -1.0776e+01, -2.2569e+01, -1.0797e+01, -1.5770e+01, -4.2199e-05]],\n",
            "\n",
            "        [[-3.2408e+01, -3.2407e+01, -2.4155e+01, -2.1072e+01, -2.1332e+01,\n",
            "          -2.1478e+01, -3.4281e+01, -2.0005e+01, -2.6755e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.6448e+01, -2.6379e+01, -1.7787e+01, -1.3715e+01, -1.3751e+01,\n",
            "          -1.0743e+01, -2.8704e+01, -2.3842e-05, -2.1301e+01, -1.6840e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[15635], [11997], [18192]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-2.4268e+01, -2.4385e+01, -1.8495e+01, -1.1971e+01, -1.0387e+01,\n",
            "          -1.5713e+01, -2.3616e+01, -1.4612e+01, -1.8343e+01, -3.7789e-05]],\n",
            "\n",
            "        [[-2.5670e+01, -2.5781e+01, -1.7283e+01, -1.0887e+01, -1.0914e+01,\n",
            "          -1.4313e+01, -2.5565e+01, -1.0414e+01, -1.9331e+01, -6.7589e-05]],\n",
            "\n",
            "        [[-2.1329e+01, -2.1366e+01, -1.2961e+01, -3.9856e-04, -9.0196e+00,\n",
            "          -8.6162e+00, -1.9001e+01, -9.7517e+00, -1.5239e+01, -1.0243e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[20374], [19095], [6065]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.5567e+01, -2.5701e+01, -1.9873e+01, -1.8301e+01, -1.9474e+01,\n",
            "          -1.6330e+01, -2.5298e+01, -1.6762e+01, -2.1769e+01, -2.3842e-07]],\n",
            "\n",
            "        [[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.8214e+01, -2.8424e+01, -2.4130e+01, -2.2611e+01, -2.1284e+01,\n",
            "          -2.1487e+01, -2.8091e+01, -2.4872e+01, -2.3827e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[20893], [1794], [15496]]\n",
            "[[3], [9], [9]]\n",
            "tensor([[[-1.5096e+01, -1.5170e+01, -8.3234e+00, -5.2759e-01, -3.7961e+00,\n",
            "          -1.0301e+00, -1.3995e+01, -6.5006e+00, -1.2332e+01, -3.5480e+00]],\n",
            "\n",
            "        [[-2.3934e+01, -2.4011e+01, -1.7969e+01, -1.5995e+01, -1.4901e+01,\n",
            "          -1.5649e+01, -2.3084e+01, -1.6115e+01, -2.0181e+01, -7.1526e-07]],\n",
            "\n",
            "        [[-2.1382e+01, -2.1335e+01, -1.3797e+01, -1.0508e+01, -1.3277e+01,\n",
            "          -1.0352e+01, -2.3345e+01, -1.0866e+01, -1.9480e+01, -8.1059e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2322], [21138], [23299]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.7032e+01, -2.6967e+01, -2.2771e+01, -1.4796e+01, -2.0139e+01,\n",
            "          -1.7245e+01, -2.7749e+01, -1.7805e+01, -2.4007e+01, -3.5763e-07]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]],\n",
            "\n",
            "        [[-2.2502e+01, -2.2608e+01, -1.6632e+01, -1.8373e+01, -1.6374e+01,\n",
            "          -1.6734e+01, -2.2420e+01, -1.7757e+01, -1.7046e+01, -1.1921e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6006], [7256], [18481]]\n",
            "[[3], [4], [9]]\n",
            "tensor([[[-2.1016e+01, -2.0841e+01, -1.4882e+01, -9.1191e-05, -1.1715e+01,\n",
            "          -9.5676e+00, -1.7460e+01, -1.4059e+01, -1.7509e+01, -1.1351e+01]],\n",
            "\n",
            "        [[-1.3262e+01, -1.3263e+01, -8.8389e+00, -9.0358e-02, -2.4843e+00,\n",
            "          -7.8986e+00, -1.2843e+01, -7.7702e+00, -8.6008e+00, -6.2744e+00]],\n",
            "\n",
            "        [[-2.1457e+01, -2.1247e+01, -1.4712e+01, -1.1332e+01, -1.0818e+01,\n",
            "          -9.8752e+00, -2.0945e+01, -1.3168e+01, -1.7346e+01, -8.5946e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[9229], [22110], [12667]]\n",
            "[[4], [5], [3]]\n",
            "tensor([[[-1.5725e+01, -1.5680e+01, -1.0170e+01, -8.0304e+00, -4.6338e-04,\n",
            "          -1.2362e+01, -1.3682e+01, -9.6810e+00, -1.1438e+01, -1.0793e+01]],\n",
            "\n",
            "        [[-1.9273e+01, -1.9198e+01, -1.2472e+01, -9.2605e+00, -1.0104e+01,\n",
            "          -2.2254e-04, -2.0104e+01, -1.3636e+01, -1.5766e+01, -9.4184e+00]],\n",
            "\n",
            "        [[-1.6390e+01, -1.6265e+01, -9.1553e+00, -7.7565e-03, -6.6465e+00,\n",
            "          -7.4925e+00, -1.5239e+01, -5.3876e+00, -1.1285e+01, -6.7431e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19095], [1312], [19425]]\n",
            "[[9], [4], [9]]\n",
            "tensor([[[-2.7899e+01, -2.7940e+01, -2.1872e+01, -1.8612e+01, -1.7792e+01,\n",
            "          -1.7781e+01, -2.8566e+01, -2.0471e+01, -2.2947e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9545e+01, -1.9612e+01, -1.4972e+01, -8.1906e+00, -3.4148e-04,\n",
            "          -1.2274e+01, -1.6946e+01, -1.0810e+01, -1.5315e+01, -1.0158e+01]],\n",
            "\n",
            "        [[-2.1912e+01, -2.1987e+01, -1.6841e+01, -1.3128e+01, -1.6334e+01,\n",
            "          -1.3825e+01, -2.1689e+01, -1.3262e+01, -1.8079e+01, -4.7684e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[5638], [12125], [21138]]\n",
            "[[4], [9], [9]]\n",
            "tensor([[[-2.6360e+01, -2.6365e+01, -1.8420e+01, -8.2024e+00, -3.3504e-04,\n",
            "          -1.4537e+01, -2.5979e+01, -1.2300e+01, -2.1960e+01, -9.7911e+00]],\n",
            "\n",
            "        [[-2.6674e+01, -2.6801e+01, -1.9866e+01, -1.4095e+01, -1.1763e+01,\n",
            "          -1.5998e+01, -2.6334e+01, -2.0122e+01, -2.3231e+01, -8.5830e-06]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[11625], [17279], [15459]]\n",
            "[[9], [3], [7]]\n",
            "tensor([[[-1.8551e+01, -1.8665e+01, -1.4266e+01, -7.0971e+00, -9.2518e+00,\n",
            "          -8.5868e+00, -1.9039e+01, -5.8603e+00, -1.4805e+01, -3.9692e-03]],\n",
            "\n",
            "        [[-1.5285e+01, -1.5244e+01, -1.2533e+01, -2.1030e-03, -6.5507e+00,\n",
            "          -8.4172e+00, -1.3661e+01, -8.8354e+00, -1.0660e+01, -8.1934e+00]],\n",
            "\n",
            "        [[-2.2356e+01, -2.2346e+01, -1.8159e+01, -1.7908e+01, -1.8631e+01,\n",
            "          -1.6322e+01, -2.3864e+01, -1.1921e-07, -1.8771e+01, -1.6860e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[17628], [11608], [18906]]\n",
            "[[9], [9], [3]]\n",
            "tensor([[[-2.2473e+01, -2.2290e+01, -1.5299e+01, -1.3539e+01, -1.0032e+01,\n",
            "          -1.3240e+01, -2.3381e+01, -1.5457e+01, -1.7500e+01, -4.7563e-05]],\n",
            "\n",
            "        [[-2.2060e+01, -2.2194e+01, -1.8224e+01, -1.2208e+01, -1.5595e+01,\n",
            "          -1.4288e+01, -2.0667e+01, -1.2521e+01, -1.7535e+01, -9.4175e-06]],\n",
            "\n",
            "        [[-1.9138e+01, -1.9116e+01, -1.2989e+01, -2.6904e-03, -6.4874e+00,\n",
            "          -9.8607e+00, -1.7597e+01, -7.4432e+00, -1.3022e+01, -7.5578e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[14164], [15496], [10350]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.5308e+01, -2.5242e+01, -1.5788e+01, -8.5337e+00, -9.3779e+00,\n",
            "          -1.1120e+01, -2.4702e+01, -6.2836e+00, -1.9084e+01, -2.1654e-03]],\n",
            "\n",
            "        [[-2.1382e+01, -2.1335e+01, -1.3797e+01, -1.0508e+01, -1.3277e+01,\n",
            "          -1.0352e+01, -2.3345e+01, -1.0866e+01, -1.9480e+01, -8.1059e-05]],\n",
            "\n",
            "        [[-2.2957e+01, -2.2854e+01, -1.8113e+01, -1.2576e+01, -1.2529e+01,\n",
            "          -1.4458e+01, -2.2665e+01, -1.9751e+01, -1.9294e+01, -7.6294e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[13223], [19620], [3808]]\n",
            "[[3], [9], [9]]\n",
            "tensor([[[-1.8785e+01, -1.8688e+01, -1.3240e+01, -9.6144e-04, -7.8181e+00,\n",
            "          -8.4284e+00, -1.7253e+01, -9.0981e+00, -1.4312e+01, -8.3961e+00]],\n",
            "\n",
            "        [[-2.2878e+01, -2.2933e+01, -1.7114e+01, -1.0279e+01, -1.0102e+01,\n",
            "          -1.6747e+01, -2.2746e+01, -1.3323e+01, -2.0135e+01, -7.7006e-05]],\n",
            "\n",
            "        [[-2.8236e+01, -2.8249e+01, -2.1075e+01, -1.7000e+01, -1.5431e+01,\n",
            "          -1.8797e+01, -2.7555e+01, -1.4946e+01, -2.1572e+01, -5.9605e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[18645], [4861], [10154]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.4404e+01, -2.4379e+01, -1.8596e+01, -1.1641e+01, -1.3686e+01,\n",
            "          -1.4798e+01, -2.4266e+01, -1.7218e+01, -1.9023e+01, -1.0371e-05]],\n",
            "\n",
            "        [[-2.1094e+01, -2.1153e+01, -1.3327e+01, -6.8438e-04, -8.1425e+00,\n",
            "          -8.4450e+00, -1.7425e+01, -1.0376e+01, -1.6780e+01, -8.8361e+00]],\n",
            "\n",
            "        [[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2849], [11273], [10154]]\n",
            "[[9], [9], [9]]\n",
            "tensor([[[-2.7347e+01, -2.7665e+01, -2.0387e+01, -1.7283e+01, -1.4477e+01,\n",
            "          -1.5222e+01, -2.5432e+01, -1.7030e+01, -2.2785e+01, -8.3446e-07]],\n",
            "\n",
            "        [[-2.5180e+01, -2.5147e+01, -2.0055e+01, -1.4538e+01, -1.4720e+01,\n",
            "          -1.2456e+01, -2.6714e+01, -1.4577e+01, -1.9906e+01, -5.2452e-06]],\n",
            "\n",
            "        [[-2.7988e+01, -2.7795e+01, -1.8046e+01, -1.4996e+01, -1.5282e+01,\n",
            "          -1.4686e+01, -2.6487e+01, -1.6873e+01, -2.1402e+01, -1.0729e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6006], [2940], [19441]]\n",
            "[[3], [9], [3]]\n",
            "tensor([[[-2.1016e+01, -2.0841e+01, -1.4882e+01, -9.1191e-05, -1.1715e+01,\n",
            "          -9.5676e+00, -1.7460e+01, -1.4059e+01, -1.7509e+01, -1.1351e+01]],\n",
            "\n",
            "        [[-1.9793e+01, -1.9812e+01, -1.6787e+01, -1.0435e+01, -1.4330e+01,\n",
            "          -1.5585e+01, -1.8544e+01, -1.5937e+01, -1.7134e+01, -3.0279e-05]],\n",
            "\n",
            "        [[-2.1376e+01, -2.1245e+01, -1.4926e+01, -7.4889e-03, -5.9265e+00,\n",
            "          -1.0614e+01, -1.8731e+01, -6.5105e+00, -1.5202e+01, -5.7198e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[3967], [6177], [12628]]\n",
            "[[9], [3], [9]]\n",
            "tensor([[[-2.2568e+01, -2.2272e+01, -1.3778e+01, -8.6458e+00, -9.7613e+00,\n",
            "          -1.2181e+01, -2.0790e+01, -9.2362e+00, -1.8916e+01, -3.3707e-04]],\n",
            "\n",
            "        [[-2.1947e+01, -2.1942e+01, -1.2986e+01, -1.1866e-02, -6.0652e+00,\n",
            "          -5.6630e+00, -1.9426e+01, -6.8867e+00, -1.5056e+01, -5.3028e+00]],\n",
            "\n",
            "        [[-1.8252e+01, -1.8334e+01, -1.5526e+01, -9.3781e+00, -1.1867e+01,\n",
            "          -1.3580e+01, -1.8589e+01, -1.3100e+01, -1.5491e+01, -9.5363e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2579], [8954], [13514]]\n",
            "[[3], [3], [9]]\n",
            "tensor([[[-1.8213e+01, -1.8076e+01, -1.2346e+01, -1.0593e-03, -7.5938e+00,\n",
            "          -9.0617e+00, -1.5655e+01, -8.3925e+00, -1.3598e+01, -8.4833e+00]],\n",
            "\n",
            "        [[-1.8688e+01, -1.8591e+01, -1.0296e+01, -2.5086e-03, -6.7135e+00,\n",
            "          -7.1747e+00, -1.6966e+01, -8.2474e+00, -1.3463e+01, -8.3854e+00]],\n",
            "\n",
            "        [[-2.2127e+01, -2.2149e+01, -1.7454e+01, -1.2686e+01, -1.1941e+01,\n",
            "          -1.1705e+01, -2.1565e+01, -1.1088e+01, -1.7724e+01, -3.3140e-05]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[20447, 0], [21138, 0], [13953, 16080]]\n",
            "[[3, 0], [9, 0], [3, 3]]\n",
            "tensor([[[-2.1236e+01, -2.1096e+01, -1.3388e+01, -8.6032e-04, -8.0836e+00,\n",
            "          -8.7992e+00, -1.9860e+01, -7.9875e+00, -1.8640e+01, -9.7336e+00],\n",
            "         [-2.6128e+01, -2.6106e+01, -1.4445e+01, -2.2573e-03, -7.4867e+00,\n",
            "          -9.6512e+00, -2.4307e+01, -9.7963e+00, -1.9906e+01, -6.4543e+00]],\n",
            "\n",
            "        [[-2.0411e+01, -2.0352e+01, -1.6672e+01, -1.4750e+01, -1.4612e+01,\n",
            "          -1.5829e+01, -1.8730e+01, -1.8267e+01, -2.1060e+01, -9.5367e-07],\n",
            "         [-2.9182e+01, -2.8986e+01, -2.0730e+01, -8.2678e-02, -3.6607e+00,\n",
            "          -9.0347e+00, -2.6141e+01, -8.6244e+00, -2.3076e+01, -2.9311e+00]],\n",
            "\n",
            "        [[-1.5550e+01, -1.5530e+01, -8.5814e+00, -1.3897e+00, -7.4465e+00,\n",
            "          -7.8339e+00, -1.6012e+01, -6.9391e+00, -1.2770e+01, -2.8939e-01],\n",
            "         [-3.1618e+01, -3.1487e+01, -2.1128e+01, -6.4848e-05, -1.2948e+01,\n",
            "          -1.3617e+01, -2.8903e+01, -1.4911e+01, -2.7877e+01, -9.7066e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10651, 2316], [7391, 856], [19520, 856]]\n",
            "[[5, 5], [4, 9], [4, 9]]\n",
            "tensor([[[-1.9858e+01, -2.0006e+01, -1.2056e+01, -1.3895e+01, -1.1953e+01,\n",
            "          -1.8120e-05, -2.0098e+01, -1.2242e+01, -1.6152e+01, -1.7939e+01],\n",
            "         [-1.9544e+01, -1.9625e+01, -9.6471e+00, -1.7113e+01, -1.5067e+01,\n",
            "          -6.5563e-05, -2.0384e+01, -1.6086e+01, -1.5628e+01, -1.4728e+01]],\n",
            "\n",
            "        [[-1.4253e+01, -1.4426e+01, -1.2954e+01, -7.8789e+00, -1.0415e-03,\n",
            "          -1.1563e+01, -1.3649e+01, -9.0619e+00, -9.5105e+00, -7.6888e+00],\n",
            "         [-3.3053e+01, -3.3143e+01, -2.5792e+01, -1.4879e+01, -1.4970e+01,\n",
            "          -1.8972e+01, -3.3600e+01, -2.3864e+01, -2.5089e+01, -7.1526e-07]],\n",
            "\n",
            "        [[-1.5721e+01, -1.5704e+01, -1.0419e+01, -8.8289e+00, -3.1967e-04,\n",
            "          -1.0814e+01, -1.4746e+01, -1.0325e+01, -1.0016e+01, -1.0007e+01],\n",
            "         [-3.6529e+01, -3.6413e+01, -2.6069e+01, -2.1781e+01, -2.2850e+01,\n",
            "          -2.2804e+01, -3.6009e+01, -2.5065e+01, -2.9040e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[7809, 334], [7391, 5289], [20095, 3174]]\n",
            "[[9, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.8673e+01, -2.8638e+01, -2.2670e+01, -1.8508e+01, -1.8084e+01,\n",
            "          -1.9144e+01, -2.9657e+01, -2.4243e+01, -2.4066e+01,  0.0000e+00],\n",
            "         [-2.9896e+01, -2.9927e+01, -2.4244e+01, -1.7471e+01, -1.5650e+01,\n",
            "          -1.4930e+01, -2.9403e+01, -1.7540e+01, -2.4443e+01, -4.7684e-07]],\n",
            "\n",
            "        [[-1.4253e+01, -1.4426e+01, -1.2954e+01, -7.8789e+00, -1.0415e-03,\n",
            "          -1.1563e+01, -1.3649e+01, -9.0619e+00, -9.5105e+00, -7.6888e+00],\n",
            "         [-2.9434e+01, -2.9614e+01, -2.4139e+01, -1.5641e+01, -1.4145e+01,\n",
            "          -1.8760e+01, -2.9114e+01, -1.9089e+01, -2.4971e+01, -8.3446e-07]],\n",
            "\n",
            "        [[-2.2857e+01, -2.2819e+01, -1.9670e+01, -1.3620e+01, -2.2650e-06,\n",
            "          -1.5634e+01, -2.2965e+01, -1.5216e+01, -1.8182e+01, -1.4288e+01],\n",
            "         [-2.4057e+01, -2.4250e+01, -2.3324e+01, -2.4395e+01, -2.0540e+01,\n",
            "          -2.2871e+01, -2.3660e+01, -2.4664e+01, -2.2350e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[21742, 83], [7312, 12125], [12936, 3174]]\n",
            "[[4, 9], [9, 9], [4, 9]]\n",
            "tensor([[[-1.4756e+01, -1.4554e+01, -9.1699e+00, -5.0616e+00, -9.7517e-03,\n",
            "          -9.7068e+00, -1.2745e+01, -6.4833e+00, -1.2513e+01, -6.3964e+00],\n",
            "         [-2.3859e+01, -2.3877e+01, -1.8654e+01, -1.7820e+01, -1.8093e+01,\n",
            "          -1.7224e+01, -2.4127e+01, -1.8107e+01, -2.1395e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.1763e+01, -2.1582e+01, -1.0183e+01, -6.8295e+00, -8.8063e+00,\n",
            "          -1.1386e+01, -2.0023e+01, -7.4561e+00, -1.5922e+01, -1.8601e-03],\n",
            "         [-3.1787e+01, -3.1851e+01, -2.2741e+01, -2.1002e+01, -1.6878e+01,\n",
            "          -1.9208e+01, -3.1642e+01, -2.4678e+01, -2.8060e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6028e+01, -1.6086e+01, -1.4697e+01, -1.1903e+01, -1.8596e-05,\n",
            "          -1.2545e+01, -1.5384e+01, -1.3381e+01, -1.2570e+01, -1.2932e+01],\n",
            "         [-2.5497e+01, -2.5536e+01, -2.3151e+01, -2.1224e+01, -1.8090e+01,\n",
            "          -2.1388e+01, -2.5897e+01, -1.9461e+01, -2.3739e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 5375], [10230, 6065], [20276, 5375]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9565e+01, -3.9592e+01, -3.2438e+01, -2.7610e+01, -2.7614e+01,\n",
            "          -3.0131e+01, -3.8915e+01, -3.3413e+01, -3.4864e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6614e+01, -1.6688e+01, -1.1797e+01, -7.1151e+00, -1.3820e-03,\n",
            "          -9.3631e+00, -1.6838e+01, -8.2764e+00, -1.1912e+01, -8.4516e+00],\n",
            "         [-2.9942e+01, -3.0122e+01, -2.6037e+01, -2.2523e+01, -1.9545e+01,\n",
            "          -2.1720e+01, -3.0965e+01, -2.5221e+01, -2.6389e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.3645e+01, -2.3561e+01, -1.8143e+01, -7.0247e+00, -2.8777e-03,\n",
            "          -1.2930e+01, -2.3144e+01, -6.4467e+00, -1.7163e+01, -7.8342e+00],\n",
            "         [-3.4792e+01, -3.4608e+01, -2.8919e+01, -2.3598e+01, -2.4343e+01,\n",
            "          -2.5593e+01, -3.6166e+01, -2.4990e+01, -2.7838e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 6065], [9748, 856], [9133, 3174]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.8363e+01, -3.8539e+01, -3.1546e+01, -2.5534e+01, -2.3701e+01,\n",
            "          -2.8111e+01, -3.7296e+01, -3.1139e+01, -3.3455e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.6847e+01, -2.6885e+01, -2.1020e+01, -1.1624e+01, -2.3484e-05,\n",
            "          -1.8075e+01, -2.7296e+01, -1.2245e+01, -2.0109e+01, -1.1540e+01],\n",
            "         [-3.6790e+01, -3.6777e+01, -2.9606e+01, -2.0856e+01, -2.1619e+01,\n",
            "          -2.6243e+01, -3.7594e+01, -2.6143e+01, -2.9773e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4288e+01, -2.4427e+01, -2.0573e+01, -1.1336e+01, -1.4305e-05,\n",
            "          -1.4787e+01, -2.2645e+01, -1.3276e+01, -1.9085e+01, -1.5335e+01],\n",
            "         [-2.7775e+01, -2.7985e+01, -2.4816e+01, -2.4925e+01, -2.2444e+01,\n",
            "          -2.5490e+01, -2.8796e+01, -2.2130e+01, -2.4769e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[19886, 83], [2581, 5375], [2515, 856]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-1.9887e+01, -1.9891e+01, -1.3965e+01, -9.3439e+00, -1.7558e-04,\n",
            "          -1.3598e+01, -1.7420e+01, -1.0518e+01, -1.2557e+01, -9.8007e+00],\n",
            "         [-2.9424e+01, -2.9592e+01, -2.4874e+01, -1.9896e+01, -2.1359e+01,\n",
            "          -2.0095e+01, -2.9731e+01, -2.2609e+01, -2.4857e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9373e+01, -1.9268e+01, -1.3371e+01, -1.0346e+01, -1.5401e-04,\n",
            "          -1.0024e+01, -1.6774e+01, -1.0388e+01, -1.2815e+01, -1.0069e+01],\n",
            "         [-3.4164e+01, -3.4041e+01, -2.8739e+01, -2.4885e+01, -2.3707e+01,\n",
            "          -2.4682e+01, -3.3575e+01, -2.9333e+01, -2.7953e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2561e+01, -2.2360e+01, -1.4602e+01, -3.9936e+00, -2.1585e-02,\n",
            "          -6.8231e+00, -2.1819e+01, -6.6493e+00, -1.5958e+01, -7.5303e+00],\n",
            "         [-4.0421e+01, -4.0404e+01, -3.0852e+01, -2.2015e+01, -2.3729e+01,\n",
            "          -2.5553e+01, -4.1231e+01, -2.7433e+01, -3.2912e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 83], [19594, 12138], [20367, 12138]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.6118e+01, -3.6221e+01, -2.9131e+01, -2.2716e+01, -2.3236e+01,\n",
            "          -2.4779e+01, -3.5871e+01, -2.9851e+01, -3.2186e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.4576e+01, -1.4681e+01, -8.9929e+00, -4.0921e+00, -3.7534e-02,\n",
            "          -8.9910e+00, -1.3911e+01, -6.2763e+00, -1.0691e+01, -4.0185e+00],\n",
            "         [-3.8202e+01, -3.8331e+01, -3.0988e+01, -2.4157e+01, -2.4775e+01,\n",
            "          -2.6713e+01, -4.0893e+01, -2.6838e+01, -3.1323e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4349e+01, -2.4246e+01, -1.9354e+01, -1.0259e+01, -3.5089e-04,\n",
            "          -9.1062e+00, -2.2617e+01, -1.2673e+01, -1.9680e+01, -8.5085e+00],\n",
            "         [-4.2414e+01, -4.2435e+01, -3.3905e+01, -2.3552e+01, -2.5962e+01,\n",
            "          -2.8592e+01, -4.4925e+01, -2.9250e+01, -3.6302e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23499, 2316], [12936, 20705], [21487, 5289]]\n",
            "[[5, 5], [4, 9], [4, 9]]\n",
            "tensor([[[-1.8587e+01, -1.8519e+01, -1.2025e+01, -1.2215e+01, -1.5422e+01,\n",
            "          -2.5987e-05, -1.8890e+01, -1.1607e+01, -1.6991e+01, -1.2078e+01],\n",
            "         [-2.1641e+01, -2.1599e+01, -1.1152e+01, -1.3796e+01, -1.7391e+01,\n",
            "          -2.0061e-04, -2.2523e+01, -1.4123e+01, -1.8155e+01, -8.5988e+00]],\n",
            "\n",
            "        [[-1.6028e+01, -1.6086e+01, -1.4697e+01, -1.1903e+01, -1.8596e-05,\n",
            "          -1.2545e+01, -1.5384e+01, -1.3381e+01, -1.2570e+01, -1.2932e+01],\n",
            "         [-3.6398e+01, -3.6283e+01, -2.8026e+01, -2.0114e+01, -2.1724e+01,\n",
            "          -2.3922e+01, -3.8089e+01, -2.6202e+01, -3.0721e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9835e+01, -1.9828e+01, -1.6228e+01, -5.8130e+00, -3.2391e-03,\n",
            "          -1.1620e+01, -1.9481e+01, -9.4855e+00, -1.3041e+01, -8.7500e+00],\n",
            "         [-3.9359e+01, -3.9496e+01, -3.2666e+01, -2.3544e+01, -2.4147e+01,\n",
            "          -2.8418e+01, -4.0033e+01, -2.7822e+01, -3.3766e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10555, 3174], [21878, 22355], [9167, 5375]]\n",
            "[[4, 9], [9, 9], [4, 9]]\n",
            "tensor([[[-2.0270e+01, -2.0199e+01, -1.6703e+01, -7.6534e+00, -6.3542e-04,\n",
            "          -1.0509e+01, -2.0443e+01, -1.1324e+01, -1.5882e+01, -9.0170e+00],\n",
            "         [-3.2012e+01, -3.2222e+01, -3.0055e+01, -2.7308e+01, -2.5394e+01,\n",
            "          -3.0202e+01, -3.3401e+01, -2.6368e+01, -3.0233e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.8637e+01, -1.8822e+01, -1.4818e+01, -1.0703e+01, -1.2435e+01,\n",
            "          -1.0920e+01, -1.7847e+01, -9.3522e+00, -1.4511e+01, -1.3231e-04],\n",
            "         [-2.0885e+01, -2.0983e+01, -1.5537e+01, -1.2136e+01, -1.7409e+01,\n",
            "          -9.3336e+00, -2.4753e+01, -8.4562e+00, -1.8141e+01, -3.0668e-04]],\n",
            "\n",
            "        [[-1.7583e+01, -1.7614e+01, -1.3136e+01, -4.9852e+00, -1.5151e-02,\n",
            "          -7.1683e+00, -1.6918e+01, -5.0371e+00, -1.1431e+01, -6.9888e+00],\n",
            "         [-3.3596e+01, -3.3606e+01, -2.8225e+01, -2.5820e+01, -2.7228e+01,\n",
            "          -2.5475e+01, -3.3829e+01, -2.9143e+01, -2.9566e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 5375], [13981, 6065], [3081, 23353]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9565e+01, -3.9592e+01, -3.2438e+01, -2.7610e+01, -2.7614e+01,\n",
            "          -3.0131e+01, -3.8915e+01, -3.3413e+01, -3.4864e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.7053e+01, -1.7007e+01, -1.3054e+01, -6.6683e+00, -2.2637e-03,\n",
            "          -1.4252e+01, -1.5650e+01, -6.9834e+00, -1.2145e+01, -9.8042e+00],\n",
            "         [-2.9456e+01, -2.9655e+01, -2.5702e+01, -2.0470e+01, -2.0158e+01,\n",
            "          -2.4257e+01, -2.9354e+01, -2.4394e+01, -2.4971e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2452e+01, -2.2653e+01, -2.0143e+01, -1.7722e+01, -1.4712e+01,\n",
            "          -1.8081e+01, -2.3268e+01, -1.7160e+01, -2.0308e+01, -3.5763e-07],\n",
            "         [-2.2409e+01, -2.2211e+01, -1.7506e+01, -1.9198e+01, -1.3924e+01,\n",
            "          -1.6402e+01, -2.2993e+01, -1.5643e+01, -1.8031e+01, -1.1921e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1518, 12138], [13800, 989], [19129, 12138]]\n",
            "[[4, 9], [3, 3], [4, 9]]\n",
            "tensor([[[-2.1628e+01, -2.1564e+01, -1.4911e+01, -1.0958e+01, -4.4583e-05,\n",
            "          -1.1140e+01, -2.0550e+01, -1.1761e+01, -1.6820e+01, -1.2303e+01],\n",
            "         [-3.6153e+01, -3.6321e+01, -2.7680e+01, -2.0675e+01, -2.0783e+01,\n",
            "          -2.1759e+01, -3.7694e+01, -2.6475e+01, -2.9583e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.5391e+01, -1.5361e+01, -9.8209e+00, -4.6040e-03, -8.6086e+00,\n",
            "          -6.4693e+00, -1.4038e+01, -7.8556e+00, -1.2959e+01, -6.0260e+00],\n",
            "         [-2.2881e+01, -2.3008e+01, -1.7770e+01, -3.5816e-04, -1.0816e+01,\n",
            "          -9.9465e+00, -2.1533e+01, -1.0945e+01, -1.8618e+01, -8.2083e+00]],\n",
            "\n",
            "        [[-2.3255e+01, -2.3292e+01, -1.8551e+01, -1.1060e+01, -2.0027e-05,\n",
            "          -1.2785e+01, -2.3335e+01, -1.3894e+01, -1.8252e+01, -1.4407e+01],\n",
            "         [-3.9004e+01, -3.9082e+01, -2.9512e+01, -1.9426e+01, -1.8967e+01,\n",
            "          -2.3317e+01, -4.1321e+01, -2.7006e+01, -3.2808e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10777, 6065], [3168, 2316], [20367, 5289]]\n",
            "[[4, 9], [5, 5], [4, 9]]\n",
            "tensor([[[-1.4419e+01, -1.4450e+01, -7.9839e+00, -5.0016e+00, -2.9316e-02,\n",
            "          -4.8991e+00, -1.2862e+01, -5.0623e+00, -1.0561e+01, -4.8272e+00],\n",
            "         [-3.1372e+01, -3.1649e+01, -2.5110e+01, -2.4192e+01, -1.9984e+01,\n",
            "          -2.1410e+01, -3.2700e+01, -2.3717e+01, -2.7268e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.0605e+01, -2.0616e+01, -1.3835e+01, -1.4602e+01, -1.4285e+01,\n",
            "          -2.5034e-06, -1.8635e+01, -1.4648e+01, -1.7846e+01, -1.7025e+01],\n",
            "         [-1.9017e+01, -1.9096e+01, -1.0111e+01, -1.5549e+01, -1.4634e+01,\n",
            "          -7.0093e-05, -1.9136e+01, -1.5832e+01, -1.4775e+01, -1.0473e+01]],\n",
            "\n",
            "        [[-2.4349e+01, -2.4246e+01, -1.9354e+01, -1.0259e+01, -3.5089e-04,\n",
            "          -9.1062e+00, -2.2617e+01, -1.2673e+01, -1.9680e+01, -8.5085e+00],\n",
            "         [-3.5499e+01, -3.5546e+01, -2.7789e+01, -2.3248e+01, -2.1304e+01,\n",
            "          -2.4086e+01, -3.5790e+01, -2.7115e+01, -3.0844e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[5874, 20705], [3168, 2316], [1146, 3174]]\n",
            "[[4, 9], [5, 5], [4, 9]]\n",
            "tensor([[[-2.3656e+01, -2.3601e+01, -1.7502e+01, -4.6232e+00, -1.0057e-02,\n",
            "          -8.9667e+00, -2.2273e+01, -1.0484e+01, -1.7352e+01, -1.0431e+01],\n",
            "         [-4.3551e+01, -4.3488e+01, -3.1373e+01, -2.2696e+01, -2.6046e+01,\n",
            "          -2.3638e+01, -4.3045e+01, -2.8112e+01, -3.4616e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.0605e+01, -2.0616e+01, -1.3835e+01, -1.4602e+01, -1.4285e+01,\n",
            "          -2.5034e-06, -1.8635e+01, -1.4648e+01, -1.7846e+01, -1.7025e+01],\n",
            "         [-1.9017e+01, -1.9096e+01, -1.0111e+01, -1.5549e+01, -1.4634e+01,\n",
            "          -7.0093e-05, -1.9136e+01, -1.5832e+01, -1.4775e+01, -1.0473e+01]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.6429e+01, -3.6476e+01, -3.0999e+01, -2.6643e+01, -2.5642e+01,\n",
            "          -2.9319e+01, -3.6573e+01, -2.8563e+01, -3.3307e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 5375], [21357, 12138], [4585, 12125]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9565e+01, -3.9592e+01, -3.2438e+01, -2.7610e+01, -2.7614e+01,\n",
            "          -3.0131e+01, -3.8915e+01, -3.3413e+01, -3.4864e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9135e+01, -1.9184e+01, -1.1979e+01, -6.7449e+00, -3.9474e-03,\n",
            "          -7.3511e+00, -1.9379e+01, -1.0499e+01, -1.2496e+01, -6.1738e+00],\n",
            "         [-3.5421e+01, -3.5516e+01, -2.8606e+01, -2.1751e+01, -2.1380e+01,\n",
            "          -2.2202e+01, -3.8305e+01, -2.4049e+01, -2.9720e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9707e+01, -1.9763e+01, -1.3635e+01, -1.0708e+01, -1.3149e+01,\n",
            "          -1.1668e+01, -1.9250e+01, -1.6784e+01, -1.5948e+01, -3.4212e-05],\n",
            "         [-3.3339e+01, -3.3438e+01, -2.6124e+01, -1.8946e+01, -1.7042e+01,\n",
            "          -1.9323e+01, -3.3760e+01, -2.4799e+01, -3.0311e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[21487, 5289], [16170, 5474], [3218, 83]]\n",
            "[[4, 9], [3, 3], [4, 9]]\n",
            "tensor([[[-1.9835e+01, -1.9828e+01, -1.6228e+01, -5.8130e+00, -3.2391e-03,\n",
            "          -1.1620e+01, -1.9481e+01, -9.4855e+00, -1.3041e+01, -8.7500e+00],\n",
            "         [-3.9359e+01, -3.9496e+01, -3.2666e+01, -2.3544e+01, -2.4147e+01,\n",
            "          -2.8418e+01, -4.0033e+01, -2.7822e+01, -3.3766e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.7719e+01, -1.7732e+01, -1.1721e+01, -3.9328e-03, -7.7302e+00,\n",
            "          -6.2723e+00, -1.5591e+01, -7.0913e+00, -1.5000e+01, -7.1862e+00],\n",
            "         [-2.7013e+01, -2.7011e+01, -1.7124e+01, -2.3365e-05, -1.4491e+01,\n",
            "          -1.2828e+01, -2.4259e+01, -1.1253e+01, -2.2581e+01, -1.1864e+01]],\n",
            "\n",
            "        [[-2.8237e+01, -2.8119e+01, -2.0784e+01, -9.8592e+00, -5.9960e-05,\n",
            "          -1.3710e+01, -2.6156e+01, -1.2613e+01, -2.1594e+01, -1.2637e+01],\n",
            "         [-3.8258e+01, -3.8513e+01, -3.1681e+01, -2.4165e+01, -2.5190e+01,\n",
            "          -2.6765e+01, -3.8053e+01, -3.0648e+01, -3.2881e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[9584, 16423], [22206, 11226], [22930, 12912]]\n",
            "[[9, 9], [3, 3], [4, 9]]\n",
            "tensor([[[-2.0264e+01, -2.0272e+01, -1.4999e+01, -1.0159e+01, -9.4988e+00,\n",
            "          -1.1331e+01, -1.8555e+01, -1.2124e+01, -1.7654e+01, -1.3148e-04],\n",
            "         [-3.0671e+01, -3.0769e+01, -2.2005e+01, -1.6907e+01, -2.2089e+01,\n",
            "          -1.7321e+01, -3.0874e+01, -1.9415e+01, -2.5717e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.5388e+01, -1.5361e+01, -1.1357e+01, -3.7133e-03, -7.5294e+00,\n",
            "          -9.7123e+00, -1.2493e+01, -8.8489e+00, -1.2645e+01, -5.8273e+00],\n",
            "         [-2.3565e+01, -2.3472e+01, -1.6833e+01, -1.1325e-05, -1.2014e+01,\n",
            "          -1.4963e+01, -2.2601e+01, -1.2824e+01, -1.9102e+01, -1.3020e+01]],\n",
            "\n",
            "        [[-1.3289e+01, -1.3360e+01, -9.2627e+00, -3.7936e+00, -5.7540e-02,\n",
            "          -7.1094e+00, -1.1482e+01, -3.6184e+00, -7.9572e+00, -5.2402e+00],\n",
            "         [-2.5428e+01, -2.5491e+01, -1.8557e+01, -7.9972e+00, -1.2261e+01,\n",
            "          -1.5069e+01, -2.6981e+01, -1.0397e+01, -1.8795e+01, -3.7198e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6106, 5289], [1030, 22355], [18409, 9376]]\n",
            "[[4, 9], [9, 9], [9, 9]]\n",
            "tensor([[[-1.3998e+01, -1.4095e+01, -1.0076e+01, -3.0727e+00, -5.9630e-02,\n",
            "          -5.1473e+00, -1.3104e+01, -7.1760e+00, -1.0342e+01, -5.3115e+00],\n",
            "         [-3.1649e+01, -3.1713e+01, -2.6057e+01, -1.7328e+01, -1.5605e+01,\n",
            "          -2.0135e+01, -3.0490e+01, -2.1794e+01, -2.6405e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-2.4045e+01, -2.4066e+01, -1.8618e+01, -1.3539e+01, -1.6208e+01,\n",
            "          -1.5032e+01, -2.4571e+01, -1.8323e+01, -1.9435e+01, -1.6689e-06],\n",
            "         [-2.6298e+01, -2.6396e+01, -1.9006e+01, -1.4643e+01, -2.0742e+01,\n",
            "          -1.1744e+01, -2.8574e+01, -1.4979e+01, -2.2852e+01, -8.7022e-06]],\n",
            "\n",
            "        [[-1.9942e+01, -1.9935e+01, -1.3876e+01, -7.4703e+00, -1.0940e+01,\n",
            "          -1.2151e+01, -2.0100e+01, -1.3053e+01, -1.6771e+01, -5.9599e-04],\n",
            "         [-2.7963e+01, -2.8000e+01, -2.0651e+01, -8.9417e+00, -1.4457e+01,\n",
            "          -1.2674e+01, -2.6178e+01, -1.1640e+01, -2.2658e+01, -1.4316e-04]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[14749, 83], [7069, 12125], [19520, 856]]\n",
            "[[4, 9], [9, 9], [4, 9]]\n",
            "tensor([[[-2.0226e+01, -2.0207e+01, -1.6364e+01, -1.0358e+01, -2.0061e-04,\n",
            "          -1.5202e+01, -2.0012e+01, -8.7062e+00, -1.4265e+01, -1.2995e+01],\n",
            "         [-3.0671e+01, -3.0882e+01, -2.4655e+01, -2.2789e+01, -2.2458e+01,\n",
            "          -2.1243e+01, -3.0998e+01, -2.4790e+01, -2.5532e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.5514e+01, -2.5513e+01, -1.6627e+01, -1.3153e+01, -1.3407e+01,\n",
            "          -1.3534e+01, -2.5917e+01, -1.7398e+01, -1.8658e+01, -4.8876e-06],\n",
            "         [-3.2513e+01, -3.2563e+01, -2.5245e+01, -1.9634e+01, -1.8795e+01,\n",
            "          -1.8060e+01, -3.1790e+01, -2.5258e+01, -2.7951e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.5721e+01, -1.5704e+01, -1.0419e+01, -8.8289e+00, -3.1967e-04,\n",
            "          -1.0814e+01, -1.4746e+01, -1.0325e+01, -1.0016e+01, -1.0007e+01],\n",
            "         [-3.6529e+01, -3.6413e+01, -2.6069e+01, -2.1781e+01, -2.2850e+01,\n",
            "          -2.2804e+01, -3.6009e+01, -2.5065e+01, -2.9040e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6533, 6289], [1518, 856], [2333, 919]]\n",
            "[[9, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.9149e+01, -2.9131e+01, -2.2779e+01, -1.3121e+01, -1.5339e+01,\n",
            "          -1.5961e+01, -2.8419e+01, -1.9958e+01, -2.4099e+01, -2.3842e-06],\n",
            "         [-3.7084e+01, -3.7164e+01, -2.3974e+01, -1.1265e+01, -2.1356e+01,\n",
            "          -1.4891e+01, -3.7537e+01, -1.6343e+01, -3.0062e+01, -1.3232e-05]],\n",
            "\n",
            "        [[-2.1628e+01, -2.1564e+01, -1.4911e+01, -1.0958e+01, -4.4583e-05,\n",
            "          -1.1140e+01, -2.0550e+01, -1.1761e+01, -1.6820e+01, -1.2303e+01],\n",
            "         [-3.4465e+01, -3.4553e+01, -2.6000e+01, -1.8685e+01, -1.9476e+01,\n",
            "          -2.1062e+01, -3.4601e+01, -2.4400e+01, -2.7800e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.1268e+01, -2.1160e+01, -1.4705e+01, -1.0938e+01, -1.2436e+01,\n",
            "          -1.1279e+01, -2.0924e+01, -1.4771e+01, -1.4642e+01, -3.5524e-05],\n",
            "         [-2.9733e+01, -2.9764e+01, -2.3993e+01, -1.4438e+01, -1.9732e+01,\n",
            "          -1.7470e+01, -2.8601e+01, -2.3421e+01, -2.5742e+01, -5.9605e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[4452, 12125], [11804, 6065], [14248, 4712]]\n",
            "[[9, 9], [4, 9], [9, 7]]\n",
            "tensor([[[-2.7318e+01, -2.7295e+01, -1.9271e+01, -1.5212e+01, -1.5169e+01,\n",
            "          -1.6853e+01, -2.7794e+01, -1.9107e+01, -2.4048e+01, -4.7684e-07],\n",
            "         [-3.9787e+01, -3.9853e+01, -3.0692e+01, -2.2140e+01, -2.3225e+01,\n",
            "          -2.3579e+01, -3.9119e+01, -2.9684e+01, -3.5668e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.0394e+01, -2.0182e+01, -1.5940e+01, -4.2186e+00, -1.6973e-02,\n",
            "          -1.3932e+01, -1.9156e+01, -1.0920e+01, -1.7539e+01, -6.1698e+00],\n",
            "         [-3.4336e+01, -3.4373e+01, -2.9358e+01, -2.3059e+01, -2.1022e+01,\n",
            "          -2.7362e+01, -3.4465e+01, -2.6126e+01, -3.0756e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6585e+01, -1.6578e+01, -1.5117e+01, -1.3923e+01, -1.7339e+01,\n",
            "          -1.4443e+01, -1.6512e+01, -9.2114e+00, -1.4865e+01, -1.0228e-04],\n",
            "         [-2.4727e+01, -2.4547e+01, -2.1299e+01, -1.5537e+01, -1.8323e+01,\n",
            "          -1.6003e+01, -2.4755e+01, -8.1062e-06, -2.1514e+01, -1.1773e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10684, 6065], [3218, 5375], [7632, 11206]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-1.8711e+01, -1.8638e+01, -1.3245e+01, -9.5820e+00, -2.8022e-04,\n",
            "          -1.1356e+01, -1.9190e+01, -1.1183e+01, -1.4234e+01, -8.6053e+00],\n",
            "         [-3.0101e+01, -3.0233e+01, -2.4841e+01, -2.2004e+01, -1.8459e+01,\n",
            "          -2.0706e+01, -3.0168e+01, -2.4360e+01, -2.5928e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.8237e+01, -2.8119e+01, -2.0784e+01, -9.8592e+00, -5.9960e-05,\n",
            "          -1.3710e+01, -2.6156e+01, -1.2613e+01, -2.1594e+01, -1.2637e+01],\n",
            "         [-3.6474e+01, -3.6472e+01, -3.1055e+01, -2.4787e+01, -2.3956e+01,\n",
            "          -2.5748e+01, -3.6097e+01, -3.1409e+01, -3.0466e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2297e+01, -2.2273e+01, -1.6208e+01, -1.0494e+01, -1.0677e+01,\n",
            "          -1.6189e+01, -2.2053e+01, -1.4990e+01, -1.7027e+01, -5.1378e-05],\n",
            "         [-2.8132e+01, -2.8207e+01, -2.2172e+01, -1.8037e+01, -2.0835e+01,\n",
            "          -2.0803e+01, -2.8862e+01, -1.6674e+01, -2.3066e+01, -1.1921e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[3045, 856], [20367, 12138], [12936, 83]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.0506e+01, -2.0485e+01, -1.1964e+01, -5.6374e+00, -4.9184e-03,\n",
            "          -9.9924e+00, -2.0539e+01, -7.5664e+00, -1.4549e+01, -7.1639e+00],\n",
            "         [-3.6293e+01, -3.6202e+01, -2.7800e+01, -2.3172e+01, -2.2849e+01,\n",
            "          -2.4842e+01, -3.7034e+01, -2.5179e+01, -2.9077e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4349e+01, -2.4246e+01, -1.9354e+01, -1.0259e+01, -3.5089e-04,\n",
            "          -9.1062e+00, -2.2617e+01, -1.2673e+01, -1.9680e+01, -8.5085e+00],\n",
            "         [-4.2414e+01, -4.2435e+01, -3.3905e+01, -2.3552e+01, -2.5962e+01,\n",
            "          -2.8592e+01, -4.4925e+01, -2.9250e+01, -3.6302e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6028e+01, -1.6086e+01, -1.4697e+01, -1.1903e+01, -1.8596e-05,\n",
            "          -1.2545e+01, -1.5384e+01, -1.3381e+01, -1.2570e+01, -1.2932e+01],\n",
            "         [-2.8176e+01, -2.8394e+01, -2.3410e+01, -1.8037e+01, -1.7985e+01,\n",
            "          -1.9449e+01, -2.8971e+01, -2.1632e+01, -2.4113e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[23499, 2316], [18438, 83], [1146, 83]]\n",
            "[[5, 5], [4, 9], [4, 9]]\n",
            "tensor([[[-1.8587e+01, -1.8519e+01, -1.2025e+01, -1.2215e+01, -1.5422e+01,\n",
            "          -2.5987e-05, -1.8890e+01, -1.1607e+01, -1.6991e+01, -1.2078e+01],\n",
            "         [-2.1641e+01, -2.1599e+01, -1.1152e+01, -1.3796e+01, -1.7391e+01,\n",
            "          -2.0061e-04, -2.2523e+01, -1.4123e+01, -1.8155e+01, -8.5988e+00]],\n",
            "\n",
            "        [[-1.8150e+01, -1.8072e+01, -8.3065e+00, -2.3966e+00, -1.8891e-01,\n",
            "          -3.1262e+00, -1.6266e+01, -6.9960e+00, -1.1251e+01, -3.3227e+00],\n",
            "         [-3.4747e+01, -3.4902e+01, -2.6171e+01, -1.9603e+01, -2.2781e+01,\n",
            "          -2.0262e+01, -3.3737e+01, -2.4682e+01, -2.9972e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.6118e+01, -3.6221e+01, -2.9131e+01, -2.2716e+01, -2.3236e+01,\n",
            "          -2.4779e+01, -3.5871e+01, -2.9851e+01, -3.2186e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[18974, 3174], [14369, 5289], [21608, 19]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.1346e+01, -2.1413e+01, -1.5614e+01, -6.0617e+00, -3.4490e-03,\n",
            "          -8.5510e+00, -2.0791e+01, -7.1105e+00, -1.6949e+01, -9.1851e+00],\n",
            "         [-2.8440e+01, -2.8669e+01, -2.6282e+01, -2.4165e+01, -2.2575e+01,\n",
            "          -2.6233e+01, -3.0175e+01, -2.2685e+01, -2.6900e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.3101e+01, -2.3132e+01, -1.5487e+01, -1.1573e+01, -2.8371e-05,\n",
            "          -1.1848e+01, -2.1559e+01, -1.2211e+01, -1.7069e+01, -1.1934e+01],\n",
            "         [-3.4015e+01, -3.4135e+01, -2.8344e+01, -2.3754e+01, -2.2806e+01,\n",
            "          -2.4522e+01, -3.4137e+01, -2.5505e+01, -2.8402e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.3992e+01, -1.3813e+01, -9.7736e+00, -6.3967e+00, -6.3442e+00,\n",
            "          -6.4321e+00, -1.2547e+01, -1.0926e+01, -1.0572e+01, -5.1519e-03],\n",
            "         [-3.2652e+01, -3.2647e+01, -2.6579e+01, -2.1722e+01, -2.4508e+01,\n",
            "          -1.9881e+01, -3.3763e+01, -2.2693e+01, -2.9783e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[21989, 12125], [3713, 83], [4079, 3174]]\n",
            "[[9, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.2964e+01, -2.3116e+01, -1.6787e+01, -7.9625e+00, -9.4250e+00,\n",
            "          -1.1858e+01, -2.2629e+01, -1.5980e+01, -1.9960e+01, -4.3633e-04],\n",
            "         [-3.3738e+01, -3.3872e+01, -2.4663e+01, -1.7958e+01, -1.8498e+01,\n",
            "          -1.6339e+01, -3.3371e+01, -2.5359e+01, -3.0879e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-1.8399e+01, -1.8327e+01, -1.2589e+01, -3.9974e+00, -2.0224e-02,\n",
            "          -1.0593e+01, -1.7292e+01, -6.9613e+00, -1.3625e+01, -7.2952e+00],\n",
            "         [-3.3442e+01, -3.3555e+01, -2.7156e+01, -1.9502e+01, -2.2277e+01,\n",
            "          -2.0561e+01, -3.2622e+01, -2.3894e+01, -2.8181e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.3138e+01, -1.3158e+01, -6.7695e+00, -3.6393e-02, -4.7209e+00,\n",
            "          -3.7495e+00, -1.0899e+01, -6.5031e+00, -8.8223e+00, -7.6329e+00],\n",
            "         [-3.0374e+01, -3.0524e+01, -2.4633e+01, -1.8815e+01, -2.1974e+01,\n",
            "          -2.2167e+01, -3.0732e+01, -1.9249e+01, -2.6532e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[6687, 22623], [10651, 2316], [4178, 3174]]\n",
            "[[5, 5], [5, 5], [4, 9]]\n",
            "tensor([[[-1.4969e+01, -1.4924e+01, -8.9375e+00, -1.0281e+01, -1.2562e+01,\n",
            "          -1.9976e-03, -1.4340e+01, -8.1860e+00, -1.2146e+01, -6.4751e+00],\n",
            "         [-1.9210e+01, -1.9153e+01, -9.4616e+00, -1.3847e+01, -1.4549e+01,\n",
            "          -8.1536e-05, -2.0981e+01, -1.5107e+01, -1.6701e+01, -1.3093e+01]],\n",
            "\n",
            "        [[-1.9858e+01, -2.0006e+01, -1.2056e+01, -1.3895e+01, -1.1953e+01,\n",
            "          -1.8120e-05, -2.0098e+01, -1.2242e+01, -1.6152e+01, -1.7939e+01],\n",
            "         [-1.9544e+01, -1.9625e+01, -9.6471e+00, -1.7113e+01, -1.5067e+01,\n",
            "          -6.5563e-05, -2.0384e+01, -1.6086e+01, -1.5628e+01, -1.4728e+01]],\n",
            "\n",
            "        [[-1.4265e+01, -1.4192e+01, -1.0721e+01, -5.8824e+00, -5.1666e-03,\n",
            "          -7.9433e+00, -1.3054e+01, -6.6142e+00, -1.1182e+01, -7.3706e+00],\n",
            "         [-2.7193e+01, -2.7331e+01, -2.3114e+01, -2.2572e+01, -2.0979e+01,\n",
            "          -2.2468e+01, -2.8553e+01, -1.9020e+01, -2.4715e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12125, 18319], [3627, 13669], [14382, 6065]]\n",
            "[[9, 9], [9, 9], [4, 9]]\n",
            "tensor([[[-2.6674e+01, -2.6801e+01, -1.9866e+01, -1.4095e+01, -1.1763e+01,\n",
            "          -1.5998e+01, -2.6334e+01, -2.0122e+01, -2.3231e+01, -8.5830e-06],\n",
            "         [-3.1788e+01, -3.1989e+01, -2.3398e+01, -1.9374e+01, -2.0929e+01,\n",
            "          -1.9722e+01, -3.2719e+01, -1.6206e+01, -2.6387e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-3.2349e+01, -3.2385e+01, -2.2353e+01, -1.6278e+01, -1.9787e+01,\n",
            "          -1.9607e+01, -3.3838e+01, -2.0038e+01, -2.7460e+01, -1.1921e-07],\n",
            "         [-3.0288e+01, -3.0268e+01, -2.1458e+01, -1.8342e+01, -2.2522e+01,\n",
            "          -1.7364e+01, -3.0134e+01, -2.1878e+01, -2.4635e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6877e+01, -1.6855e+01, -1.0629e+01, -7.0546e+00, -1.1246e-03,\n",
            "          -9.8364e+00, -1.5809e+01, -1.0341e+01, -1.3199e+01, -8.8144e+00],\n",
            "         [-2.6847e+01, -2.7068e+01, -2.3761e+01, -1.9222e+01, -1.7252e+01,\n",
            "          -2.0773e+01, -2.6863e+01, -2.3977e+01, -2.3885e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12518, 3174], [3795, 3174], [2322, 12317]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.1529e+01, -2.1326e+01, -1.6220e+01, -8.5794e+00, -9.7204e-04,\n",
            "          -8.9543e+00, -2.0045e+01, -1.0110e+01, -1.4955e+01, -7.3966e+00],\n",
            "         [-3.3096e+01, -3.3155e+01, -2.8624e+01, -2.5155e+01, -2.5497e+01,\n",
            "          -2.5552e+01, -3.3512e+01, -2.7199e+01, -3.0805e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2493e+01, -2.2410e+01, -1.4330e+01, -6.0312e+00, -3.2306e-03,\n",
            "          -7.2594e+00, -2.0376e+01, -1.2099e+01, -1.7772e+01, -9.0868e+00],\n",
            "         [-2.8500e+01, -2.8685e+01, -2.4442e+01, -2.2192e+01, -2.1027e+01,\n",
            "          -2.2663e+01, -2.8803e+01, -2.1495e+01, -2.5706e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.7032e+01, -2.6967e+01, -2.2771e+01, -1.4796e+01, -2.0139e+01,\n",
            "          -1.7245e+01, -2.7749e+01, -1.7805e+01, -2.4007e+01, -3.5763e-07],\n",
            "         [-2.3606e+01, -2.3635e+01, -1.9535e+01, -2.0155e+01, -2.1966e+01,\n",
            "          -1.5627e+01, -2.4326e+01, -1.3593e+01, -1.8433e+01, -1.3113e-06]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[12573, 5289], [22969, 8061], [1146, 856]]\n",
            "[[3, 9], [7, 7], [4, 9]]\n",
            "tensor([[[-1.7355e+01, -1.7392e+01, -1.2000e+01, -1.1830e-02, -6.3354e+00,\n",
            "          -8.0124e+00, -1.5494e+01, -5.6105e+00, -1.3489e+01, -5.1178e+00],\n",
            "         [-2.8251e+01, -2.8155e+01, -2.1902e+01, -1.7607e+01, -2.0035e+01,\n",
            "          -2.2366e+01, -2.7360e+01, -1.8739e+01, -2.5252e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.7880e+01, -1.7652e+01, -1.3448e+01, -1.2315e+01, -1.2160e+01,\n",
            "          -1.5487e+01, -1.7472e+01, -5.2808e-05, -1.1695e+01, -1.0316e+01],\n",
            "         [-2.4614e+01, -2.4434e+01, -1.7683e+01, -1.1625e+01, -1.4650e+01,\n",
            "          -1.5371e+01, -2.3906e+01, -9.8943e-06, -1.9158e+01, -1.5280e+01]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-4.1235e+01, -4.1243e+01, -3.2273e+01, -2.4428e+01, -2.4203e+01,\n",
            "          -2.8507e+01, -4.1987e+01, -2.9670e+01, -3.3766e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[2026, 20705], [15405, 18070], [5874, 20705]]\n",
            "[[4, 9], [3, 3], [4, 9]]\n",
            "tensor([[[-1.5494e+01, -1.5302e+01, -1.4015e+01, -6.9251e+00, -4.9280e-03,\n",
            "          -7.2401e+00, -1.2798e+01, -5.9412e+00, -1.0885e+01, -7.4803e+00],\n",
            "         [-3.7180e+01, -3.7042e+01, -2.8101e+01, -2.1711e+01, -2.5053e+01,\n",
            "          -2.2238e+01, -3.8565e+01, -2.4169e+01, -3.1308e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.8461e+01, -1.8249e+01, -1.1771e+01, -6.7189e-03, -5.6021e+00,\n",
            "          -9.6427e+00, -1.5200e+01, -6.2523e+00, -1.1761e+01, -6.9081e+00],\n",
            "         [-2.3718e+01, -2.3607e+01, -1.7415e+01, -4.2557e-05, -1.2946e+01,\n",
            "          -1.2458e+01, -2.1327e+01, -1.3232e+01, -1.9407e+01, -1.0273e+01]],\n",
            "\n",
            "        [[-2.3656e+01, -2.3601e+01, -1.7502e+01, -4.6232e+00, -1.0057e-02,\n",
            "          -8.9667e+00, -2.2273e+01, -1.0484e+01, -1.7352e+01, -1.0431e+01],\n",
            "         [-4.3551e+01, -4.3488e+01, -3.1373e+01, -2.2696e+01, -2.6046e+01,\n",
            "          -2.3638e+01, -4.3045e+01, -2.8112e+01, -3.4616e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[10948, 22623], [1146, 6065], [16290, 22930]]\n",
            "[[5, 5], [4, 9], [5, 5]]\n",
            "tensor([[[-1.9865e+01, -1.9882e+01, -1.0687e+01, -1.2714e+01, -1.1471e+01,\n",
            "          -8.1774e-05, -2.1208e+01, -1.0050e+01, -1.6751e+01, -1.3029e+01],\n",
            "         [-2.3570e+01, -2.3544e+01, -7.9134e+00, -1.1282e+01, -1.0816e+01,\n",
            "          -4.8947e-04, -2.5712e+01, -1.5418e+01, -1.7940e+01, -9.3085e+00]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.8363e+01, -3.8539e+01, -3.1546e+01, -2.5534e+01, -2.3701e+01,\n",
            "          -2.8111e+01, -3.7296e+01, -3.1139e+01, -3.3455e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.0905e+01, -1.0900e+01, -7.6865e+00, -7.0914e+00, -7.7051e+00,\n",
            "          -5.0126e-02, -1.2323e+01, -1.2846e+01, -8.3020e+00, -3.0607e+00],\n",
            "         [-1.0378e+01, -1.0499e+01, -7.4017e+00, -1.0222e+01, -6.4894e+00,\n",
            "          -3.4416e-03, -1.1711e+01, -7.2201e+00, -7.7200e+00, -1.0514e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[4399, 5289], [1146, 20705], [20062, 12125]]\n",
            "[[4, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.1987e+01, -2.2140e+01, -1.5344e+01, -9.4508e+00, -1.0740e-04,\n",
            "          -1.2511e+01, -2.1181e+01, -1.0999e+01, -1.5507e+01, -1.1758e+01],\n",
            "         [-3.5389e+01, -3.5546e+01, -2.8782e+01, -2.1351e+01, -2.0714e+01,\n",
            "          -2.3117e+01, -3.4873e+01, -2.5006e+01, -2.9528e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-4.6142e+01, -4.6081e+01, -3.6013e+01, -2.7335e+01, -3.0826e+01,\n",
            "          -3.1246e+01, -4.7754e+01, -3.2535e+01, -3.9892e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.2068e+01, -2.1975e+01, -1.2103e+01, -3.4333e+00, -8.1783e+00,\n",
            "          -8.6069e+00, -2.0262e+01, -6.4470e+00, -1.5221e+01, -3.4937e-02],\n",
            "         [-3.3168e+01, -3.3311e+01, -2.4932e+01, -1.5422e+01, -1.7224e+01,\n",
            "          -1.9609e+01, -3.2190e+01, -2.2830e+01, -2.8028e+01, -2.3842e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[354, 12125], [5947, 3174], [1518, 20705]]\n",
            "[[9, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-2.7030e+01, -2.7071e+01, -1.8323e+01, -1.7367e+01, -1.8173e+01,\n",
            "          -1.3966e+01, -2.7362e+01, -1.8308e+01, -2.1260e+01, -8.3446e-07],\n",
            "         [-3.2956e+01, -3.3012e+01, -2.5452e+01, -2.1239e+01, -1.8507e+01,\n",
            "          -1.8848e+01, -3.2763e+01, -2.4274e+01, -2.8945e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.8045e+01, -1.7985e+01, -1.3477e+01, -8.5778e+00, -2.8094e-04,\n",
            "          -1.3284e+01, -1.5504e+01, -9.8458e+00, -1.3991e+01, -1.0245e+01],\n",
            "         [-3.1490e+01, -3.1588e+01, -2.9048e+01, -2.2854e+01, -2.3372e+01,\n",
            "          -2.5932e+01, -3.1056e+01, -2.4333e+01, -2.8689e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.1628e+01, -2.1564e+01, -1.4911e+01, -1.0958e+01, -4.4583e-05,\n",
            "          -1.1140e+01, -2.0550e+01, -1.1761e+01, -1.6820e+01, -1.2303e+01],\n",
            "         [-3.9206e+01, -3.9224e+01, -3.0191e+01, -2.2323e+01, -2.6037e+01,\n",
            "          -2.2910e+01, -3.9857e+01, -2.6179e+01, -3.2748e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[11804, 5289], [1146, 5375], [4633, 20230]]\n",
            "[[4, 9], [4, 9], [3, 3]]\n",
            "tensor([[[-2.0394e+01, -2.0182e+01, -1.5940e+01, -4.2186e+00, -1.6973e-02,\n",
            "          -1.3932e+01, -1.9156e+01, -1.0920e+01, -1.7539e+01, -6.1698e+00],\n",
            "         [-3.3978e+01, -3.3905e+01, -2.6626e+01, -1.8563e+01, -1.8746e+01,\n",
            "          -2.2838e+01, -3.3913e+01, -2.2592e+01, -3.1244e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9565e+01, -3.9592e+01, -3.2438e+01, -2.7610e+01, -2.7614e+01,\n",
            "          -3.0131e+01, -3.8915e+01, -3.3413e+01, -3.4864e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6352e+01, -1.6275e+01, -1.1560e+01, -1.3431e-03, -8.8735e+00,\n",
            "          -9.7316e+00, -1.5216e+01, -7.2294e+00, -1.2106e+01, -7.8184e+00],\n",
            "         [-2.4648e+01, -2.4658e+01, -1.9570e+01, -9.4175e-06, -1.3445e+01,\n",
            "          -1.7552e+01, -2.1239e+01, -1.4536e+01, -2.1515e+01, -1.1805e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1146, 5375], [15472, 22355], [19404, 21003]]\n",
            "[[4, 9], [9, 9], [4, 9]]\n",
            "tensor([[[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9565e+01, -3.9592e+01, -3.2438e+01, -2.7610e+01, -2.7614e+01,\n",
            "          -3.0131e+01, -3.8915e+01, -3.3413e+01, -3.4864e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-3.1061e+01, -3.1142e+01, -2.4272e+01, -1.8930e+01, -1.7117e+01,\n",
            "          -2.1224e+01, -3.1004e+01, -2.4371e+01, -2.6453e+01,  0.0000e+00],\n",
            "         [-2.9830e+01, -2.9844e+01, -2.2712e+01, -1.9427e+01, -2.2154e+01,\n",
            "          -1.6461e+01, -3.1945e+01, -2.0492e+01, -2.6957e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-2.0348e+01, -2.0307e+01, -1.2840e+01, -6.8407e+00, -2.4741e-03,\n",
            "          -9.6734e+00, -1.8577e+01, -7.9612e+00, -1.7447e+01, -6.9204e+00],\n",
            "         [-3.5090e+01, -3.5043e+01, -2.7417e+01, -2.1456e+01, -2.3740e+01,\n",
            "          -1.9419e+01, -3.7982e+01, -2.3085e+01, -3.0539e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[22332, 349], [19880, 856], [15257, 12125]]\n",
            "[[7, 7], [4, 9], [9, 9]]\n",
            "tensor([[[-1.6674e+01, -1.6657e+01, -9.6269e+00, -7.8761e+00, -7.9662e+00,\n",
            "          -6.7287e+00, -1.6366e+01, -2.1058e-03, -1.2278e+01, -9.1154e+00],\n",
            "         [-3.2121e+01, -3.2022e+01, -2.2310e+01, -1.7208e+01, -1.9008e+01,\n",
            "          -1.7025e+01, -3.3004e+01, -1.1921e-07, -3.0187e+01, -1.7338e+01]],\n",
            "\n",
            "        [[-1.7922e+01, -1.8114e+01, -1.3201e+01, -5.6178e+00, -5.5162e-03,\n",
            "          -1.0609e+01, -1.5703e+01, -7.0681e+00, -1.3462e+01, -6.9193e+00],\n",
            "         [-3.6410e+01, -3.6441e+01, -2.8365e+01, -2.0073e+01, -2.2362e+01,\n",
            "          -2.3168e+01, -3.6686e+01, -2.7349e+01, -2.9474e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4656e+01, -2.4797e+01, -1.9574e+01, -1.4510e+01, -1.8170e+01,\n",
            "          -1.3593e+01, -2.4994e+01, -1.6623e+01, -2.3324e+01, -1.7881e-06],\n",
            "         [-3.1423e+01, -3.1518e+01, -2.4505e+01, -1.6353e+01, -1.8403e+01,\n",
            "          -1.6378e+01, -3.1355e+01, -2.0611e+01, -2.8018e+01, -2.3842e-07]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1518, 856], [8691, 2004], [10805, 12525]]\n",
            "[[4, 9], [7, 7], [3, 3]]\n",
            "tensor([[[-2.1628e+01, -2.1564e+01, -1.4911e+01, -1.0958e+01, -4.4583e-05,\n",
            "          -1.1140e+01, -2.0550e+01, -1.1761e+01, -1.6820e+01, -1.2303e+01],\n",
            "         [-3.4465e+01, -3.4553e+01, -2.6000e+01, -1.8685e+01, -1.9476e+01,\n",
            "          -2.1062e+01, -3.4601e+01, -2.4400e+01, -2.7800e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.4459e+01, -1.4635e+01, -1.1065e+01, -7.2606e+00, -1.0020e+01,\n",
            "          -7.9025e+00, -1.4120e+01, -2.4787e-03, -1.4012e+01, -6.6147e+00],\n",
            "         [-2.4774e+01, -2.4711e+01, -1.7591e+01, -1.6153e+01, -1.5771e+01,\n",
            "          -1.3361e+01, -2.6019e+01, -2.7418e-06, -2.2681e+01, -1.3902e+01]],\n",
            "\n",
            "        [[-2.0432e+01, -2.0393e+01, -1.3351e+01, -2.1092e-03, -8.8737e+00,\n",
            "          -7.4032e+00, -1.7804e+01, -9.1950e+00, -1.5444e+01, -6.6812e+00],\n",
            "         [-3.1481e+01, -3.1415e+01, -2.3814e+01, -4.6133e-05, -1.3213e+01,\n",
            "          -1.5478e+01, -2.6653e+01, -1.1592e+01, -2.4195e+01, -1.0265e+01]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[3168, 2316], [13877, 12125], [4079, 83]]\n",
            "[[5, 5], [9, 9], [4, 9]]\n",
            "tensor([[[-2.0605e+01, -2.0616e+01, -1.3835e+01, -1.4602e+01, -1.4285e+01,\n",
            "          -2.5034e-06, -1.8635e+01, -1.4648e+01, -1.7846e+01, -1.7025e+01],\n",
            "         [-1.9017e+01, -1.9096e+01, -1.0111e+01, -1.5549e+01, -1.4634e+01,\n",
            "          -7.0093e-05, -1.9136e+01, -1.5832e+01, -1.4775e+01, -1.0473e+01]],\n",
            "\n",
            "        [[-2.4769e+01, -2.4614e+01, -1.7119e+01, -1.2832e+01, -1.5742e+01,\n",
            "          -1.2445e+01, -2.4375e+01, -1.6320e+01, -1.9372e+01, -6.9141e-06],\n",
            "         [-3.1761e+01, -3.1753e+01, -2.3399e+01, -1.9396e+01, -1.7677e+01,\n",
            "          -1.6584e+01, -3.2108e+01, -2.2344e+01, -2.8140e+01, -1.1921e-07]],\n",
            "\n",
            "        [[-1.3138e+01, -1.3158e+01, -6.7695e+00, -3.6393e-02, -4.7209e+00,\n",
            "          -3.7495e+00, -1.0899e+01, -6.5031e+00, -8.8223e+00, -7.6329e+00],\n",
            "         [-2.8156e+01, -2.8238e+01, -2.1368e+01, -1.7455e+01, -1.9841e+01,\n",
            "          -1.7871e+01, -2.7504e+01, -1.9401e+01, -2.2188e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[1438, 6065], [2581, 3174], [14104, 5289]]\n",
            "[[4, 9], [4, 9], [4, 9]]\n",
            "tensor([[[-1.4622e+01, -1.4574e+01, -9.3024e+00, -4.8535e+00, -1.0138e-02,\n",
            "          -6.9732e+00, -1.2109e+01, -6.8404e+00, -1.1019e+01, -8.7084e+00],\n",
            "         [-2.5483e+01, -2.5652e+01, -2.0788e+01, -1.8478e+01, -1.7001e+01,\n",
            "          -1.7463e+01, -2.4762e+01, -1.7979e+01, -2.1100e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.9373e+01, -1.9268e+01, -1.3371e+01, -1.0346e+01, -1.5401e-04,\n",
            "          -1.0024e+01, -1.6774e+01, -1.0388e+01, -1.2815e+01, -1.0069e+01],\n",
            "         [-2.8867e+01, -2.8932e+01, -2.6794e+01, -2.6368e+01, -2.4620e+01,\n",
            "          -2.7426e+01, -2.9394e+01, -2.6319e+01, -2.6835e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-1.6550e+01, -1.6442e+01, -1.4011e+01, -8.1588e+00, -3.7297e-03,\n",
            "          -6.4592e+00, -1.6047e+01, -6.7537e+00, -1.2833e+01, -7.2642e+00],\n",
            "         [-3.2630e+01, -3.2692e+01, -2.6090e+01, -2.1096e+01, -1.9945e+01,\n",
            "          -2.1140e+01, -3.3321e+01, -2.3833e+01, -2.6988e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n",
            "[[328, 12125], [1146, 5289], [6001, 3627]]\n",
            "[[9, 9], [4, 9], [9, 9]]\n",
            "tensor([[[-2.6176e+01, -2.5972e+01, -2.2627e+01, -1.4943e+01, -1.9380e+01,\n",
            "          -1.4996e+01, -2.5755e+01, -1.7521e+01, -2.3940e+01, -7.1526e-07],\n",
            "         [-3.7545e+01, -3.7588e+01, -3.0728e+01, -1.8076e+01, -2.0931e+01,\n",
            "          -1.9384e+01, -3.7464e+01, -2.5230e+01, -3.3184e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.4033e+01, -2.3927e+01, -1.8441e+01, -1.3485e+01, -2.3842e-06,\n",
            "          -1.4452e+01, -2.3440e+01, -1.6312e+01, -1.7197e+01, -1.4892e+01],\n",
            "         [-3.9451e+01, -3.9550e+01, -3.2560e+01, -2.3820e+01, -2.2416e+01,\n",
            "          -2.6602e+01, -3.8231e+01, -2.9714e+01, -3.3122e+01,  0.0000e+00]],\n",
            "\n",
            "        [[-2.3234e+01, -2.3304e+01, -1.7325e+01, -1.3871e+01, -1.4002e+01,\n",
            "          -1.4226e+01, -2.2051e+01, -1.3638e+01, -1.8442e+01, -3.6955e-06],\n",
            "         [-3.2999e+01, -3.3065e+01, -2.3713e+01, -2.2653e+01, -2.3843e+01,\n",
            "          -2.0432e+01, -3.5423e+01, -2.1094e+01, -2.9249e+01,  0.0000e+00]]],\n",
            "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTLQvRT5t9L"
      },
      "source": [
        "Improve the tagger\n",
        "----------\n",
        "\n",
        "This exercise is relatively free. You may add improvements to the basic tagger.\n",
        "Note that I expect that improving the management of unknown words and of subword units is key on this task. You may wish to:\n",
        "* Add an attention layer\n",
        "* Use part of speech tags embeddings as additional inputs\n",
        "* Find a way to learn a word embedding for unknown words\n",
        "* Integrate your convolutional word embedding module into the tagger\n",
        "* ...\n",
        "\n",
        "Describe your improvements below and point me out the name(s) of the function(s)\n",
        "where they are implemented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention\n",
        "\n",
        "scaled dot-production attention\n",
        "Attention(Q, K, V) = softmax(QK^T / sqrt(d_k))V"
      ],
      "metadata": {
        "id": "mpINAWqMMoUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self,hidden_size):\n",
        "    super(SelfAttention,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    # linear proj\n",
        "    self.W_Q = nn.Linear(hidden_size,hidden_size)\n",
        "    self.W_K = nn.Linear(hidden_size,hidden_size)\n",
        "    self.W_V = nn.Linear(hidden_size,hidden_size)\n",
        "    # sqrt dk\n",
        "    self.scale = None\n",
        "\n",
        "  def forward(self,x,mask=None):\n",
        "    # X :hidden state[batch_size,seq_len,hidden_state]\n",
        "    if self.scale is None:\n",
        "      self.scale = torch.sqrt(torch.FloatTensor([self.hidden_size])).to(x.device)\n",
        "\n",
        "    #1. get QKV\n",
        "    Q = self.W_Q(x) # [batch_size,seq_len,hidden_size]\n",
        "    K = self.W_K(x) # [batch_size,seq_len,hidden_size]\n",
        "    V = self.W_V(x) # [batch_size,seq_len,hidden_size]\n",
        "\n",
        "    #2. calculate attn\n",
        "    # K.transpose(-2,-1) # [batch_size,hidden_state,seq_len]\n",
        "    attn = torch.matmul(Q,K.transpose(-2,-1))/self.scale # [batch_size,seq_len,seq_len]\n",
        "\n",
        "    # #if mask not none: process pad\n",
        "    if mask is not None:\n",
        "      attn_mask = mask.unsqueeze(1).expand(-1,mask.size(1),-1)\n",
        "      attn = attn.masked_fill(~attn_mask,float('-inf') ) # -inf will be 0 after softmax\n",
        "\n",
        "\n",
        "    #3. softmax\n",
        "    attn =F.softmax(attn,dim=-1) # [batch_size,seq_len,seq_len]\n",
        "\n",
        "    # V\n",
        "    x = torch.matmul(attn,V) # [batch_size, seq_len,hidden_state]\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "aHFHt9EGMqCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERtagger_attn(nn.Module):\n",
        "\n",
        "    def __init__(self, traingenerator, embedding_size, hidden_size, dropout, device='cpu'):\n",
        "        super(NERtagger_attn, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.allocate_params(traingenerator, device)\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "    def allocate_params(self, datagenerator, device):\n",
        "        vocab_size = len(datagenerator.input_idx2sym)\n",
        "        out_size = len(datagenerator.output_idx2sym)\n",
        "        self.word_embedding = nn.Embedding(vocab_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size)\n",
        "        self.scaled_dot_attn = SelfAttention(self.hidden_size)\n",
        "        self.linear_proj = nn.Linear(self.hidden_size, out_size)\n",
        "\n",
        "    def forward(self, Xinput):\n",
        "        embed = self.word_embedding(Xinput)\n",
        "        embed = embed.transpose(0, 1)\n",
        "        lstm_out, _ = self.lstm(embed)\n",
        "        lstm_out = lstm_out.transpose(0, 1)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        attention_score = self.scaled_dot_attn(lstm_out)\n",
        "        tag_out = self.linear_proj(attention_score)\n",
        "        tag_scores = F.log_softmax(tag_out, dim=-1)\n",
        "        return tag_scores\n",
        "\n",
        "    def train_model(self, traingenerator, validgenerator, epochs, batch_size, device='cpu', learning_rate=0.001, patience=5):\n",
        "        self.minloss = float('inf')\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Track losses and accuracies for plotting\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        train_accuracies = []\n",
        "        valid_accuracies = []\n",
        "\n",
        "        # Early stopping variables\n",
        "        no_improve_epochs = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "\n",
        "            for SeqX, SeqY in traingenerator.generate_batches(batch_size):\n",
        "                SeqX = torch.LongTensor(SeqX).to(self.device)\n",
        "                SeqY = torch.LongTensor(SeqY).to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred = self.forward(SeqX)\n",
        "                batch_size, seq_y_len = SeqY.shape\n",
        "                y_pred = y_pred.view(batch_size * seq_y_len, -1)\n",
        "                SeqY = SeqY.view(batch_size * seq_y_len)\n",
        "                loss = loss_fnc(y_pred, SeqY)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss.append(loss.item())\n",
        "\n",
        "                # Accuracy\n",
        "                mask = (SeqY != pad_index)\n",
        "                y_argmax = torch.argmax(y_pred, dim=-1)\n",
        "                correct = torch.sum((y_argmax == SeqY) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                epoch_acc.append(float(correct) / float(total))\n",
        "\n",
        "            avg_train_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "            avg_train_acc = sum(epoch_acc) / len(epoch_acc)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            train_accuracies.append(avg_train_acc)\n",
        "\n",
        "            # Validation\n",
        "            valid_loss, valid_acc = self.validate(validgenerator, batch_size, device, save_min_model=True)\n",
        "            valid_losses.append(valid_loss)\n",
        "            valid_accuracies.append(valid_acc)\n",
        "\n",
        "            # Print results for each epoch\n",
        "            print(f'Epoch {epoch + 1}/{epochs}')\n",
        "            print(f'Training - Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_acc:.4f}')\n",
        "            print(f'[Validation] Mean Loss = {valid_loss:.4f}, Mean Accuracy = {valid_acc:.4f}')\n",
        "\n",
        "            # Early stopping check\n",
        "            if valid_loss < self.minloss:\n",
        "                self.minloss = valid_loss\n",
        "                no_improve_epochs = 0\n",
        "            else:\n",
        "                no_improve_epochs += 1\n",
        "\n",
        "            if no_improve_epochs >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plotting training and validation losses\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.plot(valid_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def validate(self, datagenerator, batch_size, device='cpu', save_min_model=False):\n",
        "        batch_accuracies = []\n",
        "        batch_losses = []\n",
        "        pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for seqX, seqY in datagenerator.generate_batches(batch_size):\n",
        "            with torch.no_grad():\n",
        "                X = torch.LongTensor(seqX).to(self.device)\n",
        "                Y = torch.LongTensor(seqY).to(self.device)\n",
        "                Yhat = self.forward(X)\n",
        "\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "                mask = (Y != pad_index)\n",
        "                Yargmax = torch.argmax(Yhat, dim=1)\n",
        "                correct = torch.sum((Yargmax == Y) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "        valid_loss = sum(batch_losses) / len(batch_losses)\n",
        "        valid_acc = sum(batch_accuracies) / len(batch_accuracies)\n",
        "\n",
        "        if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "        return valid_loss, valid_acc\n"
      ],
      "metadata": {
        "id": "t0uwgvb6WTYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = DataGenerator('eng.train')\n",
        "validset = DataGenerator('eng.testa', parentgenerator = trainset)\n",
        "tagger_attn   = NERtagger_attn(trainset,64,128,0.3,device='cuda')\n",
        "tagger_attn.train_model(trainset,validset,30,64)\n",
        "\n",
        "#ADD CODE for searching reasonable hyperparameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "PYVc5WUFWrSZ",
        "outputId": "467f2933-b8f2-4ea7-be1f-2c296435fded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "Training - Loss: 0.8885, Accuracy: 0.7541\n",
            "[Validation] Mean Loss = 0.7721, Mean Accuracy = 0.7681\n",
            "Epoch 2/30\n",
            "Training - Loss: 0.5791, Accuracy: 0.8000\n",
            "[Validation] Mean Loss = 0.5886, Mean Accuracy = 0.8037\n",
            "Epoch 3/30\n",
            "Training - Loss: 0.3979, Accuracy: 0.8611\n",
            "[Validation] Mean Loss = 0.4697, Mean Accuracy = 0.8440\n",
            "Epoch 4/30\n",
            "Training - Loss: 0.2719, Accuracy: 0.9085\n",
            "[Validation] Mean Loss = 0.3872, Mean Accuracy = 0.8718\n",
            "Epoch 5/30\n",
            "Training - Loss: 0.2151, Accuracy: 0.9303\n",
            "[Validation] Mean Loss = 0.3626, Mean Accuracy = 0.8791\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pos layer\n"
      ],
      "metadata": {
        "id": "9KYl2_Y-ArtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator_pos:\n",
        "\n",
        "        #Reuse all relevant helper functions defined above to solve the problems\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx\n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym\n",
        "                  self.pos_sym2idx = parentgenerator.pos_sym2idx\n",
        "                  self.pos_idx2sym = parentgenerator.pos_idx2sym\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx\n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym\n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  #TODO : Create 4 encoding maps from datafile\n",
        "                  self.input_sym2idx,self.input_idx2sym   = vocabulary(conllfilename,input_vocab=True,ner=False,pos=False)\n",
        "                  self.pos_sym2idx,self.pos_idx2sym = vocabulary(conllfilename,input_vocab=False,ner=False,pos=True)\n",
        "                  self.output_sym2idx,self.output_idx2sym = vocabulary(conllfilename,input_vocab=False,ner=True,pos=False)\n",
        "                  # pass\n",
        "\n",
        "\n",
        "              #TODO : store the conll dataset with sentence structure (a list of lists of strings) in the following fields\n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename)\n",
        "              self.XPos = read_conll_pos(conllfilename)\n",
        "              # pass\n",
        "\n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #This is an example generator function yielding one batch after another\n",
        "              #Batches are lists of lists\n",
        "\n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "\n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #Data ordering (try to explain why these 2 lines make sense...)\n",
        "              \"\"\"\n",
        "              shuffle : will mix all the sentence idx\n",
        "              idxes.sort() will sort all the sentence by its length, that's why if we print seqX, we can always see the sentence that are of length 1 becomes first\n",
        "              short sentence will be assigned to the batch in the beginning, this will save the padding times, improving efficiency\n",
        "              maintain randomness as well as improve model training efficiency\n",
        "              \"\"\"\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend]\n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)\n",
        "\n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqXPos = [pad_sequence(self.XPos[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqXPos = [ code_sequence(seq,self.pos_sym2idx,self.unk_token) for seq in seqXPos]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx) for seq in seqY]\n",
        "\n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqXPos,seqY)\n",
        "                 bstart += batch_size"
      ],
      "metadata": {
        "id": "Je3QqR1qWuaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERtagger_attn_pos(nn.Module):\n",
        "\n",
        "    def __init__(self, traingenerator, embedding_size, hidden_size, dropout, device='cpu'):\n",
        "        super(NERtagger_attn_pos, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.allocate_params(traingenerator, device)\n",
        "        self.device = device\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.to(self.device)\n",
        "\n",
        "    def load(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "    def allocate_params(self, datagenerator, device):\n",
        "        vocab_size = len(datagenerator.input_idx2sym)\n",
        "        pos_size = len(datagenerator.pos_idx2sym)\n",
        "        out_size = len(datagenerator.output_idx2sym)\n",
        "        self.word_embedding = nn.Embedding(vocab_size, self.embedding_size)\n",
        "        self.pos_embedding = nn.Embedding(pos_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size * 2, self.hidden_size)\n",
        "        self.scaled_dot_attn = SelfAttention(self.hidden_size)\n",
        "        self.linear_proj = nn.Linear(self.hidden_size, out_size)\n",
        "\n",
        "    def forward(self, Xinput, Xpos):\n",
        "        embed = self.word_embedding(Xinput)\n",
        "        embed_pos = self.pos_embedding(Xpos)\n",
        "        embed_concat = torch.cat([embed, embed_pos], dim=-1)\n",
        "        embed_concat = embed_concat.transpose(0, 1)\n",
        "        lstm_out, _ = self.lstm(embed_concat)\n",
        "        lstm_out = lstm_out.transpose(0, 1)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        attention_score = self.scaled_dot_attn(lstm_out)\n",
        "        tag_out = self.linear_proj(attention_score)\n",
        "        tag_scores = F.log_softmax(tag_out, dim=-1)\n",
        "        return tag_scores\n",
        "\n",
        "    def train_model(self, traingenerator, validgenerator, epochs, batch_size, device='cpu', learning_rate=0.001, patience=5):\n",
        "        self.minloss = float('inf')\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        # Track losses and accuracies for plotting\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        train_accuracies = []\n",
        "        valid_accuracies = []\n",
        "\n",
        "        # Early stopping variables\n",
        "        no_improve_epochs = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            epoch_loss = []\n",
        "            epoch_acc = []\n",
        "\n",
        "            for SeqX, SeqXpos, SeqY in traingenerator.generate_batches(batch_size):\n",
        "                SeqX = torch.LongTensor(SeqX).to(self.device)\n",
        "                SeqXpos = torch.LongTensor(SeqXpos).to(self.device)\n",
        "                SeqY = torch.LongTensor(SeqY).to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                y_pred = self.forward(SeqX, SeqXpos)\n",
        "                batch_size, seq_y_len = SeqY.shape\n",
        "                y_pred = y_pred.view(batch_size * seq_y_len, -1)\n",
        "                SeqY = SeqY.view(batch_size * seq_y_len)\n",
        "                loss = loss_fnc(y_pred, SeqY)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss.append(loss.item())\n",
        "\n",
        "                # Accuracy calculation\n",
        "                mask = (SeqY != pad_index)\n",
        "                y_argmax = torch.argmax(y_pred, dim=-1)\n",
        "                correct = torch.sum((y_argmax == SeqY) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                epoch_acc.append(float(correct) / float(total))\n",
        "\n",
        "            avg_train_loss = sum(epoch_loss) / len(epoch_loss)\n",
        "            avg_train_acc = sum(epoch_acc) / len(epoch_acc)\n",
        "            train_losses.append(avg_train_loss)\n",
        "            train_accuracies.append(avg_train_acc)\n",
        "\n",
        "            # Validation\n",
        "            valid_loss, valid_acc = self.validate(validgenerator, batch_size, device, save_min_model=True)\n",
        "            valid_losses.append(valid_loss)\n",
        "            valid_accuracies.append(valid_acc)\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f'Epoch {epoch + 1}/{epochs}')\n",
        "            print(f'Training - Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_acc:.4f}')\n",
        "            print(f'[Validation] Mean Loss = {valid_loss:.4f}, Mean Accuracy = {valid_acc:.4f}')\n",
        "\n",
        "            # Early stopping check\n",
        "            if valid_loss < self.minloss:\n",
        "                self.minloss = valid_loss\n",
        "                no_improve_epochs = 0\n",
        "            else:\n",
        "                no_improve_epochs += 1\n",
        "\n",
        "            if no_improve_epochs >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Plotting training and validation losses\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(train_losses, label='Training Loss')\n",
        "        plt.plot(valid_losses, label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def validate(self, datagenerator, batch_size, device='cpu', save_min_model=False):\n",
        "        batch_accuracies = []\n",
        "        batch_losses = []\n",
        "        pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for seqX, SeqXpos, seqY in datagenerator.generate_batches(batch_size):\n",
        "            with torch.no_grad():\n",
        "                X = torch.LongTensor(seqX).to(self.device)\n",
        "                Xpos = torch.LongTensor(SeqXpos).to(self.device)\n",
        "                Y = torch.LongTensor(seqY).to(self.device)\n",
        "\n",
        "                Yhat = self.forward(X, Xpos)\n",
        "\n",
        "                # Flattening and loss computation\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "                # Accuracy computation\n",
        "                mask = (Y != pad_index)\n",
        "                Yargmax = torch.argmax(Yhat, dim=1)\n",
        "                correct = torch.sum((Yargmax == Y) * mask)\n",
        "                total = torch.sum(mask)\n",
        "                batch_accuracies.append(float(correct) / float(total))\n",
        "\n",
        "        valid_loss = sum(batch_losses) / len(batch_losses)\n",
        "        valid_acc = sum(batch_accuracies) / len(batch_accuracies)\n",
        "\n",
        "        if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "        return valid_loss, valid_acc"
      ],
      "metadata": {
        "id": "NHqQoyyFA_UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset_withpos = DataGenerator_pos('eng.train')\n",
        "validset_withpos = DataGenerator_pos('eng.testa',parentgenerator = trainset_withpos)\n",
        "tagger_attn   = NERtagger_attn_pos(trainset_withpos,64,128,0.3,device='cuda')\n",
        "tagger_attn.train_model(trainset_withpos,validset_withpos,30,64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "id": "1JNsWZE4CfET",
        "outputId": "7e6cfb35-7b35-4240-a505-c749e9303bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "Training - Loss: 0.6091, Accuracy: 0.8033\n",
            "[Validation] Mean Loss = 0.5326, Mean Accuracy = 0.7936\n",
            "Epoch 2/30\n",
            "Training - Loss: 0.3632, Accuracy: 0.8753\n",
            "[Validation] Mean Loss = 0.4270, Mean Accuracy = 0.8424\n",
            "Epoch 3/30\n",
            "Training - Loss: 0.2447, Accuracy: 0.9187\n",
            "[Validation] Mean Loss = 0.3329, Mean Accuracy = 0.8885\n",
            "Epoch 4/30\n",
            "Training - Loss: 0.1773, Accuracy: 0.9427\n",
            "[Validation] Mean Loss = 0.2929, Mean Accuracy = 0.9031\n",
            "Epoch 5/30\n",
            "Training - Loss: 0.1649, Accuracy: 0.9485\n",
            "[Validation] Mean Loss = 0.3152, Mean Accuracy = 0.8991\n",
            "Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}